{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 31192,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "papermill": {
      "default_parameters": {},
      "duration": 127.636509,
      "end_time": "2025-12-30T18:55:25.961447",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-12-30T18:53:18.324938",
      "version": "2.6.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e5790514268d4346974cb1968ab268e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5f2d0cc82854ca5bb71be53f6a08aa8",
              "IPY_MODEL_ca843301decb435ca5cfb9c3072762d6",
              "IPY_MODEL_fd9eb950be3f4d7a9d706461c64cfde1"
            ],
            "layout": "IPY_MODEL_c4cb25ad23ad48a58bc076007bebe6e3"
          }
        },
        "d5f2d0cc82854ca5bb71be53f6a08aa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8282182a5fed4ba2a41ca7c89eca9140",
            "placeholder": "​",
            "style": "IPY_MODEL_af02a62741a148148b5eae34de57d87a",
            "value": "Fetching 3 files: 100%"
          }
        },
        "ca843301decb435ca5cfb9c3072762d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaede7bea6934326995d61828800a889",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_504874282eda4a309e09272d02483c4d",
            "value": 3
          }
        },
        "fd9eb950be3f4d7a9d706461c64cfde1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_840a4ab43c8b49c3a4bc803df4401955",
            "placeholder": "​",
            "style": "IPY_MODEL_c0a1f3348aec41f9b7949d103645ad95",
            "value": " 3/3 [00:00&lt;00:00,  1.16it/s]"
          }
        },
        "c4cb25ad23ad48a58bc076007bebe6e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8282182a5fed4ba2a41ca7c89eca9140": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af02a62741a148148b5eae34de57d87a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eaede7bea6934326995d61828800a889": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "504874282eda4a309e09272d02483c4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "840a4ab43c8b49c3a4bc803df4401955": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0a1f3348aec41f9b7949d103645ad95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6bfd17db866845498a53d18a4e692bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2352e3a6f81849fe9e76f3d4f8745ce3",
              "IPY_MODEL_08a8909588334503bc07599e0f00f5db",
              "IPY_MODEL_dd54531fe37e4c4c8a42313654adf089"
            ],
            "layout": "IPY_MODEL_e667a14d30194373b239fa3063001aee"
          }
        },
        "2352e3a6f81849fe9e76f3d4f8745ce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6578008596f24e3b856a86c14a783205",
            "placeholder": "​",
            "style": "IPY_MODEL_14a52d6266644b838a96897f860e469a",
            "value": "Ds_10k_ChuNom_TuTao.txt: "
          }
        },
        "08a8909588334503bc07599e0f00f5db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2572f3faffc94aa99c0a5d2ca0c3af3c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d395d5b80fcc4f67987000a224281c7c",
            "value": 1
          }
        },
        "dd54531fe37e4c4c8a42313654adf089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_998927aebce4400191bd38be1c3ffb8e",
            "placeholder": "​",
            "style": "IPY_MODEL_c57789bef2854def8b35db01eb373d76",
            "value": " 59.6k/? [00:00&lt;00:00, 4.97MB/s]"
          }
        },
        "e667a14d30194373b239fa3063001aee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6578008596f24e3b856a86c14a783205": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14a52d6266644b838a96897f860e469a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2572f3faffc94aa99c0a5d2ca0c3af3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d395d5b80fcc4f67987000a224281c7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "998927aebce4400191bd38be1c3ffb8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c57789bef2854def8b35db01eb373d76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4921911022e942328d73894bf7c11f92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a684a951feca4a1295e60babc814f98a",
              "IPY_MODEL_ed9e170563684cf585a389703b6aa11f",
              "IPY_MODEL_689497a1fed04306bca71ad224af627d"
            ],
            "layout": "IPY_MODEL_14819cf9682f46fe837d9ed77e5443de"
          }
        },
        "a684a951feca4a1295e60babc814f98a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_debbd94ffbc54dbcacfd2abc7e545787",
            "placeholder": "​",
            "style": "IPY_MODEL_b7658a1ff0c14d51bf9480fea8af74ce",
            "value": "Ds_300_ChuNom_TuTao.csv: "
          }
        },
        "ed9e170563684cf585a389703b6aa11f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d0345e12cfe44b9b93557d15b1f72e1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c775606c8784b0b8f4f76a658b9399e",
            "value": 1
          }
        },
        "689497a1fed04306bca71ad224af627d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0361eaaa54da474abfca4da0746b6340",
            "placeholder": "​",
            "style": "IPY_MODEL_49e0f78971fd40548a8bc2e21ce93324",
            "value": " 11.4k/? [00:00&lt;00:00, 955kB/s]"
          }
        },
        "14819cf9682f46fe837d9ed77e5443de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "debbd94ffbc54dbcacfd2abc7e545787": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7658a1ff0c14d51bf9480fea8af74ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d0345e12cfe44b9b93557d15b1f72e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6c775606c8784b0b8f4f76a658b9399e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0361eaaa54da474abfca4da0746b6340": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49e0f78971fd40548a8bc2e21ce93324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9dfb6d9d758845ceabe401312b5d62b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_759c0cb714594d6fa58cbd597d0466c9",
              "IPY_MODEL_13f3176d50a64cc9b30745bf62029d79",
              "IPY_MODEL_2fbd6250dd6944a5ba649803faeca17c"
            ],
            "layout": "IPY_MODEL_52dc7722642b4cf2bfa37fb93301e519"
          }
        },
        "759c0cb714594d6fa58cbd597d0466c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bfb8511f3e54fc0ab7f4a99be02ddf8",
            "placeholder": "​",
            "style": "IPY_MODEL_2e3b568e422841c5a584b498fb208a69",
            "value": "Top184_PureNomChar.xlsx: 100%"
          }
        },
        "13f3176d50a64cc9b30745bf62029d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_759f0f4ac8e445a5bbf9ba70d8387773",
            "max": 15786,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6d8cc758561455995d5e3acdb8f47b7",
            "value": 15786
          }
        },
        "2fbd6250dd6944a5ba649803faeca17c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1564257a7c7c491caac2b43b79252d55",
            "placeholder": "​",
            "style": "IPY_MODEL_e9cd581937824389a1fbc491f1caa03c",
            "value": " 15.8k/15.8k [00:00&lt;00:00, 1.18MB/s]"
          }
        },
        "52dc7722642b4cf2bfa37fb93301e519": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bfb8511f3e54fc0ab7f4a99be02ddf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e3b568e422841c5a584b498fb208a69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "759f0f4ac8e445a5bbf9ba70d8387773": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6d8cc758561455995d5e3acdb8f47b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1564257a7c7c491caac2b43b79252d55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9cd581937824389a1fbc491f1caa03c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "a95a46ef",
      "cell_type": "code",
      "source": [
        "# @title Environment Setup\n",
        "import os\n",
        "import sys\n",
        "if 'MPLBACKEND' in os.environ:\n",
        "    del os.environ['MPLBACKEND']\n",
        "    print(\"MPLBACKEND environment variable cleared.\")\n",
        "\n",
        "# 2. Clone the repository\n",
        "!rm -rf FontDiffusion\n",
        "!git clone https://github.com/dzungphieuluuky/FontDiffusion.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a95a46ef",
        "outputId": "d896842c-d2c8-4c6b-fd9c-e0f68622fe8a",
        "papermill": {
          "duration": 12.857369,
          "end_time": "2025-12-30T18:53:35.066181",
          "exception": false,
          "start_time": "2025-12-30T18:53:22.208812",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MPLBACKEND environment variable cleared.\n",
            "Cloning into 'FontDiffusion'...\n",
            "remote: Enumerating objects: 20660, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 20660 (delta 5), reused 7 (delta 3), pack-reused 20647 (from 2)\u001b[K\n",
            "Receiving objects: 100% (20660/20660), 278.00 MiB | 16.41 MiB/s, done.\n",
            "Resolving deltas: 100% (1001/1001), done.\n",
            "Updating files: 100% (138/138), done.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "id": "9cdd8666",
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from IPython import get_ipython\n",
        "from typing import Optional\n",
        "\n",
        "def configure_environment_paths():\n",
        "    try:\n",
        "        if \"google.colab\" in str(get_ipython()):\n",
        "            print(\"✅ Environment: Google Colab\")\n",
        "            base_data_path = \"/content/\"\n",
        "            base_output_path = \"/content/\"\n",
        "            environment_name = \"colab\"\n",
        "        elif os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\"):\n",
        "            print(\"✅ Environment: Kaggle\")\n",
        "            base_data_path = \"/kaggle/input/\"\n",
        "            base_output_path = \"/kaggle/working/\"\n",
        "            environment_name = \"kaggle\"\n",
        "        else:\n",
        "            print(\"⚠️ Environment: Local/Unknown\")\n",
        "            base_data_path = \"./data/\"\n",
        "            base_output_path = \"./output/\"\n",
        "            environment_name = \"local\"\n",
        "    except NameError:\n",
        "        print(\"⚠️ Non-interactive session. Using local paths.\")\n",
        "        base_data_path = \"./data/\"\n",
        "        base_output_path = \"./output/\"\n",
        "        environment_name = \"local\"\n",
        "    os.makedirs(base_output_path, exist_ok=True)\n",
        "    print(f\"📂 Data Path: {base_data_path}\")\n",
        "    print(f\"📦 Output Path: {base_output_path}\")\n",
        "    return base_data_path, base_output_path, environment_name\n",
        "\n",
        "def load_secret(key_name: str) -> Optional[str]:\n",
        "    env = ENV_NAME\n",
        "    secret_value = None\n",
        "    print(f\"Attempting to load secret '{key_name}' from '{env}' environment...\")\n",
        "    try:\n",
        "        if env == \"colab\":\n",
        "            from google.colab import userdata\n",
        "            secret_value = userdata.get(key_name)\n",
        "        elif env == \"kaggle\":\n",
        "            from kaggle_secrets import UserSecretsClient\n",
        "            user_secrets = UserSecretsClient()\n",
        "            secret_value = user_secrets.get_secret(key_name)\n",
        "        else:\n",
        "            secret_value = os.getenv(key_name)\n",
        "        if not secret_value:\n",
        "            print(f\"⚠️ Secret '{key_name}' not found in the {env} environment.\")\n",
        "            return None\n",
        "        print(f\"✅ Successfully loaded secret '{key_name}'.\")\n",
        "        return secret_value\n",
        "    except Exception as e:\n",
        "        print(f\"❌ An error occurred while loading secret '{key_name}': {e}\")\n",
        "        return None\n",
        "\n",
        "def print_system_info():\n",
        "    print(\"\\n🔧 System Information\")\n",
        "    print(f\"Python version: {sys.version.split()[0]}\")\n",
        "    try:\n",
        "        import torch\n",
        "        print(f\"PyTorch version: {torch.__version__}\")\n",
        "        if torch.cuda.is_available():\n",
        "            print(f\"CUDA version: {torch.version.cuda}\")\n",
        "            print(f\"GPU count: {torch.cuda.device_count()}\")\n",
        "            for i in range(torch.cuda.device_count()):\n",
        "                print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
        "        else:\n",
        "            print(\"CUDA not available\")\n",
        "    except ImportError:\n",
        "        print(\"PyTorch not installed\")\n",
        "    finally:\n",
        "      !nvidia-smi\n",
        "\n",
        "INPUT_PATH, OUTPUT_PATH, ENV_NAME = configure_environment_paths()\n",
        "is_kaggle = (\"kaggle\" in ENV_NAME)\n",
        "is_colab = not is_kaggle\n",
        "print_system_info()\n",
        "\n",
        "os.environ[\"WANDB_API_KEY\"] = wandb_key = load_secret(\"WANDB_API_KEY\")\n",
        "os.environ[\"HF_TOKEN\"] = HF_TOKEN = load_secret('HF_TOKEN')\n",
        "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = 1\n",
        "\n",
        "# Now, these libraries will log in automatically\n",
        "import wandb\n",
        "import huggingface_hub\n",
        "\n",
        "wandb.login()\n",
        "huggingface_hub.login(token=os.environ[\"HF_TOKEN\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        },
        "id": "9cdd8666",
        "outputId": "3518f82a-d65e-490b-ae8d-54225cfa5197",
        "papermill": {
          "duration": 0.019157,
          "end_time": "2025-12-30T18:53:35.092303",
          "exception": false,
          "start_time": "2025-12-30T18:53:35.073146",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Environment: Google Colab\n",
            "📂 Data Path: /content/\n",
            "📦 Output Path: /content/\n",
            "\n",
            "🔧 System Information\n",
            "Python version: 3.12.12\n",
            "PyTorch version: 2.9.0+cu126\n",
            "CUDA version: 12.6\n",
            "GPU count: 1\n",
            "  GPU 0: Tesla T4\n",
            "Fri Jan  2 07:20:21 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8             13W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Attempting to load secret 'WANDB_API_KEY' from 'colab' environment...\n",
            "✅ Successfully loaded secret 'WANDB_API_KEY'.\n",
            "Attempting to load secret 'HF_TOKEN' from 'colab' environment...\n",
            "✅ Successfully loaded secret 'HF_TOKEN'.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "str expected, not int",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2673111421.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"WANDB_API_KEY\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_secret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"WANDB_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HF_TOKEN\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHF_TOKEN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_secret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HF_TOKEN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HF_HUB_ENABLE_HF_TRANSFER\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;31m# Now, these libraries will log in automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/os.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/os.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(value)\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: str expected, not int"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "id": "a73b4150",
      "cell_type": "code",
      "source": [
        "!uv pip install --upgrade pip\n",
        "# 3. Install PyTorch 1.13\n",
        "%cd {OUTPUT_PATH}\n",
        "# Force reinstall torch 1.13 to match the model's training environment\n",
        "# !uv pip uninstall torch torchvision\n",
        "# !uv pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "!uv pip install torch==2.9 torchvision\n",
        "# 4. Install other dependencies\n",
        "\n",
        "print(\"\\n⬇️ Installing Dependencies (Manually fixed)...\")\n",
        "# Install xformers compatible with Torch 1.13\n",
        "!uv pip install xformers==0.0.16 -q\n",
        "\n",
        "# Install original dependencies\n",
        "!uv pip install transformers==4.33.1 accelerate==0.23.0 diffusers==0.22.0\n",
        "!uv pip install gradio==4.8.0 pyyaml pygame opencv-python info-nce-pytorch kornia\n",
        "# -----------------------------------------------------------------\n",
        "!uv pip install lpips scikit-image pytorch-fid\n",
        "!sudo apt-get update && sudo apt-get install dos2unix\n",
        "!uv pip install gdown tqdm\n",
        "!uv pip install wandb hf_transfer\n",
        "!uv pip install --upgrade pyarrow datasets\n",
        "print(\"\\n✅ Environment setup complete. You can now proceed to Block 2 (Inference).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a73b4150",
        "outputId": "72304a25-a416-4ab9-91b2-603ca9733c3f",
        "papermill": {
          "duration": 61.239828,
          "end_time": "2025-12-30T18:54:36.338205",
          "exception": false,
          "start_time": "2025-12-30T18:53:35.098377",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 77ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 85ms\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 70ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 16ms\u001b[0m\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mpip\u001b[0m\u001b[2m==24.1.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpip\u001b[0m\u001b[2m==25.3\u001b[0m\n",
            "/content\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m2 packages\u001b[0m \u001b[2min 100ms\u001b[0m\u001b[0m\n",
            "\n",
            "⬇️ Installing Dependencies (Manually fixed)...\n",
            "  \u001b[31m×\u001b[0m No solution found when resolving dependencies:\n",
            "\u001b[31m  ╰─▶ \u001b[0mBecause torch==1.13.1 has no wheels with a matching Python ABI tag\n",
            "\u001b[31m      \u001b[0m(e.g., `\u001b[36mcp312\u001b[39m`) and xformers==0.0.16 depends on torch==1.13.1, we can\n",
            "\u001b[31m      \u001b[0mconclude that xformers==0.0.16 cannot be used.\n",
            "\u001b[31m      \u001b[0mAnd because you require xformers==0.0.16, we can conclude that your\n",
            "\u001b[31m      \u001b[0mrequirements are unsatisfiable.\n",
            "\n",
            "\u001b[31m      \u001b[0m\u001b[36m\u001b[1mhint\u001b[0m\u001b[39m\u001b[1m:\u001b[0m You require \u001b[36mCPython 3.12\u001b[39m (`\u001b[36mcp312\u001b[39m`), but we only found wheels for\n",
            "\u001b[31m      \u001b[0m`\u001b[36mtorch\u001b[39m` (\u001b[36mv1.13.1\u001b[39m) with the following Python ABI tags: `\u001b[36mcp37m\u001b[39m`, `\u001b[36mcp38\u001b[39m`,\n",
            "\u001b[31m      \u001b[0m`\u001b[36mcp39\u001b[39m`, `\u001b[36mcp310\u001b[39m`, `\u001b[36mcp311\u001b[39m`\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m47 packages\u001b[0m \u001b[2min 339ms\u001b[0m\u001b[0m\n",
            "\u001b[2K  \u001b[31m×\u001b[0m Failed to build `tokenizers==0.13.3`\n",
            "\u001b[31m  ├─▶ \u001b[0mThe build backend returned an error\n",
            "\u001b[31m  ╰─▶ \u001b[0mCall to `setuptools.build_meta.build_wheel` failed (exit status: 1)\n",
            "\n",
            "\u001b[31m      \u001b[0m\u001b[31m[stdout]\u001b[39m\n",
            "\u001b[31m      \u001b[0mrunning bdist_wheel\n",
            "\u001b[31m      \u001b[0mrunning build\n",
            "\u001b[31m      \u001b[0mrunning build_py\n",
            "\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-312/tokenizers\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/__init__.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers\n",
            "\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-312/tokenizers/models\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/models/__init__.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/models\n",
            "\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-312/tokenizers/decoders\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/decoders/__init__.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/decoders\n",
            "\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-312/tokenizers/normalizers\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/normalizers/__init__.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/normalizers\n",
            "\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-312/tokenizers/pre_tokenizers\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/pre_tokenizers/__init__.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/pre_tokenizers\n",
            "\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-312/tokenizers/processors\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/processors/__init__.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/processors\n",
            "\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-312/tokenizers/trainers\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/trainers/__init__.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/trainers\n",
            "\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-312/tokenizers/implementations\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/byte_level_bpe.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/sentencepiece_unigram.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/__init__.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/char_level_bpe.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/sentencepiece_bpe.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/base_tokenizer.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/bert_wordpiece.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n",
            "\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-312/tokenizers/tools\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/tools/visualizer.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/tools\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/tools/__init__.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/tools\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/__init__.pyi ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/models/__init__.pyi ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/models\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/decoders/__init__.pyi ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/decoders\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/normalizers/__init__.pyi ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/normalizers\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/pre_tokenizers/__init__.pyi ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/pre_tokenizers\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/processors/__init__.pyi ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/processors\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/trainers/__init__.pyi ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/trainers\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/tools/visualizer-styles.css ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/tools\n",
            "\u001b[31m      \u001b[0mrunning build_ext\n",
            "\u001b[31m      \u001b[0mrunning build_rust\n",
            "\n",
            "\u001b[31m      \u001b[0m\u001b[31m[stderr]\u001b[39m\n",
            "\u001b[31m      \u001b[0m/root/.cache/uv/builds-v0/.tmpYZHqLO/lib/python3.12/site-packages/setuptools/dist.py:759:\n",
            "\u001b[31m      \u001b[0mSetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
            "\u001b[31m      \u001b[0m!!\n",
            "\n",
            "\u001b[31m      \u001b[0m\n",
            "\u001b[31m      \u001b[0m********************************************************************************\n",
            "\u001b[31m      \u001b[0m        Please consider removing the following classifiers in favor of a\n",
            "\u001b[31m      \u001b[0mSPDX license expression:\n",
            "\n",
            "\u001b[31m      \u001b[0m        License :: OSI Approved :: Apache Software License\n",
            "\n",
            "\u001b[31m      \u001b[0m        See\n",
            "\u001b[31m      \u001b[0mhttps://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license\n",
            "\u001b[31m      \u001b[0mfor details.\n",
            "\u001b[31m      \u001b[0m\n",
            "\u001b[31m      \u001b[0m********************************************************************************\n",
            "\n",
            "\u001b[31m      \u001b[0m!!\n",
            "\u001b[31m      \u001b[0m  self._finalize_license_expression()\n",
            "\u001b[31m      \u001b[0merror: can't find Rust compiler\n",
            "\n",
            "\u001b[31m      \u001b[0mIf you are using an outdated pip version, it is possible a prebuilt\n",
            "\u001b[31m      \u001b[0mwheel is available for this package but pip is not able to install from\n",
            "\u001b[31m      \u001b[0mit. Installing from the wheel would avoid the need for a Rust compiler.\n",
            "\n",
            "\u001b[31m      \u001b[0mTo update pip, run:\n",
            "\n",
            "\u001b[31m      \u001b[0m    pip install --upgrade pip\n",
            "\n",
            "\u001b[31m      \u001b[0mand then retry package installation.\n",
            "\n",
            "\u001b[31m      \u001b[0mIf you did intend to build this package from source, try installing\n",
            "\u001b[31m      \u001b[0ma Rust compiler from your system package manager and ensure it is\n",
            "\u001b[31m      \u001b[0mon the PATH during installation. Alternatively, rustup (available at\n",
            "\u001b[31m      \u001b[0mhttps://rustup.rs) is the recommended way to download and update the\n",
            "\u001b[31m      \u001b[0mRust compiler toolchain.\n",
            "\n",
            "\u001b[31m      \u001b[0m\u001b[36m\u001b[1mhint\u001b[0m\u001b[39m\u001b[1m:\u001b[0m This usually indicates a problem with the package or the build\n",
            "\u001b[31m      \u001b[0menvironment.\n",
            "\u001b[36m  help: \u001b[0m`\u001b[36mtokenizers\u001b[39m` (\u001b[36mv0.13.3\u001b[39m) was included because `\u001b[36mtransformers\u001b[39m` (\u001b[36mv4.33.1\u001b[39m)\n",
            "        depends on `\u001b[36mtokenizers\u001b[39m`\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m91 packages\u001b[0m \u001b[2min 486ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m12 packages\u001b[0m \u001b[2min 1.63s\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m9 packages\u001b[0m \u001b[2min 191ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m12 packages\u001b[0m \u001b[2min 70ms\u001b[0m\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1maiofiles\u001b[0m\u001b[2m==24.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1maiofiles\u001b[0m\u001b[2m==23.2.1\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mgradio\u001b[0m\u001b[2m==5.50.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgradio\u001b[0m\u001b[2m==4.8.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mgradio-client\u001b[0m\u001b[2m==1.14.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgradio-client\u001b[0m\u001b[2m==0.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1minfo-nce-pytorch\u001b[0m\u001b[2m==0.1.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mkornia\u001b[0m\u001b[2m==0.8.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mkornia-rs\u001b[0m\u001b[2m==0.1.10\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==2.1.5\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mopencv-python\u001b[0m\u001b[2m==4.12.0.88\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopencv-python\u001b[0m\u001b[2m==4.11.0.86\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==11.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==10.4.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtomlkit\u001b[0m\u001b[2m==0.13.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtomlkit\u001b[0m\u001b[2m==0.12.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mwebsockets\u001b[0m\u001b[2m==15.0.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwebsockets\u001b[0m\u001b[2m==11.0.3\u001b[0m\n",
            "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mThe package `typer==0.20.0` does not have an extra named `all`\u001b[0m\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m38 packages\u001b[0m \u001b[2min 65ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 7ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlpips\u001b[0m\u001b[2m==0.1.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpytorch-fid\u001b[0m\u001b[2m==0.3.0\u001b[0m\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:4 https://cli.github.com/packages stable/main amd64 Packages [345 B]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,227 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,860 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,287 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,598 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,205 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,966 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,573 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,633 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [69.2 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,411 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [37.2 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.9 kB]\n",
            "Fetched 38.3 MB in 5s (7,857 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  dos2unix\n",
            "0 upgraded, 1 newly installed, 0 to remove and 54 not upgraded.\n",
            "Need to get 384 kB of archives.\n",
            "After this operation, 1,367 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 dos2unix amd64 7.4.2-2 [384 kB]\n",
            "Fetched 384 kB in 1s (336 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package dos2unix.\n",
            "(Reading database ... 121689 files and directories currently installed.)\n",
            "Preparing to unpack .../dos2unix_7.4.2-2_amd64.deb ...\n",
            "Unpacking dos2unix (7.4.2-2) ...\n",
            "Setting up dos2unix (7.4.2-2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m2 packages\u001b[0m \u001b[2min 88ms\u001b[0m\u001b[0m\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m2 packages\u001b[0m \u001b[2min 87ms\u001b[0m\u001b[0m\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m39 packages\u001b[0m \u001b[2min 210ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m12 packages\u001b[0m \u001b[2min 1.29s\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m12 packages\u001b[0m \u001b[2min 130ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m12 packages\u001b[0m \u001b[2min 58ms\u001b[0m\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==4.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==4.4.2\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mdill\u001b[0m\u001b[2m==0.3.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdill\u001b[0m\u001b[2m==0.4.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.20.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.20.1\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.10.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.36.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==1.2.3\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mmultiprocess\u001b[0m\u001b[2m==0.70.16\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmultiprocess\u001b[0m\u001b[2m==0.70.18\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.4.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.2.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.3.3\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mpyarrow\u001b[0m\u001b[2m==18.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyarrow\u001b[0m\u001b[2m==22.0.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.5\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtyper-slim\u001b[0m\u001b[2m==0.20.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyper-slim\u001b[0m\u001b[2m==0.21.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.5.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.6.2\u001b[0m\n",
            "\n",
            "✅ Environment setup complete. You can now proceed to Block 2 (Inference).\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "id": "bd517dfe",
      "cell_type": "code",
      "source": [
        "# KAGGLE CELL #1: Download checkpoint\n",
        "if is_colab:\n",
        "  !uv pip install --upgrade \"huggingface-hub>=0.34.0,<1.0\"\n",
        "else:\n",
        "  !uv pip install --upgrade \"huggingface-hub==0.25.2\" \"protobuf<5.0.0\" \"numpy<2.0.0\"\n",
        "import os\n",
        "import sys\n",
        "from tqdm.auto import tqdm\n",
        "from pathlib import Path\n",
        "os.chdir(OUTPUT_PATH)\n",
        "import os\n",
        "from pathlib import Path\n",
        "def download_from_hf(\n",
        "    repo_id: str,\n",
        "    local_dir: str = \"ckpt\",\n",
        "    allow_patterns=None,\n",
        "    force_download: bool = False,\n",
        "    repo_type: str = \"model\"\n",
        "):\n",
        "    if allow_patterns is None:\n",
        "        allow_patterns = [\"*.safetensors\", \"scr*\"]\n",
        "    print(f\"📥 Downloading checkpoint from Hugging Face Hub to '{local_dir}'...\\n\")\n",
        "    from huggingface_hub import snapshot_download\n",
        "    snapshot_download(\n",
        "        repo_id=repo_id,\n",
        "        local_dir=local_dir,\n",
        "        repo_type=repo_type,\n",
        "        allow_patterns=allow_patterns,\n",
        "        force_download=force_download\n",
        "    )\n",
        "    print(\"\\n✅ Download complete!\")\n",
        "    print(f\"\\n📂 Files in {local_dir}/:\")\n",
        "    for file in os.listdir(local_dir):\n",
        "        if file.endswith(\".safetensors\"):\n",
        "            size = os.path.getsize(os.path.join(local_dir, file)) / (1024**2)\n",
        "            print(f\"  ✓ {file} ({size:.2f} MB)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd517dfe",
        "outputId": "8c093b24-6311-4526-d968-2970479d5606",
        "papermill": {
          "duration": 12.524295,
          "end_time": "2025-12-30T18:54:48.878013",
          "exception": false,
          "start_time": "2025-12-30T18:54:36.353718",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠋\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mhuggingface-hub==0.36.0                                                       \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mfilelock==3.20.1                                                              \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mfsspec==2025.12.0                                                             \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mpackaging==25.0                                                               \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mpyyaml==6.0.3                                                                 \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mrequests==2.32.5                                                              \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mtqdm==4.67.1                                                                  \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mtyping-extensions==4.15.0                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mhf-xet==1.2.0                                                                 \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mhf-xet==1.2.0                                                                 \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mcharset-normalizer==3.4.4                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2midna==3.11                                                                    \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2murllib3==2.6.2                                                                \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mcertifi==2025.11.12                                                           \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2m                                                                              \u001b[0m\r\u001b[2K\u001b[2mResolved \u001b[1m13 packages\u001b[0m \u001b[2min 28ms\u001b[0m\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m13 packages\u001b[0m \u001b[2min 0.41ms\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "download_from_hf(\n",
        "    repo_id=\"dzungpham/font-diffusion-weights\",\n",
        "    local_dir=\"ckpt\",\n",
        "    allow_patterns=[\"*.safetensors\", \"scr*\"]\n",
        ")"
      ],
      "metadata": {
        "id": "tOpa7Bh8leVB"
      },
      "id": "tOpa7Bh8leVB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_from_hf(\n",
        "    repo_id=\"dzungpham/font-diffusion-generated-data\",\n",
        "    local_dir=\"NomTuTao\",\n",
        "    repo_type=\"dataset\",\n",
        "    allow_patterns=[\"*Nom*\"]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249,
          "referenced_widgets": [
            "e5790514268d4346974cb1968ab268e1",
            "d5f2d0cc82854ca5bb71be53f6a08aa8",
            "ca843301decb435ca5cfb9c3072762d6",
            "fd9eb950be3f4d7a9d706461c64cfde1",
            "c4cb25ad23ad48a58bc076007bebe6e3",
            "8282182a5fed4ba2a41ca7c89eca9140",
            "af02a62741a148148b5eae34de57d87a",
            "eaede7bea6934326995d61828800a889",
            "504874282eda4a309e09272d02483c4d",
            "840a4ab43c8b49c3a4bc803df4401955",
            "c0a1f3348aec41f9b7949d103645ad95",
            "6bfd17db866845498a53d18a4e692bb1",
            "2352e3a6f81849fe9e76f3d4f8745ce3",
            "08a8909588334503bc07599e0f00f5db",
            "dd54531fe37e4c4c8a42313654adf089",
            "e667a14d30194373b239fa3063001aee",
            "6578008596f24e3b856a86c14a783205",
            "14a52d6266644b838a96897f860e469a",
            "2572f3faffc94aa99c0a5d2ca0c3af3c",
            "d395d5b80fcc4f67987000a224281c7c",
            "998927aebce4400191bd38be1c3ffb8e",
            "c57789bef2854def8b35db01eb373d76",
            "4921911022e942328d73894bf7c11f92",
            "a684a951feca4a1295e60babc814f98a",
            "ed9e170563684cf585a389703b6aa11f",
            "689497a1fed04306bca71ad224af627d",
            "14819cf9682f46fe837d9ed77e5443de",
            "debbd94ffbc54dbcacfd2abc7e545787",
            "b7658a1ff0c14d51bf9480fea8af74ce",
            "8d0345e12cfe44b9b93557d15b1f72e1",
            "6c775606c8784b0b8f4f76a658b9399e",
            "0361eaaa54da474abfca4da0746b6340",
            "49e0f78971fd40548a8bc2e21ce93324",
            "9dfb6d9d758845ceabe401312b5d62b3",
            "759c0cb714594d6fa58cbd597d0466c9",
            "13f3176d50a64cc9b30745bf62029d79",
            "2fbd6250dd6944a5ba649803faeca17c",
            "52dc7722642b4cf2bfa37fb93301e519",
            "2bfb8511f3e54fc0ab7f4a99be02ddf8",
            "2e3b568e422841c5a584b498fb208a69",
            "759f0f4ac8e445a5bbf9ba70d8387773",
            "a6d8cc758561455995d5e3acdb8f47b7",
            "1564257a7c7c491caac2b43b79252d55",
            "e9cd581937824389a1fbc491f1caa03c"
          ]
        },
        "id": "Jc4jsIvvlg7T",
        "outputId": "8751e76b-0c14-46cb-a462-c5fb37347616"
      },
      "id": "Jc4jsIvvlg7T",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📥 Downloading checkpoint from Hugging Face Hub to 'NomTuTao'...\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5790514268d4346974cb1968ab268e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Ds_10k_ChuNom_TuTao.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6bfd17db866845498a53d18a4e692bb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Ds_300_ChuNom_TuTao.csv: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4921911022e942328d73894bf7c11f92"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Top184_PureNomChar.xlsx:   0%|          | 0.00/15.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9dfb6d9d758845ceabe401312b5d62b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Download complete!\n",
            "\n",
            "📂 Files in NomTuTao/:\n"
          ]
        }
      ]
    },
    {
      "id": "767e8ea2",
      "cell_type": "code",
      "source": [
        "# @title Unzipping all archived files\n",
        "import os\n",
        "import glob\n",
        "from zipfile import ZipFile\n",
        "\n",
        "zip_file_paths = glob.glob(os.path.join(INPUT_PATH, '*.zip'))\n",
        "\n",
        "if not zip_file_paths:\n",
        "    print(f'No .zip files found in {INPUT_PATH}.')\n",
        "else:\n",
        "    for zip_file_path in zip_file_paths:\n",
        "        if os.path.exists(zip_file_path):\n",
        "            print(f'Unzipping {zip_file_path}...')\n",
        "            !unzip -o {zip_file_path} -d ./\n",
        "            print(f'Unzipping of {zip_file_path} complete.')\n",
        "        else:\n",
        "            print(f'Error: The file {zip_file_path} was not found (post-glob check).')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "767e8ea2",
        "outputId": "7283f814-255e-49c3-be33-99c92ce2791e",
        "papermill": {
          "duration": 0.023805,
          "end_time": "2025-12-30T18:54:48.917163",
          "exception": false,
          "start_time": "2025-12-30T18:54:48.893358",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No .zip files found in /content/.\n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "id": "4f4cf20b",
      "cell_type": "code",
      "source": [
        "print(\"Model files:\")\n",
        "!ls -larth {OUTPUT_PATH}/ckpt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f4cf20b",
        "outputId": "5a9f48f1-96fc-4fab-bebc-01d1385ee3b4",
        "papermill": {
          "duration": 0.140282,
          "end_time": "2025-12-30T18:54:50.749810",
          "exception": false,
          "start_time": "2025-12-30T18:54:50.609528",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model files:\n",
            "total 1.1G\n",
            "drwxr-xr-x 3 root root 4.0K Jan  2 07:20 .cache\n",
            "-rw-r--r-- 1 root root 4.6M Jan  2 07:20 content_encoder.safetensors\n",
            "-rw-r--r-- 1 root root  79M Jan  2 07:20 style_encoder.safetensors\n",
            "-rw-r--r-- 1 root root 384M Jan  2 07:21 total_model.safetensors\n",
            "-rw-r--r-- 1 root root 301M Jan  2 07:21 unet.safetensors\n",
            "-rw-r--r-- 1 root root 272M Jan  2 07:21 scr_210000.pth\n",
            "drwxr-xr-x 3 root root 4.0K Jan  2 07:21 .\n",
            "drwxr-xr-x 1 root root 4.0K Jan  2 07:23 ..\n"
          ]
        }
      ],
      "execution_count": 9
    },
    {
      "id": "92cff682",
      "cell_type": "code",
      "source": [
        "%cd {OUTPUT_PATH}\n",
        "# ==========================================\n",
        "# EXPORT / DOWNLOAD DATASET COMMANDS\n",
        "# ==========================================\n",
        "HF_USERNAME = \"dzungpham\"\n",
        "# Train Split\n",
        "!python FontDiffusion/export_hf_dataset_to_disk.py \\\n",
        "  --output_dir \"my_dataset/train_original\" \\\n",
        "  --repo_id {HF_USERNAME}/font-diffusion-generated-data \\\n",
        "  --split \"train_original\" \\\n",
        "  --token HF_TOKEN"
      ],
      "metadata": {
        "id": "92cff682",
        "papermill": {
          "duration": 0.104394,
          "end_time": "2025-12-30T18:54:50.869230",
          "exception": false,
          "start_time": "2025-12-30T18:54:50.764836",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9712a8dd-44bd-4e6e-dad8-7ddc862404b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "\n",
            "============================================================\n",
            "EXPORTING DATASET TO DISK\n",
            "============================================================\n",
            "\n",
            "📥 Loading dataset from Hub...\n",
            "   Repository: dzungpham/font-diffusion-generated-data\n",
            "   Split: train_original\n",
            "README.md: 3.05kB [00:00, 8.19MB/s]\n",
            "data/train_original-00000-of-00001.parqu(…): 100% 117M/117M [00:04<00:00, 25.7MB/s]\n",
            "data/train-00000-of-00001.parquet: 100% 77.1M/77.1M [00:04<00:00, 17.6MB/s]\n",
            "data/val-00000-of-00001.parquet: 100% 3.65M/3.65M [00:02<00:00, 1.63MB/s]\n",
            "Generating train_original split: 100% 8985/8985 [00:00<00:00, 18014.66 examples/s]\n",
            "Generating train split: 100% 5760/5760 [00:00<00:00, 14617.74 examples/s]\n",
            "Generating val split: 100% 357/357 [00:00<00:00, 20638.53 examples/s]\n",
            "✓ Loaded dataset with 8985 samples from Hub\n",
            "\n",
            "Exporting images from dataset...\n",
            "\n",
            "🎨 Exporting images...\n",
            "Exporting: 100%|███████████████████████████| 8985/8985 [00:26<00:00, 333.70it/s]\n",
            "✓ Exported 599 content images\n",
            "✓ Exported 8985 target images\n",
            "\n",
            "💾 Saving results_checkpoint.json...\n",
            "  ✓ Saved results_checkpoint.json (8985 generations)\n",
            "\n",
            "📊 Metadata Statistics:\n",
            "  Total generations: 8985\n",
            "  Total characters: 599\n",
            "  Total styles: 15\n",
            "  Fonts: NomNaTong-Regular\n",
            "\n",
            "============================================================\n",
            "✅ EXPORT COMPLETE!\n",
            "============================================================\n",
            "\n",
            "Files created:\n",
            "  ✓ my_dataset/train_original/ContentImage/\n",
            "  ✓ my_dataset/train_original/TargetImage/\n",
            "  ✓ my_dataset/train_original/results_checkpoint.json\n"
          ]
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": [
        "!python FontDiffusion/export_hf_dataset_to_disk.py \\\n",
        "  --output_dir \"my_dataset/train\" \\\n",
        "  --repo_id {HF_USERNAME}/font-diffusion-generated-data \\\n",
        "  --split \"train\" \\\n",
        "  --token HF_TOKEN"
      ],
      "metadata": {
        "id": "lh696hc0l1jr"
      },
      "id": "lh696hc0l1jr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation: Unseen Both\n",
        "!python FontDiffusion/export_hf_dataset_to_disk.py \\\n",
        "  --output_dir \"my_dataset/val\" \\\n",
        "  --repo_id {HF_USERNAME}/font-diffusion-generated-data \\\n",
        "  --split \"val\" \\\n",
        "  --token HF_TOKEN"
      ],
      "metadata": {
        "id": "rzW-I7QMl2ik"
      },
      "id": "rzW-I7QMl2ik",
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "6db9c1d6-dd60-479c-92c4-2f653e4d48fd",
      "cell_type": "code",
      "source": [
        "print(\"Fonts currently in fonts/ folder\")\n",
        "!ls -lt FontDiffusion/fonts\n",
        "print(\"Styles in style_images/ folder\")\n",
        "!ls -l FontDiffusion/styles_images"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6db9c1d6-dd60-479c-92c4-2f653e4d48fd",
        "outputId": "92728fc2-2d64-4498-8f22-c395f5bcb4bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fonts currently in fonts/ folder\n",
            "total 332584\n",
            "-rw-r--r-- 1 root root 26929728 Jan  2 07:20  NomNaTongLight2.ttf\n",
            "-rw-r--r-- 1 root root 14574480 Jan  2 07:20  NomNaTongLight.ttf\n",
            "-rw-r--r-- 1 root root 31729820 Jan  2 07:20  NomNaTong-Regular2.otf\n",
            "-rw-r--r-- 1 root root 14574552 Jan  2 07:20  NomNaTong-Regular.ttf\n",
            "-rw-r--r-- 1 root root  9424552 Jan  2 07:20  NomNaTong-Regular.otf\n",
            "-rw-r--r-- 1 root root 12967288 Jan  2 07:20  HanaMinC.otf\n",
            "-rw-r--r-- 1 root root 30739236 Jan  2 07:20  HanaMinB.ttf\n",
            "-rw-r--r-- 1 root root 32201032 Jan  2 07:20  HanaMinB.otf\n",
            "-rw-r--r-- 1 root root 22761228 Jan  2 07:20  HanaMinA.ttf\n",
            "-rw-r--r-- 1 root root 31621108 Jan  2 07:20  HanaMinA.otf\n",
            "-rw-r--r-- 1 root root 18202176 Jan  2 07:20 'Han-nom Minh 1.42.otf'\n",
            "-rw-r--r-- 1 root root 19505228 Jan  2 07:20  Han-Nom-Khai-Regular-300623.ttf\n",
            "-rw-r--r-- 1 root root 20368044 Jan  2 07:20 'Han-Nom Kai 1.00.otf'\n",
            "-rw-r--r-- 1 root root 33815824 Jan  2 07:20 'HAN NOM B.ttf'\n",
            "-rw-r--r-- 1 root root 21320444 Jan  2 07:20 'HAN NOM A.ttf'\n",
            "Styles in style_images/ folder\n",
            "total 520\n",
            "-rw-r--r-- 1 root root  55480 Jan  2 07:20 1.png\n",
            "-rw-r--r-- 1 root root  73193 Jan  2 07:20 2.png\n",
            "-rw-r--r-- 1 root root  62305 Jan  2 07:20 3.png\n",
            "-rw-r--r-- 1 root root  47202 Jan  2 07:20 4.png\n",
            "-rw-r--r-- 1 root root  40943 Jan  2 07:20 5.png\n",
            "-rw-r--r-- 1 root root  11400 Jan  2 07:20 6.png\n",
            "-rw-r--r-- 1 root root  26508 Jan  2 07:20 hanh.png\n",
            "-rw-r--r-- 1 root root   1569 Jan  2 07:20 hanhthu1.jpg\n",
            "-rw-r--r-- 1 root root   1036 Jan  2 07:20 hanhthu2.jpg\n",
            "-rw-r--r-- 1 root root 100710 Jan  2 07:20 khai.png\n",
            "-rw-r--r-- 1 root root  36429 Jan  2 07:20 le.png\n",
            "-rw-r--r-- 1 root root   1086 Jan  2 07:20 lethu1.jpg\n",
            "-rw-r--r-- 1 root root   1182 Jan  2 07:20 lethu2.jpg\n",
            "-rw-r--r-- 1 root root  17600 Jan  2 07:20 thao.png\n",
            "-rw-r--r-- 1 root root  27078 Jan  2 07:20 trien.png\n"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "id": "29deed1d",
      "cell_type": "code",
      "source": [
        "if is_colab:\n",
        "  !uv pip install --upgrade \"huggingface-hub>=0.34.0,<1.0\"\n",
        "else:\n",
        "  !uv pip install --upgrade \"huggingface-hub==0.25.2\" \"protobuf<5.0.0\" \"numpy<2.0.0\"\n",
        "%cd {OUTPUT_PATH}\n",
        "!accelerate launch --num_processes 1 \\\n",
        "    FontDiffusion/sample_batch.py \\\n",
        "    --characters \"NomTuTao/Ds_10k_ChuNom_TuTao.txt\" \\\n",
        "    --style_images \"FontDiffusion/styles_images\" \\\n",
        "    --ckpt_dir \"ckpt/\" \\\n",
        "    --ttf_path \"FontDiffusion/fonts/NomNaTong-Regular.otf\" \\\n",
        "    --output_dir \"my_dataset/train_original\" \\\n",
        "    --num_inference_steps 20 \\\n",
        "    --guidance_scale 7.5 \\\n",
        "    --start_line 600 \\\n",
        "    --end_line 800 \\\n",
        "    --batch_size 35 \\\n",
        "    --save_interval 1 \\\n",
        "    --channels_last \\\n",
        "    --seed 42 \\\n",
        "    --compile \\\n",
        "    --enable_xformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29deed1d",
        "outputId": "9536dc48-e8c4-4dc7-b2c6-84222a137c2a",
        "papermill": {
          "duration": 10.53661,
          "end_time": "2025-12-30T18:55:01.421093",
          "exception": false,
          "start_time": "2025-12-30T18:54:50.884483",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠋\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mhuggingface-hub==0.36.0                                                       \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mfilelock==3.20.1                                                              \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mfsspec==2025.12.0                                                             \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mpackaging==25.0                                                               \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mpyyaml==6.0.3                                                                 \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mrequests==2.32.5                                                              \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mtqdm==4.67.1                                                                  \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mtyping-extensions==4.15.0                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mhf-xet==1.2.0                                                                 \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mhf-xet==1.2.0                                                                 \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mcharset-normalizer==3.4.4                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2midna==3.11                                                                    \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2murllib3==2.6.2                                                                \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mcertifi==2025.11.12                                                           \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2m                                                                              \u001b[0m\r\u001b[2K\u001b[2mResolved \u001b[1m13 packages\u001b[0m \u001b[2min 44ms\u001b[0m\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m13 packages\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n",
            "/content\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "/content/FontDiffusion/src/dpm_solver/dpm_solver_pytorch.py:53: SyntaxWarning: invalid escape sequence '\\h'\n",
            "  The `alphas_cumprod` is the \\hat{alpha_n} arrays in the notations of DDPM. Specifically, DDPMs assume that\n",
            "pygame 2.6.1 (SDL 2.28.4, Python 3.12.12)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
            "📖 Reading character file: 100%|\u001b[32m█████████████████████████████████\u001b[0m| 201/201 [00:00<00:00, 771kfile/s]\u001b[0m\n",
            "✓ Verifying style images: 100%|\u001b[32m███████████████████████████████\u001b[0m| 15.0/15.0 [00:00<00:00, 80.1kfile/s]\u001b[0m\n",
            "error: XDG_RUNTIME_DIR not set in the environment.\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "Loading FontDiffuser pipeline...\n",
            "Load the down block  DownBlock2D\n",
            "Load the down block  MCADownBlock2D\n",
            "The style_attention cross attention dim in Down Block 1 layer is 1024\n",
            "The style_attention cross attention dim in Down Block 2 layer is 1024\n",
            "Load the down block  MCADownBlock2D\n",
            "The style_attention cross attention dim in Down Block 1 layer is 1024\n",
            "The style_attention cross attention dim in Down Block 2 layer is 1024\n",
            "Load the down block  DownBlock2D\n",
            "Load the up block  UpBlock2D\n",
            "Load the up block  StyleRSIUpBlock2D\n",
            "Load the up block  StyleRSIUpBlock2D\n",
            "Load the up block  UpBlock2D\n",
            "Param count for Ds initialized parameters: 20591296\n",
            "Get CG-GAN Style Encoder!\n",
            "Param count for Ds initialized parameters: 1187008\n",
            "Get CG-GAN Content Encoder!\n",
            "✓ Loaded model state_dict successfully\n",
            "Converting to channels-last memory format...\n",
            "2026-01-02 07:26:08.347676: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767338768.368065    2924 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767338768.374388    2924 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1767338768.390318    2924 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767338768.390343    2924 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767338768.390347    2924 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767338768.390353    2924 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-02 07:26:08.395061: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "✓ Model moved to device\n",
            "✓ Loaded training DDPM scheduler successfully\n",
            "✓ Loaded DPM-Solver pipeline successfully\n",
            "/content/FontDiffusion/sample_batch.py:1576: FutureWarning: Accessing config attribute `unet` directly via 'FontDiffuserModelDPM' object attribute is deprecated. Please access 'unet' over 'FontDiffuserModelDPM's config object instead, e.g. 'unet.config.unet'.\n",
            "  if hasattr(pipe.model, \"unet\"):\n",
            "/content/FontDiffusion/sample_batch.py:1577: FutureWarning: Accessing config attribute `unet` directly via 'FontDiffuserModelDPM' object attribute is deprecated. Please access 'unet' over 'FontDiffuserModelDPM's config object instead, e.g. 'unet.config.unet'.\n",
            "  pipe.model.unet = torch.compile(pipe.model.unet)\n",
            "/content/FontDiffusion/sample_batch.py:1578: FutureWarning: Accessing config attribute `style_encoder` directly via 'FontDiffuserModelDPM' object attribute is deprecated. Please access 'style_encoder' over 'FontDiffuserModelDPM's config object instead, e.g. 'unet.config.style_encoder'.\n",
            "  if hasattr(pipe.model, \"style_encoder\"):\n",
            "/content/FontDiffusion/sample_batch.py:1579: FutureWarning: Accessing config attribute `style_encoder` directly via 'FontDiffuserModelDPM' object attribute is deprecated. Please access 'style_encoder' over 'FontDiffuserModelDPM's config object instead, e.g. 'unet.config.style_encoder'.\n",
            "  pipe.model.style_encoder = torch.compile(pipe.model.style_encoder)\n",
            "/content/FontDiffusion/sample_batch.py:1580: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModelDPM' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModelDPM's config object instead, e.g. 'unet.config.content_encoder'.\n",
            "  if hasattr(pipe.model, \"content_encoder\"):\n",
            "/content/FontDiffusion/sample_batch.py:1582: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModelDPM' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModelDPM's config object instead, e.g. 'unet.config.content_encoder'.\n",
            "  pipe.model.content_encoder\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100% 233M/233M [00:01<00:00, 175MB/s]\n",
            "Loading model from: /usr/local/lib/python3.12/dist-packages/lpips/weights/v0.1/alex.pth\n",
            "📸 Generating content images: 100%|\u001b[35m██████████████████████████████\u001b[0m| 201/201 [00:15<00:00, 12.7pair/s]\u001b[0m\n",
            "🎨 Generating styles:   0%|                                           | 0.00/15.0 [00:00<?, ?pair/s]\n",
            "  📸 Preparing NomNaTong-Regular:   0%|\u001b[36m                                \u001b[0m| 0.00/200 [00:00<?, ?file/s]\u001b[0m\u001b[A\n",
            "  📸 Preparing NomNaTong-Regular:  34%|\u001b[36m████████▋                 \u001b[0m| 67.0/200 [00:00<00:00, 663file/s]\u001b[0m\u001b[A\n",
            "  📸 Preparing NomNaTong-Regular: 100%|\u001b[36m███████████████████████████\u001b[0m| 200/200 [00:00<00:00, 824file/s]\u001b[0m\n",
            "\n",
            "    🚀 Batch Inference:   0%|\u001b[38;2;16;85;201m                                         \u001b[0m| 0.00/6.00 [00:00<?, ?pair/s]\u001b[0m\u001b[A\n",
            "    🚀 Batch Inference:  17%|\u001b[38;2;16;85;201m█████▋                            \u001b[0m| 1.00/6.00 [00:57<04:47, 57.4s/pair]\u001b[0m\u001b[A\n",
            "    🚀 Batch Inference:  50%|\u001b[38;2;16;85;201m█████████████████                 \u001b[0m| 3.00/6.00 [01:55<01:48, 36.3s/pair]\u001b[0m\u001b[A\n",
            "    🚀 Batch Inference:  83%|\u001b[38;2;16;85;201m████████████████████████████▎     \u001b[0m| 5.00/6.00 [02:52<00:32, 32.4s/pair]\u001b[0m\u001b[A\n",
            "    🚀 Batch Inference: 100%|\u001b[38;2;16;85;201m██████████████████████████████████\u001b[0m| 6.00/6.00 [03:50<00:00, 39.2s/pair]\u001b[0m\u001b[A\n",
            "    🚀 Batch Inference: 8.00pair [04:47, 34.7s/pair]                                                \u001b[A\n",
            "    🚀 Batch Inference: 100%|\u001b[38;2;16;85;201m██████████████████████████████████\u001b[0m| 6.00/6.00 [05:29<00:00, 54.9s/pair]\u001b[0m\n",
            "🎨 Generating styles:   7%|██▎                                | 1.00/15.0 [06:01<1:24:14, 361s/pair]\n",
            "  📸 Preparing NomNaTong-Regular:   0%|\u001b[36m                                \u001b[0m| 0.00/200 [00:00<?, ?file/s]\u001b[0m\u001b[A\n",
            "  📸 Preparing NomNaTong-Regular:  50%|\u001b[36m█████████████▌             \u001b[0m| 100/200 [00:00<00:00, 994file/s]\u001b[0m\u001b[A\n",
            "  📸 Preparing NomNaTong-Regular: 100%|\u001b[36m███████████████████████████\u001b[0m| 200/200 [00:00<00:00, 804file/s]\u001b[0m\n",
            "\n",
            "    🚀 Batch Inference:   0%|\u001b[38;2;16;85;201m                                         \u001b[0m| 0.00/6.00 [00:00<?, ?pair/s]\u001b[0m\u001b[A\n",
            "    🚀 Batch Inference:  17%|\u001b[38;2;16;85;201m█████▋                            \u001b[0m| 1.00/6.00 [00:58<04:52, 58.4s/pair]\u001b[0m\u001b[A\n",
            "    🚀 Batch Inference:  50%|\u001b[38;2;16;85;201m█████████████████                 \u001b[0m| 3.00/6.00 [01:55<01:49, 36.4s/pair]\u001b[0m\u001b[A\n",
            "    🚀 Batch Inference:  83%|\u001b[38;2;16;85;201m████████████████████████████▎     \u001b[0m| 5.00/6.00 [02:53<00:32, 32.5s/pair]\u001b[0m\u001b[A\n",
            "    🚀 Batch Inference: 100%|\u001b[38;2;16;85;201m██████████████████████████████████\u001b[0m| 6.00/6.00 [03:51<00:00, 39.3s/pair]\u001b[0m\u001b[A\n",
            "    🚀 Batch Inference: 8.00pair [04:48, 34.7s/pair]                                                \u001b[A\n",
            "    🚀 Batch Inference: 100%|\u001b[38;2;16;85;201m██████████████████████████████████\u001b[0m| 6.00/6.00 [05:30<00:00, 55.0s/pair]\u001b[0m\n",
            "🎨 Generating styles:  13%|████▋                              | 2.00/15.0 [12:02<1:18:19, 361s/pair]\n",
            "  📸 Preparing NomNaTong-Regular:   0%|\u001b[36m                                \u001b[0m| 0.00/200 [00:00<?, ?file/s]\u001b[0m\u001b[A\n",
            "  📸 Preparing NomNaTong-Regular:  38%|\u001b[36m██████████                \u001b[0m| 77.0/200 [00:00<00:00, 765file/s]\u001b[0m\u001b[A\n",
            "  📸 Preparing NomNaTong-Regular: 100%|\u001b[36m███████████████████████████\u001b[0m| 200/200 [00:00<00:00, 901file/s]\u001b[0m\n",
            "\n",
            "    🚀 Batch Inference:   0%|\u001b[38;2;16;85;201m                                         \u001b[0m| 0.00/6.00 [00:00<?, ?pair/s]\u001b[0m\u001b[A\n",
            "    🚀 Batch Inference:  17%|\u001b[38;2;16;85;201m█████▋                            \u001b[0m| 1.00/6.00 [00:58<04:51, 58.3s/pair]\u001b[0m\u001b[A\n",
            "    🚀 Batch Inference:  50%|\u001b[38;2;16;85;201m█████████████████                 \u001b[0m| 3.00/6.00 [01:55<01:49, 36.3s/pair]\u001b[0m\u001b[A\n",
            "    🚀 Batch Inference:  83%|\u001b[38;2;16;85;201m████████████████████████████▎     \u001b[0m| 5.00/6.00 [02:53<00:32, 32.5s/pair]\u001b[0m\u001b[A\n",
            "    🚀 Batch Inference: 100%|\u001b[38;2;16;85;201m██████████████████████████████████\u001b[0m| 6.00/6.00 [03:50<00:00, 39.2s/pair]\u001b[0m\u001b[ATraceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/subprocess.py\", line 1264, in wait\n",
            "    return self._wait(timeout=timeout)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/subprocess.py\", line 2053, in _wait\n",
            "    (pid, sts) = self._try_wait(0)\n",
            "                 ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/subprocess.py\", line 2011, in _try_wait\n",
            "    (pid, sts) = os.waitpid(self.pid, wait_flags)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/accelerate_cli.py\", line 50, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/launch.py\", line 1281, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/launch.py\", line 866, in simple_launcher\n",
            "    process.wait()\n",
            "  File \"/usr/lib/python3.12/subprocess.py\", line 1277, in wait\n",
            "    self._wait(timeout=sigint_timeout)\n",
            "  File \"/usr/lib/python3.12/subprocess.py\", line 2047, in _wait\n",
            "    time.sleep(delay)\n",
            "KeyboardInterrupt\n",
            "    🚀 Batch Inference:  67%|\u001b[38;2;16;85;201m██████████████████████▋           \u001b[0m| 4.00/6.00 [04:13<02:06, 63.5s/pair]\u001b[0m\n",
            "🎨 Generating styles:  13%|████▋                              | 2.00/15.0 [16:32<1:47:29, 496s/pair]\n"
          ]
        }
      ],
      "execution_count": 13
    },
    {
      "id": "997103e5-221c-40a1-a0d1-83a93e1030f7",
      "cell_type": "code",
      "source": [
        "!find my_dataset/train_original/ContentImage -type f | wc -l\n",
        "!find my_dataset/train_original/TargetImage -type f | wc -l"
      ],
      "metadata": {
        "trusted": true,
        "id": "997103e5-221c-40a1-a0d1-83a93e1030f7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f9250a14",
      "cell_type": "code",
      "source": [
        "!python FontDiffusion/create_validation_split.py \\\n",
        "  --data_root my_dataset \\\n",
        "  --val_ratio 0.2 \\\n",
        "  --seed 42"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-01-02T04:39:25.243505Z",
          "iopub.status.busy": "2026-01-02T04:39:25.243143Z",
          "iopub.status.idle": "2026-01-02T04:39:27.551960Z",
          "shell.execute_reply": "2026-01-02T04:39:27.551218Z",
          "shell.execute_reply.started": "2026-01-02T04:39:25.243445Z"
        },
        "id": "f9250a14",
        "outputId": "1744310b-b55f-401c-8e0f-a50e5386bc28",
        "papermill": {
          "duration": 0.236541,
          "end_time": "2025-12-30T18:55:01.673705",
          "exception": false,
          "start_time": "2025-12-30T18:55:01.437164",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-02 07:25:02,544 | INFO | ✓ Using source directory: my_dataset/train_original\n",
            "2026-01-02 07:25:02,548 | INFO | \n",
            "============================================================\n",
            "2026-01-02 07:25:02,548 | INFO | FONTDIFFUSION VALIDATION SPLIT CREATOR\n",
            "2026-01-02 07:25:02,549 | INFO | ============================================================\n",
            "2026-01-02 07:25:02,549 | INFO | \n",
            "============================================================\n",
            "2026-01-02 07:25:02,549 | INFO | ANALYZING TRAINING DATA\n",
            "2026-01-02 07:25:02,549 | INFO | ============================================================\n",
            "2026-01-02 07:25:02,549 | INFO | \n",
            "🔍 Scanning content images...\n",
            "\rContent images:   0% 0/599 [00:00<?, ?img/s]\rContent images: 100% 599/599 [00:00<00:00, 1227951.17img/s]\n",
            "2026-01-02 07:25:02,552 | INFO |   ✓ Found 599 content images\n",
            "2026-01-02 07:25:02,553 | INFO | \n",
            "🔍 Scanning target images...\n",
            "\rStyles:   0% 0/15 [00:00<?, ?style/s]\rStyles: 100% 15/15 [00:00<00:00, 359.87style/s]\n",
            "2026-01-02 07:25:02,595 | INFO |   ✓ Found 8985 valid target images\n",
            "2026-01-02 07:25:02,595 | INFO | \n",
            "🔍 Validating content ↔ target pairs...\n",
            "\rValidating pairs:   0%|                                                  | 0/8985 [00:00<?, ?pair/s]\rValidating pairs: 100%|██████████████████████████████████| 8985/8985 [00:00<00:00, 2051822.37pair/s]\n",
            "2026-01-02 07:25:02,601 | INFO | ============================================================\n",
            "2026-01-02 07:25:02,602 | INFO | 📊 DATA ANALYSIS SUMMARY\n",
            "2026-01-02 07:25:02,602 | INFO | ============================================================\n",
            "2026-01-02 07:25:02,602 | INFO | Content images found:        599\n",
            "2026-01-02 07:25:02,602 | INFO | Target images scanned:       8,985\n",
            "2026-01-02 07:25:02,602 | INFO |   ├─ Parse errors:          0\n",
            "2026-01-02 07:25:02,602 | INFO |   └─ Style mismatches:      0\n",
            "2026-01-02 07:25:02,602 | INFO | Target images after filter:  8,985\n",
            "2026-01-02 07:25:02,602 | INFO | Missing content images:      0\n",
            "2026-01-02 07:25:02,602 | INFO | Final valid pairs:           8,985\n",
            "2026-01-02 07:25:02,602 | INFO | ============================================================\n",
            "2026-01-02 07:25:02,602 | INFO | \n",
            "============================================================\n",
            "2026-01-02 07:25:02,602 | INFO | CREATING TRAIN/VAL SPLITS (random char & style)\n",
            "2026-01-02 07:25:02,602 | INFO | ============================================================\n",
            "2026-01-02 07:25:02,604 | INFO | \n",
            "📊 Split Statistics:\n",
            "2026-01-02 07:25:02,604 | INFO |   Total chars: 599 → train: 480, val: 119\n",
            "2026-01-02 07:25:02,604 | INFO |   Total styles: 15 → train: 12, val: 3\n",
            "2026-01-02 07:25:02,604 | INFO |   train:\n",
            "2026-01-02 07:25:02,604 | INFO |     Chars: 480\n",
            "2026-01-02 07:25:02,604 | INFO |     Styles: 12\n",
            "2026-01-02 07:25:02,604 | INFO |   val:\n",
            "2026-01-02 07:25:02,604 | INFO |     Chars: 119\n",
            "2026-01-02 07:25:02,604 | INFO |     Styles: 3\n",
            "2026-01-02 07:25:02,604 | INFO | \n",
            "📁 CREATING TRAIN SPLIT...\n",
            "2026-01-02 07:25:02,605 | INFO |   📥 Copying content images for train...\n",
            "2026-01-02 07:25:02,699 | INFO |   📥 Copying target images for train...\n",
            "2026-01-02 07:25:04,070 | INFO |   ✓ train: 480 content, 5,760 target (skipped: 0)\n",
            "2026-01-02 07:25:04,070 | INFO |   📋 Filtering checkpoint for train...\n",
            "2026-01-02 07:25:04,162 | INFO |     ✓ Saved: 5,760/8,985 generations\n",
            "2026-01-02 07:25:04,164 | INFO | 📁 CREATING VAL SPLIT...\n",
            "2026-01-02 07:25:04,164 | INFO |   📥 Copying content images for val...\n",
            "2026-01-02 07:25:04,187 | INFO |   📥 Copying target images for val...\n",
            "2026-01-02 07:25:04,282 | INFO |   ✓ val: 119 content, 357 target (skipped: 0)\n",
            "2026-01-02 07:25:04,282 | INFO |   📋 Filtering checkpoint for val...\n",
            "2026-01-02 07:25:04,329 | INFO |     ✓ Saved: 357/8,985 generations\n",
            "2026-01-02 07:25:04,331 | INFO | ✓ Saved split metadata to my_dataset/split_info.json\n",
            "2026-01-02 07:25:04,332 | INFO | \n",
            "============================================================\n",
            "2026-01-02 07:25:04,332 | INFO | ✓ SPLIT CREATION COMPLETE\n",
            "2026-01-02 07:25:04,332 | INFO | ============================================================\n",
            "2026-01-02 07:25:04,332 | INFO | \n",
            "✅ Created:\n",
            "2026-01-02 07:25:04,332 | INFO |   📁 train/\n",
            "2026-01-02 07:25:04,332 | INFO |     ├── ContentImage/ (training chars)\n",
            "2026-01-02 07:25:04,332 | INFO |     ├── TargetImage/ (training styles)\n",
            "2026-01-02 07:25:04,332 | INFO |     └── results_checkpoint.json (filtered)\n",
            "2026-01-02 07:25:04,332 | INFO |   📁 val/\n",
            "2026-01-02 07:25:04,332 | INFO |     ├── ContentImage/ (validation chars)\n",
            "2026-01-02 07:25:04,333 | INFO |     ├── TargetImage/ (validation styles)\n",
            "2026-01-02 07:25:04,333 | INFO |     └── results_checkpoint.json (filtered)\n",
            "2026-01-02 07:25:04,333 | INFO | \n",
            "💡 Guarantees:\n",
            "2026-01-02 07:25:04,333 | INFO |   ✓ Every target has matching content\n",
            "2026-01-02 07:25:04,333 | INFO |   ✓ Checkpoint contains only relevant generations\n",
            "2026-01-02 07:25:04,333 | INFO |   ✓ Train and val are completely disjoint\n"
          ]
        }
      ],
      "execution_count": 12
    },
    {
      "id": "79508d80-fac1-4318-9174-a32613a557e3",
      "cell_type": "code",
      "source": [
        "!uv pip install --upgrade pyarrow datasets"
      ],
      "metadata": {
        "id": "79508d80-fac1-4318-9174-a32613a557e3",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "48f97e84-cd8c-49a9-86bd-fce456be56a4",
      "cell_type": "code",
      "source": [
        "# remove_unparseable_files.py\n",
        "\n",
        "with open(\"my_dataset/unparseable_files.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    paths = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "import os\n",
        "\n",
        "for path in paths:\n",
        "    try:\n",
        "        if os.path.exists(path):\n",
        "            os.remove(path)\n",
        "            print(f\"Deleted: {path}\")\n",
        "        else:\n",
        "            print(f\"Not found: {path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error deleting {path}: {e}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "48f97e84-cd8c-49a9-86bd-fce456be56a4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "vRL8QovYCvLY",
      "cell_type": "code",
      "source": [
        "HF_USERNAME = \"dzungpham\"\n",
        "!python FontDiffusion/create_hf_dataset.py \\\n",
        "  --data_dir \"my_dataset/train_original\" \\\n",
        "  --repo_id dzungpham/font-diffusion-generated-data \\\n",
        "  --split \"train_original\" \\\n",
        "  --token {HF_TOKEN}\n",
        "\n",
        "# Train Split\n",
        "!python FontDiffusion/create_hf_dataset.py \\\n",
        "  --data_dir \"my_dataset/train\" \\\n",
        "  --repo_id dzungpham/font-diffusion-generated-data \\\n",
        "  --split \"train\" \\\n",
        "  --token {HF_TOKEN}\n",
        "\n",
        "# Train Split\n",
        "!python FontDiffusion/create_hf_dataset.py \\\n",
        "  --data_dir \"my_dataset/val\" \\\n",
        "  --repo_id dzungpham/font-diffusion-generated-data \\\n",
        "  --split \"val\" \\\n",
        "  --token {HF_TOKEN}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-01-02T04:39:37.656640Z",
          "iopub.status.busy": "2026-01-02T04:39:37.656344Z",
          "iopub.status.idle": "2026-01-02T04:40:55.252069Z",
          "shell.execute_reply": "2026-01-02T04:40:55.251050Z",
          "shell.execute_reply.started": "2026-01-02T04:39:37.656615Z"
        },
        "id": "vRL8QovYCvLY",
        "outputId": "08301c52-4ae1-4268-c516-2ff8bd834783",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "FONTDIFFUSION DATASET CREATOR\n",
            "============================================================\n",
            "\n",
            "Data dir: my_dataset/train_original\n",
            "Repo: dzungpham/font-diffusion-generated-data\n",
            "Push to Hub: True\n",
            "✓ Validated directory structure\n",
            "  Content images: my_dataset/train_original/ContentImage\n",
            "  Target images: my_dataset/train_original/TargetImage\n",
            "  Results checkpoint: my_dataset/train_original/results_checkpoint.json\n",
            "\n",
            "============================================================\n",
            "BUILDING DATASET\n",
            "============================================================\n",
            "\n",
            "✓ Loaded results_checkpoint.json\n",
            "  Generations: 8985\n",
            "  Characters: 599\n",
            "  Styles: 15\n",
            "\n",
            "🖼️  Loading 8985 image pairs...\n",
            "Loading image pairs: 100%|██████████████| 8.98k/8.98k [00:07<00:00, 1.18kpair/s]\n",
            "✓ Loaded 8985 samples\n",
            "\n",
            "============================================================\n",
            "PUSHING TO HUB\n",
            "============================================================\n",
            "Repository: dzungpham/font-diffusion-generated-data\n",
            "Split: train_original\n",
            "Uploading the dataset shards:   0%|                  | 0/1 [00:00<?, ? shards/s]\n",
            "Map:   0%|                                      | 0/8985 [00:00<?, ? examples/s]\u001b[A\n",
            "Map:  73%|█████████████████▋      | 6601/8985 [00:00<00:00, 17523.15 examples/s]\u001b[A\n",
            "Map: 100%|████████████████████████| 8985/8985 [00:00<00:00, 15307.79 examples/s]\u001b[A\n",
            "\n",
            "Creating parquet from Arrow format:   0%|                 | 0/2 [00:00<?, ?ba/s]\u001b[A\n",
            "Creating parquet from Arrow format: 100%|█████████| 2/2 [00:00<00:00,  9.89ba/s]\u001b[A\n",
            "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.25s/ shards]\n",
            "\n",
            "✓ Successfully pushed to Hub!\n",
            "  URL: https://huggingface.co/datasets/dzungpham/font-diffusion-generated-data\n",
            "\n",
            "✅ COMPLETE!\n",
            "\n",
            "============================================================\n",
            "FONTDIFFUSION DATASET CREATOR\n",
            "============================================================\n",
            "\n",
            "Data dir: my_dataset/train\n",
            "Repo: dzungpham/font-diffusion-generated-data\n",
            "Push to Hub: True\n",
            "✓ Validated directory structure\n",
            "  Content images: my_dataset/train/ContentImage\n",
            "  Target images: my_dataset/train/TargetImage\n",
            "  Results checkpoint: my_dataset/train/results_checkpoint.json\n",
            "\n",
            "============================================================\n",
            "BUILDING DATASET\n",
            "============================================================\n",
            "\n",
            "✓ Loaded results_checkpoint.json\n",
            "  Generations: 5760\n",
            "  Characters: 480\n",
            "  Styles: 12\n",
            "\n",
            "🖼️  Loading 5760 image pairs...\n",
            "Loading image pairs: 100%|██████████████| 5.76k/5.76k [00:04<00:00, 1.16kpair/s]\n",
            "✓ Loaded 5760 samples\n",
            "\n",
            "============================================================\n",
            "PUSHING TO HUB\n",
            "============================================================\n",
            "Repository: dzungpham/font-diffusion-generated-data\n",
            "Split: train\n",
            "Uploading the dataset shards:   0%|                  | 0/1 [00:00<?, ? shards/s]\n",
            "Map:   0%|                                      | 0/5760 [00:00<?, ? examples/s]\u001b[A\n",
            "Map: 100%|████████████████████████| 5760/5760 [00:00<00:00, 14851.57 examples/s]\u001b[A\n",
            "\n",
            "Creating parquet from Arrow format:   0%|                 | 0/1 [00:00<?, ?ba/s]\u001b[A\n",
            "Creating parquet from Arrow format: 100%|█████████| 1/1 [00:00<00:00,  6.85ba/s]\u001b[A\n",
            "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.09 shards/s]\n",
            "README.md: 3.05kB [00:00, 12.0MB/s]\n",
            "\n",
            "✓ Successfully pushed to Hub!\n",
            "  URL: https://huggingface.co/datasets/dzungpham/font-diffusion-generated-data\n",
            "\n",
            "✅ COMPLETE!\n",
            "\n",
            "============================================================\n",
            "FONTDIFFUSION DATASET CREATOR\n",
            "============================================================\n",
            "\n",
            "Data dir: my_dataset/val\n",
            "Repo: dzungpham/font-diffusion-generated-data\n",
            "Push to Hub: True\n",
            "✓ Validated directory structure\n",
            "  Content images: my_dataset/val/ContentImage\n",
            "  Target images: my_dataset/val/TargetImage\n",
            "  Results checkpoint: my_dataset/val/results_checkpoint.json\n",
            "\n",
            "============================================================\n",
            "BUILDING DATASET\n",
            "============================================================\n",
            "\n",
            "✓ Loaded results_checkpoint.json\n",
            "  Generations: 357\n",
            "  Characters: 119\n",
            "  Styles: 3\n",
            "\n",
            "🖼️  Loading 357 image pairs...\n",
            "Loading image pairs: 100%|██████████████████| 357/357 [00:00<00:00, 1.20kpair/s]\n",
            "✓ Loaded 357 samples\n",
            "\n",
            "============================================================\n",
            "PUSHING TO HUB\n",
            "============================================================\n",
            "Repository: dzungpham/font-diffusion-generated-data\n",
            "Split: val\n",
            "Uploading the dataset shards:   0%|                  | 0/1 [00:00<?, ? shards/s]\n",
            "Map: 100%|██████████████████████████| 357/357 [00:00<00:00, 19035.45 examples/s]\u001b[A\n",
            "\n",
            "Creating parquet from Arrow format: 100%|█████████| 1/1 [00:00<00:00, 80.84ba/s]\u001b[A\n",
            "Uploading the dataset shards: 100%|██████████| 1/1 [00:11<00:00, 11.31s/ shards]\n",
            "README.md: 3.05kB [00:00, 13.0MB/s]\n",
            "\n",
            "✓ Successfully pushed to Hub!\n",
            "  URL: https://huggingface.co/datasets/dzungpham/font-diffusion-generated-data\n",
            "\n",
            "✅ COMPLETE!\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "id": "a87caab2",
      "cell_type": "code",
      "source": [
        "import torch, gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "a87caab2",
        "papermill": {
          "duration": 1.992585,
          "end_time": "2025-12-30T18:55:24.769269",
          "exception": false,
          "start_time": "2025-12-30T18:55:22.776684",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "267634e8",
      "cell_type": "code",
      "source": [
        "# TRAINING PHASE 1\n",
        "if is_colab:\n",
        "  !uv pip install --upgrade \"huggingface-hub>=0.34.0,<1.0\"\n",
        "else:\n",
        "  !uv pip install --upgrade \"huggingface-hub==0.25.2\"\n",
        "import wandb\n",
        "\n",
        "MAX_TRAIN_STEPS = 1000 # @param {type:\"integer\"}\n",
        "!accelerate launch FontDiffusion/train.py \\\n",
        "    --seed=123 \\\n",
        "    --experience_name=\"FontDiffuser_training_phase_1\" \\\n",
        "    --data_root=\"my_dataset\" \\\n",
        "    --output_dir=\"outputs/FontDiffuser\" \\\n",
        "    --report_to=\"wandb\" \\\n",
        "      \\\n",
        "    --resolution=96 \\\n",
        "    --style_image_size=96 \\\n",
        "    --content_image_size=96 \\\n",
        "    --content_encoder_downsample_size=3 \\\n",
        "    --channel_attn=True \\\n",
        "    --content_start_channel=64 \\\n",
        "    --style_start_channel=64 \\\n",
        "      \\\n",
        "    --train_batch_size=8 \\\n",
        "    --gradient_accumulation_steps=2 \\\n",
        "    --perceptual_coefficient=0.05 \\\n",
        "    --offset_coefficient=0.7 \\\n",
        "    --max_train_steps=${MAX_TRAIN_STEPS} \\\n",
        "    --ckpt_interval=${MAX_TRAIN_STEPS // 2} \\\n",
        "    --log_interval=50 \\\n",
        "      \\\n",
        "    --learning_rate=1e-4 \\\n",
        "    --lr_scheduler=\"linear\" \\\n",
        "    --lr_warmup_steps=10000 \\\n",
        "    --drop_prob=0.1 \\\n",
        "    --mixed_precision=\"no\""
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-02T04:43:59.401482Z",
          "iopub.status.busy": "2026-01-02T04:43:59.401134Z",
          "iopub.status.idle": "2026-01-02T04:47:50.896613Z",
          "shell.execute_reply": "2026-01-02T04:47:50.895674Z",
          "shell.execute_reply.started": "2026-01-02T04:43:59.401454Z"
        },
        "id": "267634e8",
        "papermill": {
          "duration": 0.021927,
          "end_time": "2025-12-30T18:55:24.807644",
          "exception": false,
          "start_time": "2025-12-30T18:55:24.785717",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "outputId": "26188cb4-f4c1-476c-8d43-7f284c6a98dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m12 packages\u001b[0m \u001b[2min 78ms\u001b[0m\u001b[0m                                         \u001b[0m\n",
            "\u001b[2mAudited \u001b[1m12 packages\u001b[0m \u001b[2min 0.12ms\u001b[0m\u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `2`\n",
            "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
            "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "2026-01-02 04:44:09.202585: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2026-01-02 04:44:09.202600: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767329049.225566    1532 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767329049.225569    1531 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767329049.233230    1531 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "E0000 00:00:1767329049.233268    1532 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "pygame 2.6.1 (SDL 2.28.4, Python 3.11.13)pygame 2.6.1 (SDL 2.28.4, Python 3.11.13)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
            "\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
            "Load the down block  DownBlock2D\n",
            "Load the down block  DownBlock2D\n",
            "Load the down block  MCADownBlock2D\n",
            "Load the down block  MCADownBlock2D\n",
            "The style_attention cross attention dim in Down Block 1 layer is 1024\n",
            "The style_attention cross attention dim in Down Block 1 layer is 1024\n",
            "The style_attention cross attention dim in Down Block 2 layer is 1024\n",
            "The style_attention cross attention dim in Down Block 2 layer is 1024\n",
            "Load the down block  MCADownBlock2D\n",
            "Load the down block  MCADownBlock2D\n",
            "The style_attention cross attention dim in Down Block 1 layer is 1024\n",
            "The style_attention cross attention dim in Down Block 1 layer is 1024\n",
            "The style_attention cross attention dim in Down Block 2 layer is 1024\n",
            "The style_attention cross attention dim in Down Block 2 layer is 1024\n",
            "Load the down block  DownBlock2D\n",
            "Load the down block  DownBlock2D\n",
            "Load the up block  UpBlock2D\n",
            "Load the up block  UpBlock2D\n",
            "Load the up block  StyleRSIUpBlock2D\n",
            "Load the up block  StyleRSIUpBlock2D\n",
            "Load the up block  StyleRSIUpBlock2D\n",
            "Load the up block  UpBlock2D\n",
            "Load the up block  StyleRSIUpBlock2D\n",
            "Load the up block  UpBlock2D\n",
            "Param count for Ds initialized parameters: 20591296\n",
            "Get CG-GAN Style Encoder!\n",
            "Param count for Ds initialized parameters: 1187008\n",
            "Get CG-GAN Content Encoder!\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Param count for Ds initialized parameters: 20591296\n",
            "Get CG-GAN Style Encoder!\n",
            "Param count for Ds initialized parameters: 1187008\n",
            "Get CG-GAN Content Encoder!\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdungngocpham171\u001b[0m (\u001b[33mdungngocpham171-university-of-science\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20260102_044419-e28gq05h\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdandy-butterfly-21\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dungngocpham171-university-of-science/FontDiffuser_training_phase_1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/dungngocpham171-university-of-science/FontDiffuser_training_phase_1/runs/e28gq05h\u001b[0m\n",
            "Steps:   0%|                                            | 0/200 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/diffusers/configuration_utils.py:134: FutureWarning: Accessing config attribute `num_train_timesteps` directly via 'DDPMScheduler' object attribute is deprecated. Please access 'num_train_timesteps' over 'DDPMScheduler's config object instead, e.g. 'scheduler.config.num_train_timesteps'.\n",
            "  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/configuration_utils.py:134: FutureWarning: Accessing config attribute `num_train_timesteps` directly via 'DDPMScheduler' object attribute is deprecated. Please access 'num_train_timesteps' over 'DDPMScheduler's config object instead, e.g. 'scheduler.config.num_train_timesteps'.\n",
            "  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n",
            "/kaggle/working/FontDiffusion/src/model.py:34: FutureWarning: Accessing config attribute `style_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'style_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.style_encoder'.\n",
            "  style_img_feature, _, _ = self.style_encoder(style_images)\n",
            "/kaggle/working/FontDiffusion/src/model.py:34: FutureWarning: Accessing config attribute `style_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'style_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.style_encoder'.\n",
            "  style_img_feature, _, _ = self.style_encoder(style_images)\n",
            "/kaggle/working/FontDiffusion/src/model.py:42: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.content_encoder'.\n",
            "  content_img_feature, content_residual_features = self.content_encoder(\n",
            "/kaggle/working/FontDiffusion/src/model.py:42: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.content_encoder'.\n",
            "  content_img_feature, content_residual_features = self.content_encoder(\n",
            "/kaggle/working/FontDiffusion/src/model.py:47: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.content_encoder'.\n",
            "  style_content_feature, style_content_res_features = self.content_encoder(\n",
            "/kaggle/working/FontDiffusion/src/model.py:47: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.content_encoder'.\n",
            "  style_content_feature, style_content_res_features = self.content_encoder(\n",
            "/kaggle/working/FontDiffusion/src/model.py:59: FutureWarning: Accessing config attribute `unet` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'unet' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.unet'.\n",
            "  out = self.unet(\n",
            "/kaggle/working/FontDiffusion/src/model.py:59: FutureWarning: Accessing config attribute `unet` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'unet' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.unet'.\n",
            "  out = self.unet(\n",
            "Steps:   0%|                       | 0/200 [00:01<?, ?it/s, lr=0, step_loss=5.7]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:841: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\n",
            "grad.sizes() = [128, 128, 1, 1], strides() = [128, 1, 128, 128]\n",
            "bucket_view.sizes() = [128, 128, 1, 1], strides() = [128, 1, 1, 1] (Triggered internally at /pytorch/torch/csrc/distributed/c10d/reducer.cpp:334.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:841: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\n",
            "grad.sizes() = [128, 128, 1, 1], strides() = [128, 1, 128, 128]\n",
            "bucket_view.sizes() = [128, 128, 1, 1], strides() = [128, 1, 1, 1] (Triggered internally at /pytorch/torch/csrc/distributed/c10d/reducer.cpp:334.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "Steps:  50%|███▌   | 100/200 [03:23<03:38,  2.19s/it, lr=9.9e-7, step_loss=4.36]Traceback (most recent call last):\n",
            "  File \"/kaggle/working/FontDiffusion/train.py\", line 348, in <module>\n",
            "    main()\n",
            "  File \"/kaggle/working/FontDiffusion/train.py\", line 313, in main\n",
            "    torch.save(model.unet.state_dict(), f\"{save_dir}/unet.pth\")\n",
            "               ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1964, in __getattr__\n",
            "    raise AttributeError(\n",
            "AttributeError: 'DistributedDataParallel' object has no attribute 'unet'\n",
            "[rank0]: Traceback (most recent call last):\n",
            "[rank0]:   File \"/kaggle/working/FontDiffusion/train.py\", line 348, in <module>\n",
            "[rank0]:     main()\n",
            "[rank0]:   File \"/kaggle/working/FontDiffusion/train.py\", line 313, in main\n",
            "[rank0]:     torch.save(model.unet.state_dict(), f\"{save_dir}/unet.pth\")\n",
            "[rank0]:                ^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1964, in __getattr__\n",
            "[rank0]:     raise AttributeError(\n",
            "[rank0]: AttributeError: 'DistributedDataParallel' object has no attribute 'unet'\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mdandy-butterfly-21\u001b[0m at: \u001b[34mhttps://wandb.ai/dungngocpham171-university-of-science/FontDiffuser_training_phase_1/runs/e28gq05h\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20260102_044419-e28gq05h/logs\u001b[0m\n",
            "W0102 04:47:49.693000 1523 torch/distributed/elastic/multiprocessing/api.py:908] Sending process 1532 closing signal SIGTERM\n",
            "E0102 04:47:49.907000 1523 torch/distributed/elastic/multiprocessing/api.py:882] failed (exitcode: 1) local_rank: 0 (pid: 1531) of binary: /usr/bin/python3\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 47, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 977, in launch_command\n",
            "    multi_gpu_launcher(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 646, in multi_gpu_launcher\n",
            "    distrib_run.run(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/run.py\", line 927, in run\n",
            "    elastic_launch(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 156, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 293, in launch_agent\n",
            "    raise ChildFailedError(\n",
            "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
            "============================================================\n",
            "FontDiffusion/train.py FAILED\n",
            "------------------------------------------------------------\n",
            "Failures:\n",
            "  <NO_OTHER_FAILURES>\n",
            "------------------------------------------------------------\n",
            "Root Cause (first observed failure):\n",
            "[0]:\n",
            "  time      : 2026-01-02_04:47:49\n",
            "  host      : 0e1df859923c\n",
            "  rank      : 0 (local_rank: 0)\n",
            "  exitcode  : 1 (pid: 1531)\n",
            "  error_file: <N/A>\n",
            "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
            "============================================================\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "id": "cb2a3326-6bfa-4fba-bbcc-e2e7be996c7f",
      "cell_type": "code",
      "source": [
        "!ls -lr outputs/FontDiffuser"
      ],
      "metadata": {
        "id": "cb2a3326-6bfa-4fba-bbcc-e2e7be996c7f",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "97f8136e",
      "cell_type": "code",
      "source": [
        "# TRAINING PHASE 2\n",
        "!wandb login\n",
        "\n",
        "MAX_TRAIN_STEPS = 1000 # @param {type:\"integer\"}\n",
        "!python FontDiffusion/my_train.py \\\n",
        "    --seed=123 \\\n",
        "    --experience_name=\"FontDiffuser_training_phase_2\" \\\n",
        "    --data_root=\"my_dataset\" \\\n",
        "    --output_dir=\"outputs/FontDiffuser\" \\\n",
        "    --report_to=\"wandb\" \\\n",
        "    --phase_2 \\\n",
        "    --phase_1_ckpt_dir=\"outputs/FontDiffuser/global_step_2000\" \\\n",
        "    --scr_ckpt_path=\"ckpt/scr_210000.pth\" \\\n",
        "    \\\n",
        "    --sc_coefficient=0.05 \\\n",
        "    --num_neg=13 \\\n",
        "    --resolution=96 \\\n",
        "    --style_image_size=96 \\\n",
        "    --content_image_size=96 \\\n",
        "    --content_encoder_downsample_size=3 \\\n",
        "    --channel_attn=True \\\n",
        "    --content_start_channel=64 \\\n",
        "    --style_start_channel=64 \\\n",
        "    \\\n",
        "    --train_batch_size=8 \\\n",
        "    --gradient_accumulation_steps=2 \\\n",
        "    --perceptual_coefficient=0.05 \\\n",
        "    --offset_coefficient=0.7 \\\n",
        "    --max_train_steps=${MAX_TRAIN_STEPS} \\\n",
        "    --ckpt_interval=${MAX_TRAIN_STEPS // 2} \\\n",
        "    --log_interval=50 \\\n",
        "    \\\n",
        "    --learning_rate=1e-5 \\\n",
        "    --lr_scheduler=\"constant\" \\\n",
        "    --lr_warmup_steps=1000 \\\n",
        "    --drop_prob=0.1 \\\n",
        "    --mixed_precision=\"no\"\n"
      ],
      "metadata": {
        "id": "97f8136e",
        "papermill": {
          "duration": 0.022471,
          "end_time": "2025-12-30T18:55:24.845778",
          "exception": false,
          "start_time": "2025-12-30T18:55:24.823307",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "88c45e2f",
      "cell_type": "code",
      "source": [
        "!python FontDiffusion/upload_models.py \\\n",
        "    --weights_dir \"outputs/FontDiffuser\" \\\n",
        "    --repo_id \"dzungpham/font-diffusion-weights\" \\\n",
        "    --token \"{HF_TOKEN}\""
      ],
      "metadata": {
        "id": "88c45e2f",
        "papermill": {
          "duration": 0.217876,
          "end_time": "2025-12-30T18:55:25.079820",
          "exception": false,
          "start_time": "2025-12-30T18:55:24.861944",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5868b20b",
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "def find_result_folders(base_path: Path, pattern_name: str) -> List[Path]:\n",
        "    return [p for p in base_path.glob(pattern_name) if p.is_dir()]\n",
        "\n",
        "def zip_folder(folder_path: Path, output_base_path: Path) -> bool:\n",
        "    folder_name = folder_path.name\n",
        "    zip_path = output_base_path / f\"{folder_name}.zip\"\n",
        "    try:\n",
        "        print(f\"   -> Zipping folder: {folder_name}...\")\n",
        "        with zipfile.ZipFile(zip_path, mode=\"w\", compression=zipfile.ZIP_DEFLATED) as zipf:\n",
        "            for file_path in folder_path.rglob(\"*\"):\n",
        "                if file_path.is_file():\n",
        "                    arcname = file_path.relative_to(folder_path.parent)\n",
        "                    zipf.write(file_path, arcname)\n",
        "        print(f\"   ✅ Created ZIP: {zip_path.name}\")\n",
        "        return True\n",
        "    except Exception as exc:\n",
        "        print(f\"   ❌ Failed to zip {folder_name}: {exc}\")\n",
        "        return False\n",
        "\n",
        "def zip_stats_results_folders(output_base_path: str, pattern_name: str) -> None:\n",
        "    base = Path(output_base_path)\n",
        "    base.mkdir(parents=True, exist_ok=True)\n",
        "    result_folders = find_result_folders(base, pattern_name)\n",
        "    if not result_folders:\n",
        "        print(f\"⚠️ No folders matching '*dataset' found in '{output_base_path}'.\")\n",
        "        return\n",
        "    print(f\"🔍 Found {len(result_folders)} result folder(s) to zip.\")\n",
        "    successful = sum(1 for folder in result_folders if zip_folder(folder, base))\n",
        "    print(f\"\\n✅ DONE! Successfully zipped {successful} out of {len(result_folders)} folder(s).\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        output_root = os.getenv(\"OUTPUT_PATH\") or globals().get(\"OUTPUT_PATH\")\n",
        "        if not output_root:\n",
        "            raise ValueError(\"OUTPUT_PATH not defined\")\n",
        "        zip_stats_results_folders(\n",
        "            output_base_path=OUTPUT_PATH,\n",
        "            pattern_name=\"my_dataset\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ An error occurred: {e}\")"
      ],
      "metadata": {
        "id": "5868b20b",
        "papermill": {
          "duration": 0.031197,
          "end_time": "2025-12-30T18:55:25.126961",
          "exception": false,
          "start_time": "2025-12-30T18:55:25.095764",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}