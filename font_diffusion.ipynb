{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":127.636509,"end_time":"2025-12-30T18:55:25.961447","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-12-30T18:53:18.324938","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"a95a46ef","cell_type":"code","source":"# @title Environment Setup\nimport os\nimport sys\nif 'MPLBACKEND' in os.environ:\n    del os.environ['MPLBACKEND']\n    print(\"MPLBACKEND environment variable cleared.\")\n\n# 2. Clone the repository\n!rm -rf FontDiffusion\n!git clone https://github.com/dzungphieuluuky/FontDiffusion.git","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a95a46ef","outputId":"cff4e0e2-72bb-4edf-d4ea-db85b209ab7c","papermill":{"duration":12.857369,"end_time":"2025-12-30T18:53:35.066181","exception":false,"start_time":"2025-12-30T18:53:22.208812","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T17:03:50.084511Z","iopub.execute_input":"2026-01-02T17:03:50.085503Z","iopub.status.idle":"2026-01-02T17:04:02.387295Z","shell.execute_reply.started":"2026-01-02T17:03:50.085464Z","shell.execute_reply":"2026-01-02T17:04:02.386424Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'FontDiffusion'...\nremote: Enumerating objects: 20734, done.\u001b[K\nremote: Counting objects: 100% (87/87), done.\u001b[K\nremote: Compressing objects: 100% (60/60), done.\u001b[K\nremote: Total 20734 (delta 48), reused 58 (delta 27), pack-reused 20647 (from 2)\u001b[K\nReceiving objects: 100% (20734/20734), 278.11 MiB | 36.04 MiB/s, done.\nResolving deltas: 100% (1044/1044), done.\nUpdating files: 100% (138/138), done.\n","output_type":"stream"}],"execution_count":51},{"id":"9cdd8666","cell_type":"code","source":"import os\nimport sys\nfrom IPython import get_ipython\nfrom typing import Optional\n\ndef configure_environment_paths():\n    try:\n        if \"google.colab\" in str(get_ipython()):\n            print(\"âœ… Environment: Google Colab\")\n            base_data_path = \"/content/\"\n            base_output_path = \"/content/\"\n            environment_name = \"colab\"\n        elif os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\"):\n            print(\"âœ… Environment: Kaggle\")\n            base_data_path = \"/kaggle/input/\"\n            base_output_path = \"/kaggle/working/\"\n            environment_name = \"kaggle\"\n        else:\n            print(\"âš ï¸ Environment: Local/Unknown\")\n            base_data_path = \"./data/\"\n            base_output_path = \"./output/\"\n            environment_name = \"local\"\n    except NameError:\n        print(\"âš ï¸ Non-interactive session. Using local paths.\")\n        base_data_path = \"./data/\"\n        base_output_path = \"./output/\"\n        environment_name = \"local\"\n    os.makedirs(base_output_path, exist_ok=True)\n    print(f\"ðŸ“‚ Data Path: {base_data_path}\")\n    print(f\"ðŸ“¦ Output Path: {base_output_path}\")\n    return base_data_path, base_output_path, environment_name\n\ndef load_secret(key_name: str) -> Optional[str]:\n    env = ENV_NAME\n    secret_value = None\n    print(f\"Attempting to load secret '{key_name}' from '{env}' environment...\")\n    try:\n        if env == \"colab\":\n            from google.colab import userdata\n            secret_value = userdata.get(key_name)\n        elif env == \"kaggle\":\n            from kaggle_secrets import UserSecretsClient\n            user_secrets = UserSecretsClient()\n            secret_value = user_secrets.get_secret(key_name)\n        else:\n            secret_value = os.getenv(key_name)\n        if not secret_value:\n            print(f\"âš ï¸ Secret '{key_name}' not found in the {env} environment.\")\n            return None\n        print(f\"âœ… Successfully loaded secret '{key_name}'.\")\n        return secret_value\n    except Exception as e:\n        print(f\"âŒ An error occurred while loading secret '{key_name}': {e}\")\n        return None\n\ndef print_system_info():\n    print(\"\\nðŸ”§ System Information\")\n    print(f\"Python version: {sys.version.split()[0]}\")\n    try:\n        import torch\n        print(f\"PyTorch version: {torch.__version__}\")\n        if torch.cuda.is_available():\n            print(f\"CUDA version: {torch.version.cuda}\")\n            print(f\"GPU count: {torch.cuda.device_count()}\")\n            for i in range(torch.cuda.device_count()):\n                print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n        else:\n            print(\"CUDA not available\")\n    except ImportError:\n        print(\"PyTorch not installed\")\n    finally:\n      !nvidia-smi\n\nINPUT_PATH, OUTPUT_PATH, ENV_NAME = configure_environment_paths()\nis_kaggle = (\"kaggle\" in ENV_NAME)\nis_colab = not is_kaggle\nprint_system_info()\n\nos.environ[\"WANDB_API_KEY\"] = wandb_key = load_secret(\"WANDB_API_KEY\")\nos.environ[\"HF_TOKEN\"] = HF_TOKEN = load_secret('HF_TOKEN')\nos.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n\n# Now, these libraries will log in automatically\nimport wandb\nimport huggingface_hub\n\nwandb.login()\nhuggingface_hub.login(token=os.environ[\"HF_TOKEN\"])","metadata":{"id":"9cdd8666","papermill":{"duration":0.019157,"end_time":"2025-12-30T18:53:35.092303","exception":false,"start_time":"2025-12-30T18:53:35.073146","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"a73b4150","cell_type":"code","source":"!uv pip install --upgrade pip\n# 3. Install PyTorch 1.13\n%cd {OUTPUT_PATH}\n# Force reinstall torch 1.13 to match the model's training environment\n# !uv pip uninstall torch torchvision\n# !uv pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 --extra-index-url https://download.pytorch.org/whl/cu117\n!uv pip install torch==2.9 torchvision\n# 4. Install other dependencies\n\nprint(\"\\nâ¬‡ï¸ Installing Dependencies (Manually fixed)...\")\n# Install xformers compatible with Torch 1.13\n!uv pip install xformers==0.0.16 -q\n\n# Install original dependencies\n!uv pip install transformers==4.33.1 accelerate==0.23.0 diffusers==0.22.0\n!uv pip install gradio==4.8.0 pyyaml pygame opencv-python info-nce-pytorch kornia\n# -----------------------------------------------------------------\n!uv pip install lpips scikit-image pytorch-fid\n# !sudo apt-get update && sudo apt-get install dos2unix\n!uv pip install gdown tqdm\n!uv pip install wandb hf_transfer\n!uv pip install --upgrade pyarrow datasets\nprint(\"\\nâœ… Environment setup complete. You can now proceed to Block 2 (Inference).\")","metadata":{"id":"a73b4150","papermill":{"duration":61.239828,"end_time":"2025-12-30T18:54:36.338205","exception":false,"start_time":"2025-12-30T18:53:35.098377","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"bd517dfe","cell_type":"code","source":"# KAGGLE CELL #1: Download checkpoint\nif is_colab:\n  !uv pip install --upgrade \"huggingface-hub>=0.34.0,<1.0\"\nelse:\n  !uv pip install --upgrade \"huggingface-hub==0.25.2\" \"protobuf<5.0.0\" \"numpy<2.0.0\"\nimport os\nimport sys\nfrom tqdm.auto import tqdm\nfrom pathlib import Path\nos.chdir(OUTPUT_PATH)\nimport os\nfrom pathlib import Path\ndef download_from_hf(\n    repo_id: str,\n    local_dir: str = \"ckpt\",\n    allow_patterns=None,\n    force_download: bool = False,\n    repo_type: str = \"model\"\n):\n    if allow_patterns is None:\n        allow_patterns = [\"*.safetensors\", \"scr*\"]\n    print(f\"ðŸ“¥ Downloading checkpoint from Hugging Face Hub to '{local_dir}'...\\n\")\n    from huggingface_hub import snapshot_download\n    snapshot_download(\n        repo_id=repo_id,\n        local_dir=local_dir,\n        repo_type=repo_type,\n        allow_patterns=allow_patterns,\n        force_download=force_download\n    )\n    print(\"\\nâœ… Download complete!\")\n    print(f\"\\nðŸ“‚ Files in {local_dir}/:\")\n    for file in os.listdir(local_dir):\n        if file.endswith(\".safetensors\"):\n            size = os.path.getsize(os.path.join(local_dir, file)) / (1024**2)\n            print(f\"  âœ“ {file} ({size:.2f} MB)\")","metadata":{"id":"bd517dfe","papermill":{"duration":12.524295,"end_time":"2025-12-30T18:54:48.878013","exception":false,"start_time":"2025-12-30T18:54:36.353718","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"tOpa7Bh8leVB","cell_type":"code","source":"download_from_hf(\n    repo_id=\"dzungpham/font-diffusion-weights\",\n    local_dir=\"ckpt\",\n    allow_patterns=[\"*.safetensors\", \"scr*\"]\n)","metadata":{"id":"tOpa7Bh8leVB","trusted":true},"outputs":[],"execution_count":null},{"id":"Jc4jsIvvlg7T","cell_type":"code","source":"download_from_hf(\n    repo_id=\"dzungpham/font-diffusion-generated-data\",\n    local_dir=\"NomTuTao\",\n    repo_type=\"dataset\",\n    allow_patterns=[\"*Nom*\"]\n)","metadata":{"id":"Jc4jsIvvlg7T","trusted":true},"outputs":[],"execution_count":null},{"id":"767e8ea2","cell_type":"code","source":"# @title Unzipping all archived files\nimport os\nimport glob\nfrom zipfile import ZipFile\n\nzip_file_paths = glob.glob(os.path.join(INPUT_PATH, '*.zip'))\n\nif not zip_file_paths:\n    print(f'No .zip files found in {INPUT_PATH}.')\nelse:\n    for zip_file_path in zip_file_paths:\n        if os.path.exists(zip_file_path):\n            print(f'Unzipping {zip_file_path}...')\n            !unzip -o {zip_file_path} -d ./\n            print(f'Unzipping of {zip_file_path} complete.')\n        else:\n            print(f'Error: The file {zip_file_path} was not found (post-glob check).')","metadata":{"id":"767e8ea2","papermill":{"duration":0.023805,"end_time":"2025-12-30T18:54:48.917163","exception":false,"start_time":"2025-12-30T18:54:48.893358","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"4f4cf20b","cell_type":"code","source":"print(\"Model files:\")\n!ls -larth {OUTPUT_PATH}/ckpt","metadata":{"id":"4f4cf20b","papermill":{"duration":0.140282,"end_time":"2025-12-30T18:54:50.749810","exception":false,"start_time":"2025-12-30T18:54:50.609528","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"92cff682","cell_type":"code","source":"# @title Exporting train original data from HF\n%cd {OUTPUT_PATH}\nHF_USERNAME = \"dzungpham\"\n# Train Split\n!python FontDiffusion/export_hf_dataset_to_disk.py \\\n  --output-dir \"my_dataset/train_original\" \\\n  --repo-id {HF_USERNAME}/font-diffusion-generated-data \\\n  --split \"train_original\" \\\n  --token HF_TOKEN","metadata":{"id":"92cff682","papermill":{"duration":0.104394,"end_time":"2025-12-30T18:54:50.869230","exception":false,"start_time":"2025-12-30T18:54:50.764836","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"lh696hc0l1jr","cell_type":"code","source":"# @title Exporting train data from HF\n!python FontDiffusion/export_hf_dataset_to_disk.py \\\n  --output-dir \"my_dataset/train\" \\\n  --repo-id {HF_USERNAME}/font-diffusion-generated-data \\\n  --split \"train\" \\\n  --token HF_TOKEN","metadata":{"id":"lh696hc0l1jr","trusted":true},"outputs":[],"execution_count":null},{"id":"rzW-I7QMl2ik","cell_type":"code","source":"# @title Exporting validation data from HF\n!python FontDiffusion/export_hf_dataset_to_disk.py \\\n  --output-dir \"my_dataset/val\" \\\n  --repo-id {HF_USERNAME}/font-diffusion-generated-data \\\n  --split \"val\" \\\n  --token HF_TOKEN","metadata":{"id":"rzW-I7QMl2ik","trusted":true},"outputs":[],"execution_count":null},{"id":"6db9c1d6-dd60-479c-92c4-2f653e4d48fd","cell_type":"code","source":"# @title Show fonts and styles images\nprint(\"Fonts currently in fonts/ folder\")\n!ls -lt FontDiffusion/fonts\nprint(\"Styles in style_images/ folder\")\n!ls -l FontDiffusion/styles_images","metadata":{"trusted":true,"id":"6db9c1d6-dd60-479c-92c4-2f653e4d48fd"},"outputs":[],"execution_count":null},{"id":"29deed1d","cell_type":"code","source":"# @title Run batch generation\nif is_colab:\n  !uv pip install --upgrade \"huggingface-hub>=0.34.0,<1.0\"\nelse:\n  !uv pip install --upgrade \"huggingface-hub==0.25.2\" \"protobuf<5.0.0\" \"numpy<2.0.0\"\n%cd {OUTPUT_PATH}\n!accelerate launch --mixed_precision fp16 --dynamo_backend inductor \\\n        FontDiffusion/sample_batch_multi_gpus.py \\\n    --characters \"NomTuTao/Ds_10k_ChuNom_TuTao.txt\" \\\n    --style_images \"FontDiffusion/styles_images\" \\\n    --ckpt_dir \"ckpt/\" \\\n    --ttf_path \"FontDiffusion/fonts/NomNaTong-Regular.otf\" \\\n    --output_dir \"my_dataset/train_original\" \\\n    --num_inference_steps 20 \\\n    --guidance_scale 7.5 \\\n    --start_line 720 \\\n    --end_line 730 \\\n    --batch_size 35 \\\n    --save_interval 1 \\\n    --channels_last \\\n    --seed 42 \\\n    --compile \\\n    --enable_xformers","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"29deed1d","outputId":"4cc51007-a743-4bd4-a6b8-be90f0d6f4ff","papermill":{"duration":10.53661,"end_time":"2025-12-30T18:55:01.421093","exception":false,"start_time":"2025-12-30T18:54:50.884483","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T17:04:20.366461Z","iopub.execute_input":"2026-01-02T17:04:20.367258Z","iopub.status.idle":"2026-01-02T17:12:49.453271Z","shell.execute_reply.started":"2026-01-02T17:04:20.367218Z","shell.execute_reply":"2026-01-02T17:12:49.452394Z"}},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m14 packages\u001b[0m \u001b[2min 90ms\u001b[0m\u001b[0m                                         \u001b[0m\n\u001b[2mAudited \u001b[1m14 packages\u001b[0m \u001b[2min 0.17ms\u001b[0m\u001b[0m\n/kaggle/working\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\nThe following values were not passed to `accelerate launch` and had defaults used instead:\n\t`--num_processes` was set to a value of `2`\n\t\tMore than one GPU was found, enabling multi-GPU training.\n\t\tIf this was unintended please pass in `--num_processes=1`.\n\t`--num_machines` was set to a value of `1`\nTo avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n2026-01-02 17:04:31.768641: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767373471.792198   39346 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767373471.799627   39346 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2026-01-02 17:04:32.441576: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767373472.465447   39345 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767373472.472778   39345 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\npygame 2.6.1 (SDL 2.28.4, Python 3.11.13)\nHello from the pygame community. https://www.pygame.org/contribute.html\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\npygame 2.6.1 (SDL 2.28.4, Python 3.11.13)\nHello from the pygame community. https://www.pygame.org/contribute.html\n2026-01-02 17:04:38,380 | INFO | ============================================================\n2026-01-02 17:04:38,381 | INFO | FONTDIFFUSER MULTI-GPU SYNTHESIS\n2026-01-02 17:04:38,381 | INFO | ============================================================\n2026-01-02 17:04:38,534 | INFO | Loading characters from NomTuTao/Ds_10k_ChuNom_TuTao.txt\n2026-01-02 17:04:38,534 | INFO |   Lines 720-730 (11 lines)\n2026-01-02 17:04:38,535 | INFO | Loaded 11 characters\n2026-01-02 17:04:38,535 | INFO | Loaded 15 style images from directory\nerror: XDG_RUNTIME_DIR not set in the environment.\nALSA lib confmisc.c:855:(parse_card) cannot find card '0'\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\nALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\nALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\nALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\nALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n2026-01-02 17:04:38,662 | INFO | Loaded font: NomNaTong-Regular\n2026-01-02 17:04:38,771 | INFO | Loaded checkpoint: 10785 unique generations\nLoading FontDiffuser pipeline...\nLoad the down block  DownBlock2D\nLoad the down block  MCADownBlock2D\nThe style_attention cross attention dim in Down Block 1 layer is 1024\nThe style_attention cross attention dim in Down Block 2 layer is 1024\nLoad the down block  MCADownBlock2D\nThe style_attention cross attention dim in Down Block 1 layer is 1024\nThe style_attention cross attention dim in Down Block 2 layer is 1024\nLoad the down block  DownBlock2D\nLoad the up block  UpBlock2D\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\nLoad the up block  StyleRSIUpBlock2D\nLoad the up block  StyleRSIUpBlock2D\nLoad the up block  UpBlock2D\nParam count for Ds initialized parameters: 20591296\nGet CG-GAN Style Encoder!\nParam count for Ds initialized parameters: 1187008\nGet CG-GAN Content Encoder!\nâœ“ Loaded model state_dict successfully\nConverting to channels-last memory format...\n2026-01-02 17:04:40,351 | INFO | ============================================================\n2026-01-02 17:04:40,351 | INFO | FONTDIFFUSER MULTI-GPU SYNTHESIS\n2026-01-02 17:04:40,351 | INFO | ============================================================\n2026-01-02 17:04:40,495 | INFO | Using 2 GPUs\n2026-01-02 17:04:40,498 | INFO | Loading characters from NomTuTao/Ds_10k_ChuNom_TuTao.txt\n2026-01-02 17:04:40,498 | INFO |   Lines 720-730 (11 lines)\n2026-01-02 17:04:40,498 | INFO | Loaded 11 characters\n2026-01-02 17:04:40,499 | INFO | Loaded 15 style images from directory\nerror: XDG_RUNTIME_DIR not set in the environment.\nALSA lib confmisc.c:855:(parse_card) cannot find card '0'\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\nALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\nALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\nALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\nALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n2026-01-02 17:04:40,631 | INFO | Loaded font: NomNaTong-Regular\n2026-01-02 17:04:40,727 | INFO | Loaded checkpoint: 10785 unique generations\n2026-01-02 17:04:40,729 | INFO | Loading FontDiffuser pipeline...\nLoading FontDiffuser pipeline...\nLoad the down block  DownBlock2D\nLoad the down block  MCADownBlock2D\nThe style_attention cross attention dim in Down Block 1 layer is 1024\nThe style_attention cross attention dim in Down Block 2 layer is 1024\nLoad the down block  MCADownBlock2D\nThe style_attention cross attention dim in Down Block 1 layer is 1024\nThe style_attention cross attention dim in Down Block 2 layer is 1024\nLoad the down block  DownBlock2D\nLoad the up block  UpBlock2D\nLoad the up block  StyleRSIUpBlock2D\nLoad the up block  StyleRSIUpBlock2D\nLoad the up block  UpBlock2D\nâœ“ Model moved to device\nâœ“ Loaded training DDPM scheduler successfully\nâœ“ Loaded DPM-Solver pipeline successfully\nSetting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nParam count for Ds initialized parameters: 20591296\nGet CG-GAN Style Encoder!\nParam count for Ds initialized parameters: 1187008\nGet CG-GAN Content Encoder!\nâœ“ Loaded model state_dict successfully\nConverting to channels-last memory format...\nâœ“ Model moved to device\nâœ“ Loaded training DDPM scheduler successfully\nâœ“ Loaded DPM-Solver pipeline successfully\nSetting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nLoading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/alex.pth\nLoading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/alex.pth\n2026-01-02 17:04:43,275 | INFO | Generating 11 Ã— 15 images\n/usr/local/lib/python3.11/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n  warnings.warn(  # warn only once\n[rank0]:[W102 17:04:43.612409211 ProcessGroupNCCL.cpp:5068] Guessing device ID based on global rank. This can cause a hang if rank to GPU mapping is heterogeneous. You can specify device_id in init_process_group()\n2026-01-02 17:04:44,088 | INFO | Generating content images for 11 characters\nGPU 0: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 6.00/6.00 [00:00<00:00, 7.43B/s]\u001b[0m\n2026-01-02 17:04:44,914 | INFO | Generated 11 content images\n2026-01-02 17:04:44,919 | INFO | Generating images: 11 chars Ã— 15 styles\n2026-01-02 17:04:44,920 | INFO | Using 2 GPUs\n2026-01-02 17:04:44,920 | INFO | Primary font: NomNaTong-Regular\nGPU 0:   0%|                                              | 0/8 [00:00<?, ?it/s]\n  ðŸ“¸ Preparing NomNaTong-Regular:   0%|\u001b[36m                                  \u001b[0m| 0.00/10.0 [00:00<?, ?B/s]\u001b[0m\u001b[A\n  ðŸ“¸ Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 10.0/10.0 [00:00<00:00, 790B/s]\u001b[0m\u001b[A\n\n  ðŸ“¸ Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 10.0/10.0 [00:00<00:00, 619B/s]\u001b[0m[A\n    ðŸš€ Batch Inference:   0%|\u001b[38;2;16;85;201m                                            \u001b[0m| 0.00/1.00 [00:00<?, ?B/s]\u001b[0m\n    ðŸš€ Batch Inference: 100%|\u001b[38;2;16;85;201mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1.00/1.00 [00:18<00:00, 18.5s/B]\u001b[0m\u001b[A\n    ðŸš€ Batch Inference: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1.00/1.00 [00:18<00:00, 18.5s/B]\u001b[0m\u001b[A\n    ðŸš€ Batch Inference: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1.00/1.00 [00:32<00:00, 32.0s/B]\u001b[0m\n2026-01-02 17:05:18,375 | INFO | Saved checkpoint: 10795 generations            \n2026-01-02 17:05:18,376 | INFO | Checkpoint saved at 1/8 styles                 \n  ðŸ“¸ Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 10.0/10.0 [00:00<00:00, 849B/s]\u001b[0m\n    ðŸš€ Batch Inference:   0%|\u001b[38;2;16;85;201m                                            \u001b[0m| 0.00/1.00 [00:00<?, ?B/s]\u001b[0m\n  ðŸ“¸ Preparing NomNaTong-Regular:   0%|\u001b[36m                                  \u001b[0m| 0.00/10.0 [00:00<?, ?B/s]\u001b[0m\u001b[A\n  ðŸ“¸ Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 10.0/10.0 [00:00<00:00, 586B/s]\u001b[0m\u001b[A\n\n    ðŸš€ Batch Inference:   0%|\u001b[38;2;16;85;201m                                            \u001b[0m| 0.00/1.00 [00:00<?, ?B/s]\u001b[0m\u001b[A\n    ðŸš€ Batch Inference: 100%|\u001b[38;2;16;85;201mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1.00/1.00 [00:18<00:00, 18.1s/B]\u001b[0m\u001b[A\n    ðŸš€ Batch Inference: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1.00/1.00 [00:18<00:00, 18.1s/B]\u001b[0m\u001b[A\n    ðŸš€ Batch Inference: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1.00/1.00 [00:31<00:00, 31.2s/B]\u001b[0m\n2026-01-02 17:05:50,391 | INFO | Saved checkpoint: 10805 generations            \n2026-01-02 17:05:50,391 | INFO | Checkpoint saved at 2/8 styles                 \n  ðŸ“¸ Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 10.0/10.0 [00:00<00:00, 951B/s]\u001b[0m\n    ðŸš€ Batch Inference:   0%|\u001b[38;2;16;85;201m                                            \u001b[0m| 0.00/1.00 [00:00<?, ?B/s]\u001b[0m\n  ðŸ“¸ Preparing NomNaTong-Regular:   0%|\u001b[36m                                  \u001b[0m| 0.00/10.0 [00:00<?, ?B/s]\u001b[0m\u001b[A\n  ðŸ“¸ Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 10.0/10.0 [00:00<00:00, 661B/s]\u001b[0m\u001b[A\n\n    ðŸš€ Batch Inference:   0%|\u001b[38;2;16;85;201m                                            \u001b[0m| 0.00/1.00 [00:00<?, ?B/s]\u001b[0m\u001b[A\n    ðŸš€ Batch Inference: 100%|\u001b[38;2;16;85;201mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1.00/1.00 [00:18<00:00, 18.4s/B]\u001b[0m\u001b[A\n    ðŸš€ Batch Inference: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1.00/1.00 [00:18<00:00, 18.4s/B]\u001b[0m\u001b[A\n    ðŸš€ Batch Inference: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1.00/1.00 [00:31<00:00, 31.2s/B]\u001b[0m\n2026-01-02 17:06:22,357 | INFO | Saved checkpoint: 10815 generations            \n2026-01-02 17:06:22,358 | INFO | Checkpoint saved at 3/8 styles                 \n  ðŸ“¸ Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 10.0/10.0 [00:00<00:00, 932B/s]\u001b[0m\n    ðŸš€ Batch Inference:   0%|\u001b[38;2;16;85;201m                                            \u001b[0m| 0.00/1.00 [00:00<?, ?B/s]\u001b[0m\n  ðŸ“¸ Preparing NomNaTong-Regular:   0%|\u001b[36m                                  \u001b[0m| 0.00/10.0 [00:00<?, ?B/s]\u001b[0m\u001b[A\n  ðŸ“¸ Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 10.0/10.0 [00:00<00:00, 683B/s]\u001b[0m\u001b[A\n\n    ðŸš€ Batch Inference:   0%|\u001b[38;2;16;85;201m                                            \u001b[0m| 0.00/1.00 [00:00<?, ?B/s]\u001b[0m\u001b[A\n    ðŸš€ Batch Inference: 100%|\u001b[38;2;16;85;201mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1.00/1.00 [00:18<00:00, 18.8s/B]\u001b[0m\u001b[A\n    ðŸš€ Batch Inference: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1.00/1.00 [00:18<00:00, 18.8s/B]\u001b[0m\u001b[A\n    ðŸš€ Batch Inference: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1.00/1.00 [00:31<00:00, 31.3s/B]\u001b[0m\n2026-01-02 17:06:54,690 | INFO | Saved checkpoint: 10825 generations            \n2026-01-02 17:06:54,691 | INFO | Checkpoint saved at 4/8 styles                 \n  ðŸ“¸ Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 10.0/10.0 [00:00<00:00, 934B/s]\u001b[0m\n    ðŸš€ Batch Inference:   0%|\u001b[38;2;16;85;201m                                            \u001b[0m| 0.00/1.00 [00:00<?, ?B/s]\u001b[0m\n  ðŸ“¸ Preparing NomNaTong-Regular:   0%|\u001b[36m                                  \u001b[0m| 0.00/10.0 [00:00<?, ?B/s]\u001b[0m\u001b[A\n  ðŸ“¸ Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 10.0/10.0 [00:00<00:00, 695B/s]\u001b[0m\u001b[A\n\n    ðŸš€ Batch Inference:   0%|\u001b[38;2;16;85;201m                                            \u001b[0m| 0.00/1.00 [00:00<?, ?B/s]\u001b[0m\u001b[A\n    ðŸš€ Batch Inference: 100%|\u001b[38;2;16;85;201mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1.00/1.00 [00:18<00:00, 18.7s/B]\u001b[0m\u001b[A\n    ðŸš€ Batch Inference: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1.00/1.00 [00:18<00:00, 18.7s/B]\u001b[0m\u001b[A\n    ðŸš€ Batch Inference: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1.00/1.00 [00:31<00:00, 31.2s/B]\u001b[0m\n2026-01-02 17:07:26,553 | INFO | Saved checkpoint: 10835 generations            \n2026-01-02 17:07:26,554 | INFO | Checkpoint saved at 5/8 styles                 \nGPU 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š              | 5/8 [02:41<01:36, 32.16s/it]\n  ðŸ“¸ Preparing NomNaTong-Regular:   0%|\u001b[36m                                  \u001b[0m| 0.00/10.0 [00:00<?, ?B/s]\u001b[0m\u001b[A\n  ðŸ“¸ Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 10.0/10.0 [00:00<00:00, 908B/s]\u001b[0m\u001b[A\n\n  ðŸ“¸ Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 10.0/10.0 [00:00<00:00, 688B/s]\u001b[0m[A\n    ðŸš€ Batch Inference:   0%|\u001b[38;2;16;85;201m                                            \u001b[0m| 0.00/1.00 [00:00<?, ?B/s]\u001b[0m\n    ðŸš€ Batch Inference: 100%|\u001b[38;2;16;85;201mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1.00/1.00 [00:18<00:00, 18.9s/B]\u001b[0m\u001b[A\n    ðŸš€ Batch Inference: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1.00/1.00 [00:18<00:00, 18.9s/B]\u001b[0m\u001b[A\n    ðŸš€ Batch Inference: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1.00/1.00 [00:31<00:00, 31.2s/B]\u001b[0m\n2026-01-02 17:07:58,864 | INFO | Saved checkpoint: 10845 generations            \n2026-01-02 17:07:58,865 | INFO | Checkpoint saved at 6/8 styles                 \n  ðŸ“¸ Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 10.0/10.0 [00:00<00:00, 474B/s]\u001b[0m\n    ðŸš€ Batch Inference:   0%|\u001b[38;2;16;85;201m                                            \u001b[0m| 0.00/1.00 [00:00<?, ?B/s]\u001b[0m\n  ðŸ“¸ Preparing NomNaTong-Regular:   0%|\u001b[36m                                  \u001b[0m| 0.00/10.0 [00:00<?, ?B/s]\u001b[0m\u001b[A\n  ðŸ“¸ Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 10.0/10.0 [00:00<00:00, 873B/s]\u001b[0m\u001b[A\n\n    ðŸš€ Batch Inference:   0%|\u001b[38;2;16;85;201m                                            \u001b[0m| 0.00/1.00 [00:00<?, ?B/s]\u001b[0m\u001b[A\n    ðŸš€ Batch Inference: 100%|\u001b[38;2;16;85;201mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1.00/1.00 [00:18<00:00, 19.0s/B]\u001b[0m\u001b[A\n    ðŸš€ Batch Inference: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1.00/1.00 [00:18<00:00, 19.0s/B]\u001b[0m\u001b[A\n    ðŸš€ Batch Inference: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1.00/1.00 [00:31<00:00, 31.2s/B]\u001b[0m\n2026-01-02 17:08:30,964 | INFO | Saved checkpoint: 10855 generations            \n2026-01-02 17:08:30,964 | INFO | Checkpoint saved at 7/8 styles                 \nGPU 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 7/8 [03:46<00:32, 32.17s/it]\n  ðŸ“¸ Preparing NomNaTong-Regular:   0%|\u001b[36m                                  \u001b[0m| 0.00/10.0 [00:00<?, ?B/s]\u001b[0m\u001b[A\n  ðŸ“¸ Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 10.0/10.0 [00:00<00:00, 679B/s]\u001b[0m\u001b[A\n\n    ðŸš€ Batch Inference:   0%|\u001b[38;2;16;85;201m                                            \u001b[0m| 0.00/1.00 [00:00<?, ?B/s]\u001b[0m\u001b[A\n    ðŸš€ Batch Inference: 100%|\u001b[38;2;16;85;201mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1.00/1.00 [00:19<00:00, 19.1s/B]\u001b[0m\u001b[A\n    ðŸš€ Batch Inference: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 1.00/1.00 [00:19<00:00, 19.1s/B]\u001b[0m\u001b[A\n2026-01-02 17:08:51,323 | INFO | Saved checkpoint: 10865 generations            \n2026-01-02 17:08:51,323 | INFO | Checkpoint saved at 8/8 styles                 \nGPU 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [04:06<00:00, 30.80s/it]\n2026-01-02 17:08:51,325 | INFO | ============================================================\n2026-01-02 17:08:51,325 | INFO | GENERATION COMPLETE\n2026-01-02 17:08:51,325 | INFO | ============================================================\n2026-01-02 17:08:51,325 | INFO | Generated: 80 images\n2026-01-02 17:08:51,325 | INFO | Skipped: 0 images\n2026-01-02 17:08:51,325 | INFO | Failed: 0 images\n2026-01-02 17:08:51,325 | INFO | Total characters: 729\n2026-01-02 17:08:51,325 | INFO | Total styles: 15\n2026-01-02 17:08:51,325 | INFO | ============================================================\n2026-01-02 17:08:51,424 | INFO | Saved checkpoint: 10865 generations\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdungngocpham171\u001b[0m (\u001b[33mdungngocpham171-university-of-science\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.0\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20260102_170851-c914xe8c\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtrain_original_20260102_170851\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dungngocpham171-university-of-science/fontdiffuser-eval\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dungngocpham171-university-of-science/fontdiffuser-eval/runs/c914xe8c\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n\u001b[34m\u001b[1mwandb\u001b[0m:    num_characters â–\n\u001b[34m\u001b[1mwandb\u001b[0m:         num_fonts â–\n\u001b[34m\u001b[1mwandb\u001b[0m:        num_styles â–\n\u001b[34m\u001b[1mwandb\u001b[0m: total_generations â–\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n\u001b[34m\u001b[1mwandb\u001b[0m:    num_characters 729\n\u001b[34m\u001b[1mwandb\u001b[0m:         num_fonts 1\n\u001b[34m\u001b[1mwandb\u001b[0m:        num_styles 15\n\u001b[34m\u001b[1mwandb\u001b[0m: total_generations 10865\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mtrain_original_20260102_170851\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dungngocpham171-university-of-science/fontdiffuser-eval/runs/c914xe8c\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dungngocpham171-university-of-science/fontdiffuser-eval\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20260102_170851-c914xe8c/logs\u001b[0m\n2026-01-02 17:08:53,384 | INFO | Logged to wandb: train_original_20260102_170851\n2026-01-02 17:08:53,385 | INFO | ============================================================\n2026-01-02 17:08:53,385 | INFO | âœ… GENERATION COMPLETE!\n2026-01-02 17:08:53,385 | INFO | ============================================================\n^C\nW0102 17:12:48.748000 39337 torch/distributed/elastic/agent/server/api.py:725] Received 2 death signal, shutting down workers\nW0102 17:12:48.749000 39337 torch/distributed/elastic/multiprocessing/api.py:908] Sending process 39345 closing signal SIGINT\nW0102 17:12:48.749000 39337 torch/distributed/elastic/multiprocessing/api.py:908] Sending process 39346 closing signal SIGINT\n","output_type":"stream"}],"execution_count":52},{"id":"997103e5-221c-40a1-a0d1-83a93e1030f7","cell_type":"code","source":"# @title Count images in ContentImage and TargetImage\n!find my_dataset/train_original/ContentImage -type f | wc -l\n!find my_dataset/train_original/TargetImage -type f | wc -l","metadata":{"trusted":true,"id":"997103e5-221c-40a1-a0d1-83a93e1030f7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5793b862-0cb9-4865-b335-55a1e2694629","execution":{"iopub.status.busy":"2026-01-02T17:13:01.708077Z","iopub.execute_input":"2026-01-02T17:13:01.708400Z","iopub.status.idle":"2026-01-02T17:13:01.977462Z","shell.execute_reply.started":"2026-01-02T17:13:01.708373Z","shell.execute_reply":"2026-01-02T17:13:01.976622Z"}},"outputs":[{"name":"stdout","text":"749\n10935\n","output_type":"stream"}],"execution_count":55},{"id":"f9250a14","cell_type":"code","source":"# @title Train Validation split\n!python FontDiffusion/create_validation_split.py \\\n  --data_root my_dataset \\\n  --val_ratio 0.2 \\\n  --seed 42","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2026-01-02T17:13:06.934882Z","iopub.execute_input":"2026-01-02T17:13:06.935751Z","iopub.status.idle":"2026-01-02T17:13:11.685836Z","shell.execute_reply.started":"2026-01-02T17:13:06.935717Z","shell.execute_reply":"2026-01-02T17:13:11.684946Z"},"id":"f9250a14","outputId":"2067ddd0-043d-43ac-a8c5-cda453912ae0","papermill":{"duration":0.236541,"end_time":"2025-12-30T18:55:01.673705","exception":false,"start_time":"2025-12-30T18:55:01.437164","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"2026-01-02 17:13:08,820 | INFO | âœ“ Using source directory: my_dataset/train_original\n2026-01-02 17:13:08,821 | INFO | \n============================================================\n2026-01-02 17:13:08,821 | INFO | FONTDIFFUSION VALIDATION SPLIT CREATOR\n2026-01-02 17:13:08,821 | INFO | ============================================================\n2026-01-02 17:13:08,821 | INFO | \n============================================================\n2026-01-02 17:13:08,821 | INFO | ANALYZING TRAINING DATA\n2026-01-02 17:13:08,821 | INFO | ============================================================\n2026-01-02 17:13:08,821 | INFO | \nðŸ” Scanning content images...\nContent images: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 749/749 [00:00<00:00, 520kimg/s]\u001b[0m\n2026-01-02 17:13:08,826 | INFO |   âœ“ Found 749 content images\n2026-01-02 17:13:08,826 | INFO | \nðŸ” Scanning target images...\nStyles: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 15.0/15.0 [00:00<00:00, 302style/s]\u001b[0m\n2026-01-02 17:13:08,876 | INFO |   âœ“ Found 10935 valid target images\n2026-01-02 17:13:08,876 | INFO | \nðŸ” Validating content â†” target pairs...\nValidating pairs: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 10.7k/10.7k [00:00<00:00, 2.20Mpair/s]\u001b[0m\n2026-01-02 17:13:08,884 | INFO | ============================================================\n2026-01-02 17:13:08,884 | INFO | ðŸ“Š DATA ANALYSIS SUMMARY\n2026-01-02 17:13:08,884 | INFO | ============================================================\n2026-01-02 17:13:08,884 | INFO | Content images found:        749\n2026-01-02 17:13:08,884 | INFO | Target images scanned:       10,935\n2026-01-02 17:13:08,884 | INFO |   â”œâ”€ Parse errors:          0\n2026-01-02 17:13:08,884 | INFO |   â””â”€ Style mismatches:      0\n2026-01-02 17:13:08,884 | INFO | Target images after filter:  10,935\n2026-01-02 17:13:08,884 | INFO | Missing content images:      0\n2026-01-02 17:13:08,884 | INFO | Final valid pairs:           10,935\n2026-01-02 17:13:08,884 | INFO | ============================================================\n2026-01-02 17:13:08,885 | INFO | \n============================================================\n2026-01-02 17:13:08,885 | INFO | CREATING TRAIN/VAL SPLITS (random char & style)\n2026-01-02 17:13:08,885 | INFO | ============================================================\n2026-01-02 17:13:08,886 | INFO | \nðŸ“Š Split Statistics:\n2026-01-02 17:13:08,886 | INFO |   Total chars: 749 â†’ train: 600, val: 149\n2026-01-02 17:13:08,886 | INFO |   Total styles: 15 â†’ train: 12, val: 3\n2026-01-02 17:13:08,886 | INFO |   train:\n2026-01-02 17:13:08,886 | INFO |     Chars: 600\n2026-01-02 17:13:08,886 | INFO |     Styles: 12\n2026-01-02 17:13:08,886 | INFO |   val:\n2026-01-02 17:13:08,886 | INFO |     Chars: 149\n2026-01-02 17:13:08,886 | INFO |     Styles: 3\n2026-01-02 17:13:08,886 | INFO | \nðŸ“ CREATING TRAIN SPLIT...\n2026-01-02 17:13:08,887 | INFO |   ðŸ“¥ Copying content images for train...\n2026-01-02 17:13:09,018 | INFO |   ðŸ“¥ Copying target images for train...        00<00:00, 4.62kchar/s]\u001b[0m\n2026-01-02 17:13:10,883 | INFO |   âœ“ train: 600 content, 6,972 target (skipped: 0)<00:00, 5.85kpair/s]\u001b[0m\n2026-01-02 17:13:10,884 | INFO |   ðŸ“‹ Filtering checkpoint for train...\n2026-01-02 17:13:11,013 | INFO |     âœ“ Saved: 6,924/10,865 generations          6k/10.6k [00:00<00:00]\u001b[0m\n2026-01-02 17:13:11,015 | INFO | ðŸ“ CREATING VAL SPLIT...\n2026-01-02 17:13:11,015 | INFO |   ðŸ“¥ Copying content images for val...\n2026-01-02 17:13:11,048 | INFO |   ðŸ“¥ Copying target images for val...          00<00:00, 4.62kchar/s]\u001b[0m\n2026-01-02 17:13:11,163 | INFO |   âœ“ val: 149 content, 444 target (skipped: 0)  :00<00:00, 110kpair/s]\u001b[0m\n2026-01-02 17:13:11,163 | INFO |   ðŸ“‹ Filtering checkpoint for val...\n2026-01-02 17:13:11,229 | INFO |     âœ“ Saved: 442/10,865 generations            6k/10.6k [00:00<00:00]\u001b[0m\n2026-01-02 17:13:11,231 | INFO | âœ“ Saved split metadata to my_dataset/split_info.json\n2026-01-02 17:13:11,233 | INFO | \n============================================================\n2026-01-02 17:13:11,233 | INFO | âœ“ SPLIT CREATION COMPLETE\n2026-01-02 17:13:11,233 | INFO | ============================================================\n2026-01-02 17:13:11,233 | INFO | \nâœ… Created:\n2026-01-02 17:13:11,233 | INFO |   ðŸ“ train/\n2026-01-02 17:13:11,233 | INFO |     â”œâ”€â”€ ContentImage/ (training chars)\n2026-01-02 17:13:11,233 | INFO |     â”œâ”€â”€ TargetImage/ (training styles)\n2026-01-02 17:13:11,233 | INFO |     â””â”€â”€ results_checkpoint.json (filtered)\n2026-01-02 17:13:11,233 | INFO |   ðŸ“ val/\n2026-01-02 17:13:11,233 | INFO |     â”œâ”€â”€ ContentImage/ (validation chars)\n2026-01-02 17:13:11,233 | INFO |     â”œâ”€â”€ TargetImage/ (validation styles)\n2026-01-02 17:13:11,233 | INFO |     â””â”€â”€ results_checkpoint.json (filtered)\n2026-01-02 17:13:11,233 | INFO | \nðŸ’¡ Guarantees:\n2026-01-02 17:13:11,233 | INFO |   âœ“ Every target has matching content\n2026-01-02 17:13:11,233 | INFO |   âœ“ Checkpoint contains only relevant generations\n2026-01-02 17:13:11,233 | INFO |   âœ“ Train and val are completely disjoint\n","output_type":"stream"}],"execution_count":56},{"id":"79508d80-fac1-4318-9174-a32613a557e3","cell_type":"code","source":"!uv pip install --upgrade pyarrow datasets","metadata":{"id":"79508d80-fac1-4318-9174-a32613a557e3","trusted":true,"execution":{"iopub.status.busy":"2026-01-02T17:13:26.884141Z","iopub.execute_input":"2026-01-02T17:13:26.884611Z","iopub.status.idle":"2026-01-02T17:13:27.361512Z","shell.execute_reply.started":"2026-01-02T17:13:26.884578Z","shell.execute_reply":"2026-01-02T17:13:27.360605Z"}},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m39 packages\u001b[0m \u001b[2min 155ms\u001b[0m\u001b[0m                                        \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m3 packages\u001b[0m \u001b[2min 0.75ms\u001b[0m\u001b[0m                                            \n\u001b[2mUninstalled \u001b[1m3 packages\u001b[0m \u001b[2min 32ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 28ms\u001b[0m\u001b[0m                                \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.12.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.10.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.25.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==1.2.3\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.4.0\u001b[0m\n","output_type":"stream"}],"execution_count":57},{"id":"vRL8QovYCvLY","cell_type":"code","source":"# @title Creat and upload dataset to HF\nHF_USERNAME = \"dzungpham\"\n!python FontDiffusion/create_hf_dataset.py \\\n  --data-dir \"my_dataset/train_original\" \\\n  --repo-id dzungpham/font-diffusion-generated-data \\\n  --split \"train_original\" \\\n  --token {HF_TOKEN}\n\n# Train Split\n!python FontDiffusion/create_hf_dataset.py \\\n  --data-dir \"my_dataset/train\" \\\n  --repo-id dzungpham/font-diffusion-generated-data \\\n  --split \"train\" \\\n  --token {HF_TOKEN}\n\n# Train Split\n!python FontDiffusion/create_hf_dataset.py \\\n  --data-dir \"my_dataset/val\" \\\n  --repo-id dzungpham/font-diffusion-generated-data \\\n  --split \"val\" \\\n  --token {HF_TOKEN}\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2026-01-02T17:13:29.551339Z","iopub.execute_input":"2026-01-02T17:13:29.551884Z","iopub.status.idle":"2026-01-02T17:15:02.356233Z","shell.execute_reply.started":"2026-01-02T17:13:29.551833Z","shell.execute_reply":"2026-01-02T17:15:02.355267Z"},"id":"vRL8QovYCvLY","outputId":"d66b2cea-1a37-4b4a-c2ff-ccfe8d2baad2","trusted":true},"outputs":[{"name":"stdout","text":"2026-01-02 17:13:32,847 | INFO | Directory structure validated successfully\n2026-01-02 17:13:32,849 | INFO | Building dataset...\n2026-01-02 17:13:32,910 | INFO | Loaded checkpoint: 10865 generations, 729 characters, 15 styles\nLoading image pairs: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 10.6k/10.6k [00:09<00:00, 1.19kpair/s]\u001b[0m\n2026-01-02 17:13:42,011 | INFO | Successfully loaded 10865 samples\n2026-01-02 17:14:09,835 | INFO | Pushing dataset to dzungpham/font-diffusion-generated-data...\n2026-01-02 17:14:10,068 | INFO | HTTP Request: GET https://huggingface.co/api/datasets/dzungpham/font-diffusion-generated-data \"HTTP/1.1 200 OK\"\nUploading the dataset shards:   0%|                  | 0/1 [00:00<?, ? shards/s]\nMap:   0%|                                     | 0/10865 [00:00<?, ? examples/s]\u001b[A\nMap:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 6616/10865 [00:00<00:00, 15878.38 examples/s]\u001b[A\nMap: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10865/10865 [00:00<00:00, 14220.78 examples/s]\u001b[A\n\nCreating parquet from Arrow format:   0%|                 | 0/2 [00:00<?, ?ba/s]\u001b[A\nCreating parquet from Arrow format:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1/2 [00:00<00:00,  4.05ba/s]\u001b[A\nCreating parquet from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.63ba/s]\u001b[A\n2026-01-02 17:14:11,769 | INFO | HTTP Request: POST https://huggingface.co/api/datasets/dzungpham/font-diffusion-generated-data/preupload/main \"HTTP/1.1 200 OK\"\n2026-01-02 17:14:11,845 | INFO | HTTP Request: POST https://huggingface.co/datasets/dzungpham/font-diffusion-generated-data.git/info/lfs/objects/batch \"HTTP/1.1 200 OK\"\n2026-01-02 17:14:12,030 | INFO | HTTP Request: GET https://huggingface.co/api/datasets/dzungpham/font-diffusion-generated-data/xet-write-token/main \"HTTP/1.1 200 OK\"\nProcessing Files (0 / 0)      : |                  |  0.00B /  0.00B            \nNew Data Upload               : |                  |  0.00B /  0.00B            \u001b[A\n\n                              :   0%|              |  239kB /  146MB            \u001b[A\u001b[A\n\nProcessing Files (0 / 1)      :   0%|              |  239kB /  146MB, 1.19MB/s  \u001b[A\u001b[A\n\nProcessing Files (0 / 1)      :   8%|â–ˆ             | 10.9MB /  146MB, 27.3MB/s  \u001b[A\u001b[A\n\nProcessing Files (0 / 1)      :  11%|â–ˆâ–Œ            | 15.6MB /  146MB, 26.1MB/s  \u001b[A\u001b[A\n\nProcessing Files (0 / 1)      :  12%|â–ˆâ–Œ            | 16.9MB /  146MB, 21.1MB/s  \u001b[A\u001b[A\nNew Data Upload               :   1%|              |  526kB / 90.5MB,  658kB/s  \u001b[A\n\nProcessing Files (0 / 1)      :  21%|â–ˆâ–ˆâ–‰           | 30.0MB /  146MB, 30.0MB/s  \u001b[A\u001b[A\nNew Data Upload               :  15%|â–ˆâ–ˆ            | 13.7MB / 90.5MB, 13.7MB/s  \u001b[A\n\nProcessing Files (0 / 1)      :  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š        | 61.0MB /  146MB, 50.9MB/s  \u001b[A\u001b[A\nNew Data Upload               :  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰       | 44.7MB / 90.5MB, 37.3MB/s  \u001b[A\n\nProcessing Files (0 / 1)      :  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 93.1MB /  146MB, 66.5MB/s  \u001b[A\u001b[A\nNew Data Upload               :  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 76.7MB / 90.5MB, 54.8MB/s  \u001b[A\n\nProcessing Files (0 / 1)      :  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   |  106MB /  146MB, 66.4MB/s  \u001b[A\u001b[A\nNew Data Upload               :  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 89.9MB / 90.5MB, 56.2MB/s  \u001b[A\n\n                              :  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   |  106MB /  146MB            \u001b[A\u001b[A\n\nProcessing Files (0 / 1)      :  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   |  107MB /  146MB, 53.4MB/s  \u001b[A\u001b[A\nNew Data Upload               : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 90.4MB / 90.5MB, 45.2MB/s  \u001b[A\n\n                              :  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   |  107MB /  146MB            \u001b[A\u001b[A\n\nProcessing Files (0 / 1)      :  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   |  107MB /  146MB, 44.5MB/s  \u001b[A\u001b[A\nNew Data Upload               : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90.5MB / 90.5MB, 37.7MB/s  \u001b[A\n\n                              :  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   |  107MB /  146MB            \u001b[A\u001b[A\n\nProcessing Files (0 / 1)      :  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   |  107MB /  146MB, 41.1MB/s  \u001b[A\u001b[A\nNew Data Upload               : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90.5MB / 90.5MB, 34.8MB/s  \n                              :  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   |  107MB /  146MB            \nUploading the dataset shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.78s/ shards]\n2026-01-02 17:14:16,943 | INFO | HTTP Request: GET https://huggingface.co/api/datasets/dzungpham/font-diffusion-generated-data \"HTTP/1.1 200 OK\"\n2026-01-02 17:14:17,085 | INFO | HTTP Request: GET https://huggingface.co/api/datasets/dzungpham/font-diffusion-generated-data/tree/7bb77fe93645453511a44b6a1713843417c9c86e?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n2026-01-02 17:14:17,270 | INFO | HTTP Request: HEAD https://huggingface.co/datasets/dzungpham/font-diffusion-generated-data/resolve/7bb77fe93645453511a44b6a1713843417c9c86e/README.md \"HTTP/1.1 307 Temporary Redirect\"\n2026-01-02 17:14:17,391 | INFO | HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/dzungpham/font-diffusion-generated-data/7bb77fe93645453511a44b6a1713843417c9c86e/README.md \"HTTP/1.1 200 OK\"\n2026-01-02 17:14:17,510 | INFO | HTTP Request: GET https://huggingface.co/api/resolve-cache/datasets/dzungpham/font-diffusion-generated-data/7bb77fe93645453511a44b6a1713843417c9c86e/README.md \"HTTP/1.1 200 OK\"\nREADME.md: 3.05kB [00:00, 6.51MB/s]\n2026-01-02 17:14:17,590 | INFO | HTTP Request: POST https://huggingface.co/api/validate-yaml \"HTTP/1.1 200 OK\"\n2026-01-02 17:14:17,736 | INFO | HTTP Request: POST https://huggingface.co/api/datasets/dzungpham/font-diffusion-generated-data/preupload/main \"HTTP/1.1 200 OK\"\n2026-01-02 17:14:18,764 | INFO | HTTP Request: POST https://huggingface.co/api/datasets/dzungpham/font-diffusion-generated-data/commit/main \"HTTP/1.1 200 OK\"\n2026-01-02 17:14:18,765 | INFO | Successfully pushed to https://huggingface.co/datasets/dzungpham/font-diffusion-generated-data\n2026-01-02 17:14:18,775 | INFO | Dataset creation completed successfully\n2026-01-02 17:14:22,552 | INFO | Directory structure validated successfully\n2026-01-02 17:14:22,553 | INFO | Building dataset...\n2026-01-02 17:14:22,595 | INFO | Loaded checkpoint: 6924 generations, 600 characters, 12 styles\nLoading image pairs: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 6.76k/6.76k [00:05<00:00, 1.16kpair/s]\u001b[0m\n2026-01-02 17:14:28,540 | INFO | Successfully loaded 6924 samples\n2026-01-02 17:14:46,627 | INFO | Pushing dataset to dzungpham/font-diffusion-generated-data...\n2026-01-02 17:14:46,883 | INFO | HTTP Request: GET https://huggingface.co/api/datasets/dzungpham/font-diffusion-generated-data \"HTTP/1.1 200 OK\"\nUploading the dataset shards:   0%|                  | 0/1 [00:00<?, ? shards/s]\nMap:   0%|                                      | 0/6924 [00:00<?, ? examples/s]\u001b[A\nMap: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6924/6924 [00:00<00:00, 16005.54 examples/s]\u001b[A\n\nCreating parquet from Arrow format:   0%|                 | 0/2 [00:00<?, ?ba/s]\u001b[A\nCreating parquet from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  8.38ba/s]\u001b[A\n2026-01-02 17:14:48,063 | INFO | HTTP Request: POST https://huggingface.co/api/datasets/dzungpham/font-diffusion-generated-data/preupload/main \"HTTP/1.1 200 OK\"\n2026-01-02 17:14:48,140 | INFO | HTTP Request: POST https://huggingface.co/datasets/dzungpham/font-diffusion-generated-data.git/info/lfs/objects/batch \"HTTP/1.1 200 OK\"\n2026-01-02 17:14:48,211 | INFO | HTTP Request: GET https://huggingface.co/api/datasets/dzungpham/font-diffusion-generated-data/xet-write-token/main \"HTTP/1.1 200 OK\"\nProcessing Files (0 / 0)      : |                  |  0.00B /  0.00B            \nNew Data Upload               : |                  |  0.00B /  0.00B            \u001b[A\n\n                              :   0%|              |  307kB / 93.4MB            \u001b[A\u001b[A\n\nProcessing Files (0 / 1)      :   0%|              |  307kB / 93.4MB,   ???B/s  \u001b[A\u001b[A\n\nProcessing Files (0 / 1)      :   1%|              |  495kB / 93.4MB,  938kB/s  \u001b[A\u001b[A\n\nProcessing Files (0 / 1)      :   1%|              |  650kB / 93.4MB,  856kB/s  \u001b[A\u001b[A\n\nProcessing Files (0 / 1)      :   4%|â–Œ             | 3.51MB / 93.4MB, 5.34MB/s  \u001b[A\u001b[A\nNew Data Upload               :   3%|â–             | 2.64MB / 75.5MB, 4.40MB/s  \u001b[A\n\nProcessing Files (0 / 1)      :  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–         | 28.3MB / 93.4MB, 35.0MB/s  \u001b[A\u001b[A\nNew Data Upload               :  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 27.4MB / 75.5MB, 34.3MB/s  \u001b[A\n\nProcessing Files (0 / 1)      :  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š      | 52.5MB / 93.4MB, 52.3MB/s  \u001b[A\u001b[A\nNew Data Upload               :  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 51.7MB / 75.5MB, 51.7MB/s  \u001b[A\n\nProcessing Files (0 / 1)      :  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 72.6MB / 93.4MB, 60.3MB/s  \u001b[A\u001b[A\nNew Data Upload               :  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 71.7MB / 75.5MB, 59.8MB/s  \u001b[A\n\nProcessing Files (0 / 1)      :  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76.3MB / 93.4MB, 54.3MB/s  \u001b[A\u001b[A\nNew Data Upload               : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 75.4MB / 75.5MB, 53.9MB/s  \u001b[A\n\n                              :  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76.3MB / 93.4MB            \u001b[A\u001b[A\n\n                              :  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76.3MB / 93.4MB            \u001b[A\u001b[A\n\nProcessing Files (0 / 1)      :  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76.3MB / 93.4MB, 38.0MB/s  \u001b[A\u001b[A\nNew Data Upload               : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75.5MB / 75.5MB, 37.7MB/s  \u001b[A\n\n                              :  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76.3MB / 93.4MB            \u001b[A\u001b[A\n\nProcessing Files (0 / 1)      :  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76.3MB / 93.4MB, 34.6MB/s  \u001b[A\u001b[A\nNew Data Upload               : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75.5MB / 75.5MB, 34.3MB/s  \n                              :  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76.3MB / 93.4MB            \nUploading the dataset shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.09s/ shards]\n2026-01-02 17:14:52,064 | INFO | HTTP Request: GET https://huggingface.co/api/datasets/dzungpham/font-diffusion-generated-data \"HTTP/1.1 200 OK\"\n2026-01-02 17:14:52,181 | INFO | HTTP Request: GET https://huggingface.co/api/datasets/dzungpham/font-diffusion-generated-data/tree/00a1e3bb0c6424c15f7238ddce18516111b8cb2f?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n2026-01-02 17:14:52,264 | INFO | HTTP Request: HEAD https://huggingface.co/datasets/dzungpham/font-diffusion-generated-data/resolve/00a1e3bb0c6424c15f7238ddce18516111b8cb2f/README.md \"HTTP/1.1 307 Temporary Redirect\"\n2026-01-02 17:14:52,377 | INFO | HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/dzungpham/font-diffusion-generated-data/00a1e3bb0c6424c15f7238ddce18516111b8cb2f/README.md \"HTTP/1.1 200 OK\"\n2026-01-02 17:14:52,497 | INFO | HTTP Request: GET https://huggingface.co/api/resolve-cache/datasets/dzungpham/font-diffusion-generated-data/00a1e3bb0c6424c15f7238ddce18516111b8cb2f/README.md \"HTTP/1.1 200 OK\"\nREADME.md: 3.05kB [00:00, 5.79MB/s]\n2026-01-02 17:14:52,574 | INFO | HTTP Request: POST https://huggingface.co/api/validate-yaml \"HTTP/1.1 200 OK\"\n2026-01-02 17:14:52,684 | INFO | HTTP Request: POST https://huggingface.co/api/datasets/dzungpham/font-diffusion-generated-data/preupload/main \"HTTP/1.1 200 OK\"\n2026-01-02 17:14:53,525 | INFO | HTTP Request: POST https://huggingface.co/api/datasets/dzungpham/font-diffusion-generated-data/commit/main \"HTTP/1.1 200 OK\"\n2026-01-02 17:14:53,525 | INFO | Successfully pushed to https://huggingface.co/datasets/dzungpham/font-diffusion-generated-data\n2026-01-02 17:14:53,532 | INFO | Dataset creation completed successfully\n2026-01-02 17:14:57,102 | INFO | Directory structure validated successfully\n2026-01-02 17:14:57,103 | INFO | Building dataset...\n2026-01-02 17:14:57,106 | INFO | Loaded checkpoint: 442 generations, 149 characters, 3 styles\nLoading image pairs: 100%|\u001b[38;2;65;166;126mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 442/442 [00:00<00:00, 1.16kpair/s]\u001b[0m\n2026-01-02 17:14:57,488 | INFO | Successfully loaded 442 samples\n2026-01-02 17:14:58,571 | INFO | Pushing dataset to dzungpham/font-diffusion-generated-data...\n2026-01-02 17:14:58,807 | INFO | HTTP Request: GET https://huggingface.co/api/datasets/dzungpham/font-diffusion-generated-data \"HTTP/1.1 200 OK\"\nUploading the dataset shards:   0%|                  | 0/1 [00:00<?, ? shards/s]\nMap: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 442/442 [00:00<00:00, 18712.10 examples/s]\u001b[A\n\nCreating parquet from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 71.98ba/s]\u001b[A\n2026-01-02 17:14:58,969 | INFO | HTTP Request: POST https://huggingface.co/api/datasets/dzungpham/font-diffusion-generated-data/preupload/main \"HTTP/1.1 200 OK\"\n2026-01-02 17:14:59,048 | INFO | HTTP Request: POST https://huggingface.co/datasets/dzungpham/font-diffusion-generated-data.git/info/lfs/objects/batch \"HTTP/1.1 200 OK\"\n2026-01-02 17:14:59,121 | INFO | HTTP Request: GET https://huggingface.co/api/datasets/dzungpham/font-diffusion-generated-data/xet-write-token/main \"HTTP/1.1 200 OK\"\nProcessing Files (0 / 0)      : |                  |  0.00B /  0.00B            \nNew Data Upload               : |                  |  0.00B /  0.00B            \u001b[A\n\n                              :   1%|              | 31.5kB / 4.36MB            \u001b[A\u001b[A\n\nProcessing Files (0 / 1)      :   1%|              | 31.5kB / 4.36MB,   ???B/s  \u001b[A\u001b[A\n\nProcessing Files (0 / 1)      :  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4.23MB / 4.36MB, 20.9MB/s  \u001b[A\u001b[A\nNew Data Upload               :  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4.19MB / 4.33MB, 20.9MB/s  \u001b[A\n\n                              :  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4.23MB / 4.36MB            \u001b[A\u001b[A\n\nProcessing Files (1 / 1)      : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.36MB / 4.36MB, 8.00MB/s  \u001b[A\u001b[A\nNew Data Upload               : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.33MB / 4.33MB, 8.00MB/s  \u001b[A\n\nProcessing Files (1 / 1)      : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.36MB / 4.36MB, 7.22MB/s  \u001b[A\u001b[A\nNew Data Upload               : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.33MB / 4.33MB, 7.22MB/s  \n                              : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.36MB / 4.36MB            \nUploading the dataset shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.18s/ shards]\n2026-01-02 17:15:00,069 | INFO | HTTP Request: GET https://huggingface.co/api/datasets/dzungpham/font-diffusion-generated-data \"HTTP/1.1 200 OK\"\n2026-01-02 17:15:00,183 | INFO | HTTP Request: GET https://huggingface.co/api/datasets/dzungpham/font-diffusion-generated-data/tree/a1076808aeb93be19e68cd0f4b34fc8d4961dab8?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n2026-01-02 17:15:00,272 | INFO | HTTP Request: HEAD https://huggingface.co/datasets/dzungpham/font-diffusion-generated-data/resolve/a1076808aeb93be19e68cd0f4b34fc8d4961dab8/README.md \"HTTP/1.1 307 Temporary Redirect\"\n2026-01-02 17:15:00,388 | INFO | HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/dzungpham/font-diffusion-generated-data/a1076808aeb93be19e68cd0f4b34fc8d4961dab8/README.md \"HTTP/1.1 200 OK\"\n2026-01-02 17:15:00,524 | INFO | HTTP Request: GET https://huggingface.co/api/resolve-cache/datasets/dzungpham/font-diffusion-generated-data/a1076808aeb93be19e68cd0f4b34fc8d4961dab8/README.md \"HTTP/1.1 200 OK\"\nREADME.md: 3.05kB [00:00, 6.76MB/s]\n2026-01-02 17:15:00,593 | INFO | HTTP Request: POST https://huggingface.co/api/validate-yaml \"HTTP/1.1 200 OK\"\n2026-01-02 17:15:00,864 | INFO | HTTP Request: POST https://huggingface.co/api/datasets/dzungpham/font-diffusion-generated-data/preupload/main \"HTTP/1.1 200 OK\"\n2026-01-02 17:15:01,610 | INFO | HTTP Request: POST https://huggingface.co/api/datasets/dzungpham/font-diffusion-generated-data/commit/main \"HTTP/1.1 200 OK\"\n2026-01-02 17:15:01,610 | INFO | Successfully pushed to https://huggingface.co/datasets/dzungpham/font-diffusion-generated-data\n2026-01-02 17:15:01,610 | INFO | Dataset creation completed successfully\n","output_type":"stream"}],"execution_count":58},{"id":"a87caab2","cell_type":"code","source":"# import torch, gc\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"id":"a87caab2","papermill":{"duration":1.992585,"end_time":"2025-12-30T18:55:24.769269","exception":false,"start_time":"2025-12-30T18:55:22.776684","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"267634e8","cell_type":"code","source":"# @title Training phase 1\nif is_colab:\n  !uv pip install --upgrade \"huggingface-hub>=0.34.0,<1.0\"\nelse:\n  !uv pip install --upgrade \"huggingface-hub==0.25.2\"\nimport wandb\n\nMAX_TRAIN_STEPS = 1000 # @param {type:\"integer\"}\n!accelerate launch --mixed_precision fp16 --dynamo_backend inductor \\\n    FontDiffusion/my_train.py \\\n    --seed=123 \\\n    --experience_name=\"FontDiffuser_training_phase_1\" \\\n    --data_root=\"my_dataset\" \\\n    --output_dir=\"outputs/FontDiffuser\" \\\n    --phase_1_ckpt_dir=\"outputs/FontDiffuser/global_step_500\" \\\n    --report_to=\"wandb\" \\\n      \\\n    --resolution=96 \\\n    --style_image_size=96 \\\n    --content_image_size=96 \\\n    --content_encoder_downsample_size=3 \\\n    --channel_attn=True \\\n    --content_start_channel=64 \\\n    --style_start_channel=64 \\\n      \\\n    --train_batch_size=16 \\\n    --gradient_accumulation_steps=1 \\\n    --perceptual_coefficient=0.05 \\\n    --offset_coefficient=0.5 \\\n    --max_train_steps={MAX_TRAIN_STEPS} \\\n    --ckpt_interval={MAX_TRAIN_STEPS // 2} \\\n    --log_interval=50 \\\n      \\\n    --learning_rate=1e-4 \\\n    --lr_scheduler=\"linear\" \\\n    --lr_warmup_steps=100 \\\n    --drop_prob=0.1 \\\n    --mixed_precision=\"no\"","metadata":{"execution":{"iopub.status.busy":"2026-01-02T15:33:30.031312Z","iopub.execute_input":"2026-01-02T15:33:30.032039Z","iopub.status.idle":"2026-01-02T16:16:36.542257Z","shell.execute_reply.started":"2026-01-02T15:33:30.032013Z","shell.execute_reply":"2026-01-02T16:16:36.541507Z"},"id":"267634e8","papermill":{"duration":0.021927,"end_time":"2025-12-30T18:55:24.807644","exception":false,"start_time":"2025-12-30T18:55:24.785717","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m12 packages\u001b[0m \u001b[2min 82ms\u001b[0m\u001b[0m                                         \u001b[0m\n\u001b[2mAudited \u001b[1m12 packages\u001b[0m \u001b[2min 0.13ms\u001b[0m\u001b[0m\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\nThe following values were not passed to `accelerate launch` and had defaults used instead:\n\t`--num_processes` was set to a value of `2`\n\t\tMore than one GPU was found, enabling multi-GPU training.\n\t\tIf this was unintended please pass in `--num_processes=1`.\n\t`--num_machines` was set to a value of `1`\nTo avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n2026-01-02 15:33:39.820833: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2026-01-02 15:33:39.820924: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767368019.843178    1635 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767368019.843229    1636 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767368019.850710    1636 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1767368019.850747    1635 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\npygame 2.6.1 (SDL 2.28.4, Python 3.11.13)\nHello from the pygame community. https://www.pygame.org/contribute.html\npygame 2.6.1 (SDL 2.28.4, Python 3.11.13)\nHello from the pygame community. https://www.pygame.org/contribute.html\nLoad the down block  DownBlock2D\nLoad the down block  DownBlock2D\nLoad the down block  MCADownBlock2D\nLoad the down block  MCADownBlock2D\nThe style_attention cross attention dim in Down Block 1 layer is 1024\nThe style_attention cross attention dim in Down Block 1 layer is 1024\nThe style_attention cross attention dim in Down Block 2 layer is 1024\nThe style_attention cross attention dim in Down Block 2 layer is 1024\nLoad the down block  MCADownBlock2D\nLoad the down block  MCADownBlock2D\nThe style_attention cross attention dim in Down Block 1 layer is 1024\nThe style_attention cross attention dim in Down Block 1 layer is 1024\nThe style_attention cross attention dim in Down Block 2 layer is 1024\nThe style_attention cross attention dim in Down Block 2 layer is 1024\nLoad the down block  DownBlock2D\nLoad the down block  DownBlock2D\nLoad the up block  UpBlock2D\nLoad the up block  UpBlock2D\nLoad the up block  StyleRSIUpBlock2D\nLoad the up block  StyleRSIUpBlock2D\nLoad the up block  StyleRSIUpBlock2D\nLoad the up block  StyleRSIUpBlock2D\nLoad the up block  UpBlock2D\nLoad the up block  UpBlock2D\nParam count for Ds initialized parameters: 20591296\nGet CG-GAN Style Encoder!\nParam count for Ds initialized parameters: 20591296\nGet CG-GAN Style Encoder!\nParam count for Ds initialized parameters: 1187008\nGet CG-GAN Content Encoder!\n\nðŸ“¦ Loading Phase 1 checkpoints...\nParam count for Ds initialized parameters: 1187008\nGet CG-GAN Content Encoder!\n\nðŸ“¦ Loading Phase 1 checkpoints...\n  âœ“ Loaded unet from outputs/FontDiffuser/global_step_500/unet.safetensors\n  âœ“ Loaded unet from outputs/FontDiffuser/global_step_500/unet.safetensors\n  âœ“ Loaded style_encoder from outputs/FontDiffuser/global_step_500/style_encoder.safetensors\n  âœ“ Loaded style_encoder from outputs/FontDiffuser/global_step_500/style_encoder.safetensors\n  âœ“ Loaded content_encoder from outputs/FontDiffuser/global_step_500/content_encoder.safetensors\n  âœ“ Loaded content_encoder from outputs/FontDiffuser/global_step_500/content_encoder.safetensors\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdungngocpham171\u001b[0m (\u001b[33mdungngocpham171-university-of-science\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.0\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20260102_153351-jqgox26m\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcosmic-night-24\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dungngocpham171-university-of-science/FontDiffuser_training_phase_1\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dungngocpham171-university-of-science/FontDiffuser_training_phase_1/runs/jqgox26m\u001b[0m\nSteps:   0%|                                           | 0/1000 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/diffusers/configuration_utils.py:134: FutureWarning: Accessing config attribute `num_train_timesteps` directly via 'DDPMScheduler' object attribute is deprecated. Please access 'num_train_timesteps' over 'DDPMScheduler's config object instead, e.g. 'scheduler.config.num_train_timesteps'.\n  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n/usr/local/lib/python3.11/dist-packages/diffusers/configuration_utils.py:134: FutureWarning: Accessing config attribute `num_train_timesteps` directly via 'DDPMScheduler' object attribute is deprecated. Please access 'num_train_timesteps' over 'DDPMScheduler's config object instead, e.g. 'scheduler.config.num_train_timesteps'.\n  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n[rank0]:W0102 15:33:53.140000 1635 torch/_logging/_internal.py:1199] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored\n[rank1]:W0102 15:33:53.141000 1636 torch/_logging/_internal.py:1199] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored\n/usr/local/lib/python3.11/dist-packages/torch/backends/cuda/__init__.py:131: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n  return torch._C._get_cublas_allow_tf32()\n/usr/local/lib/python3.11/dist-packages/torch/backends/cuda/__init__.py:131: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n  return torch._C._get_cublas_allow_tf32()\n[rank1]:W0102 15:34:09.042000 1636 torch/_inductor/utils.py:1558] [4/0] Not enough SMs to use max_autotune_gemm mode\n[rank0]:W0102 15:34:09.048000 1635 torch/_inductor/utils.py:1558] [4/0] Not enough SMs to use max_autotune_gemm mode\n/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:841: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\ngrad.sizes() = [128, 128, 1, 1], strides() = [128, 1, 128, 128]\nbucket_view.sizes() = [128, 128, 1, 1], strides() = [128, 1, 1, 1] (Triggered internally at /pytorch/torch/csrc/distributed/c10d/reducer.cpp:334.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:841: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\ngrad.sizes() = [128, 128, 1, 1], strides() = [128, 1, 128, 128]\nbucket_view.sizes() = [128, 128, 1, 1], strides() = [128, 1, 1, 1] (Triggered internally at /pytorch/torch/csrc/distributed/c10d/reducer.cpp:334.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\nSteps:   0%|    | 1/1000 [07:55<131:51:01, 475.14s/it, lr=2e-6, step_loss=0.326]/usr/local/lib/python3.11/dist-packages/diffusers/configuration_utils.py:134: FutureWarning: Accessing config attribute `num_train_timesteps` directly via 'DDPMScheduler' object attribute is deprecated. Please access 'num_train_timesteps' over 'DDPMScheduler's config object instead, e.g. 'scheduler.config.num_train_timesteps'.\n  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n/usr/local/lib/python3.11/dist-packages/diffusers/configuration_utils.py:134: FutureWarning: Accessing config attribute `num_train_timesteps` directly via 'DDPMScheduler' object attribute is deprecated. Please access 'num_train_timesteps' over 'DDPMScheduler's config object instead, e.g. 'scheduler.config.num_train_timesteps'.\n  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\nSteps:   5%|â–Ž     | 50/1000 [09:38<33:24,  2.11s/it, lr=9.8e-5, step_loss=0.272]2026-01-02 15:43:31,585 | INFO | [2026-01-02 15:43:31] Global Step 50 => train_loss = 0.30077287554740906\n2026-01-02 15:43:31,585 | INFO | [2026-01-02 15:43:31] Global Step 50 => train_loss = 0.2812369763851166\nSteps:  10%|â–   | 100/1000 [11:22<31:07,  2.07s/it, lr=8.91e-5, step_loss=0.267]2026-01-02 15:45:15,671 | INFO | [2026-01-02 15:45:15] Global Step 100 => train_loss = 0.4312046766281128\n2026-01-02 15:45:15,671 | INFO | [2026-01-02 15:45:15] Global Step 100 => train_loss = 0.48921331763267517\nSteps:  15%|â–Š    | 150/1000 [13:06<29:20,  2.07s/it, lr=7.8e-5, step_loss=0.288]2026-01-02 15:46:59,398 | INFO | [2026-01-02 15:46:59] Global Step 150 => train_loss = 0.2758287787437439\n2026-01-02 15:46:59,398 | INFO | [2026-01-02 15:46:59] Global Step 150 => train_loss = 0.24789109826087952\nSteps:  20%|â–Š   | 200/1000 [14:50<27:42,  2.08s/it, lr=6.69e-5, step_loss=0.434]2026-01-02 15:48:43,123 | INFO | [2026-01-02 15:48:43] Global Step 200 => train_loss = 0.44335320591926575\n2026-01-02 15:48:43,124 | INFO | [2026-01-02 15:48:43] Global Step 200 => train_loss = 0.4703448414802551\nSteps:  25%|â–ˆ   | 250/1000 [16:33<25:54,  2.07s/it, lr=5.58e-5, step_loss=0.359]2026-01-02 15:50:26,647 | INFO | [2026-01-02 15:50:26] Global Step 250 => train_loss = 0.2794547975063324\n2026-01-02 15:50:26,647 | INFO | [2026-01-02 15:50:26] Global Step 250 => train_loss = 0.2939267158508301\nSteps:  30%|â–ˆâ–Œ   | 300/1000 [18:16<24:09,  2.07s/it, lr=4.47e-5, step_loss=0.21]2026-01-02 15:52:09,941 | INFO | [2026-01-02 15:52:09] Global Step 300 => train_loss = 0.16624347865581512\n2026-01-02 15:52:09,942 | INFO | [2026-01-02 15:52:09] Global Step 300 => train_loss = 0.21884514391422272\nSteps:  35%|â–ˆâ–  | 350/1000 [20:00<22:26,  2.07s/it, lr=3.36e-5, step_loss=0.352]2026-01-02 15:53:53,250 | INFO | [2026-01-02 15:53:53] Global Step 350 => train_loss = 0.43049147725105286\n2026-01-02 15:53:53,251 | INFO | [2026-01-02 15:53:53] Global Step 350 => train_loss = 0.4240286648273468\nSteps:  40%|â–ˆâ–Œ  | 400/1000 [21:43<20:32,  2.05s/it, lr=2.24e-5, step_loss=0.366]2026-01-02 15:55:36,653 | INFO | [2026-01-02 15:55:36] Global Step 400 => train_loss = 0.24136926233768463\n2026-01-02 15:55:36,654 | INFO | [2026-01-02 15:55:36] Global Step 400 => train_loss = 0.23777905106544495\nSteps:  45%|â–ˆâ–Š  | 450/1000 [23:26<18:51,  2.06s/it, lr=1.13e-5, step_loss=0.273]2026-01-02 15:57:19,317 | INFO | [2026-01-02 15:57:19] Global Step 450 => train_loss = 0.22985702753067017\n2026-01-02 15:57:19,317 | INFO | [2026-01-02 15:57:19] Global Step 450 => train_loss = 0.17272812128067017\nSteps:  50%|â–ˆâ–ˆ  | 500/1000 [25:09<17:17,  2.08s/it, lr=2.22e-7, step_loss=0.334]/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:446: FutureWarning: Accessing config attribute `unet` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'unet' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.unet'.\n  return getattr(self._orig_mod, name)\n2026-01-02 15:59:02,679 | INFO | [2026-01-02 15:59:02] Global Step 500 => train_loss = 0.29380786418914795\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:446: FutureWarning: Accessing config attribute `style_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'style_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.style_encoder'.\n  return getattr(self._orig_mod, name)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:446: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.content_encoder'.\n  return getattr(self._orig_mod, name)\n2026-01-02 15:59:05,004 | INFO | [2026-01-02 15:59:05] Save the checkpoint on global step 500\nSteps:  50%|â–ˆâ–ˆ  | 500/1000 [25:12<17:17,  2.08s/it, lr=2.22e-7, step_loss=0.334]âœ… [2026-01-02 15:59:05] Save the checkpoint on global step 500\n2026-01-02 15:59:05,005 | INFO | [2026-01-02 15:59:05] Global Step 500 => train_loss = 0.3531331419944763\nSteps:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 550/1000 [26:56<15:33,  2.07s/it, lr=0, step_loss=0.242]2026-01-02 16:00:49,353 | INFO | [2026-01-02 16:00:49] Global Step 550 => train_loss = 0.31013381481170654\n2026-01-02 16:00:49,354 | INFO | [2026-01-02 16:00:49] Global Step 550 => train_loss = 0.30899959802627563\nSteps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 600/1000 [28:39<13:49,  2.07s/it, lr=0, step_loss=0.397]2026-01-02 16:02:32,550 | INFO | [2026-01-02 16:02:32] Global Step 600 => train_loss = 0.25149184465408325\n2026-01-02 16:02:32,550 | INFO | [2026-01-02 16:02:32] Global Step 600 => train_loss = 0.2041575014591217\nSteps:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 650/1000 [30:24<12:14,  2.10s/it, lr=0, step_loss=0.312]2026-01-02 16:04:17,389 | INFO | [2026-01-02 16:04:17] Global Step 650 => train_loss = 0.5198198556900024\n2026-01-02 16:04:17,389 | INFO | [2026-01-02 16:04:17] Global Step 650 => train_loss = 0.4731776714324951\nSteps:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 700/1000 [32:07<10:14,  2.05s/it, lr=0, step_loss=0.285]2026-01-02 16:06:00,512 | INFO | [2026-01-02 16:06:00] Global Step 700 => train_loss = 0.28627002239227295\n2026-01-02 16:06:00,513 | INFO | [2026-01-02 16:06:00] Global Step 700 => train_loss = 0.38936489820480347\nSteps:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 750/1000 [33:50<08:33,  2.05s/it, lr=0, step_loss=0.149]2026-01-02 16:07:43,738 | INFO | [2026-01-02 16:07:43] Global Step 750 => train_loss = 0.2975009083747864\n2026-01-02 16:07:43,739 | INFO | [2026-01-02 16:07:43] Global Step 750 => train_loss = 0.3016335070133209\nSteps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 800/1000 [35:33<06:54,  2.07s/it, lr=0, step_loss=0.198]2026-01-02 16:09:26,721 | INFO | [2026-01-02 16:09:26] Global Step 800 => train_loss = 0.22625325620174408\n2026-01-02 16:09:26,722 | INFO | [2026-01-02 16:09:26] Global Step 800 => train_loss = 0.21715709567070007\nSteps:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 850/1000 [37:17<05:11,  2.08s/it, lr=0, step_loss=0.255]2026-01-02 16:11:10,640 | INFO | [2026-01-02 16:11:10] Global Step 850 => train_loss = 0.32264506816864014\n2026-01-02 16:11:10,641 | INFO | [2026-01-02 16:11:10] Global Step 850 => train_loss = 0.3092448115348816\nSteps:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 900/1000 [39:01<03:28,  2.09s/it, lr=0, step_loss=0.298]2026-01-02 16:12:54,955 | INFO | [2026-01-02 16:12:54] Global Step 900 => train_loss = 0.2901361584663391\n2026-01-02 16:12:54,956 | INFO | [2026-01-02 16:12:54] Global Step 900 => train_loss = 0.32907962799072266\nSteps:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 950/1000 [40:46<01:44,  2.09s/it, lr=0, step_loss=0.276]2026-01-02 16:14:39,028 | INFO | [2026-01-02 16:14:39] Global Step 950 => train_loss = 0.28249791264533997\n2026-01-02 16:14:39,029 | INFO | [2026-01-02 16:14:39] Global Step 950 => train_loss = 0.27724727988243103\nSteps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [42:30<00:00,  2.07s/it, lr=0, step_loss=0.31]2026-01-02 16:16:23,050 | INFO | [2026-01-02 16:16:23] Global Step 1000 => train_loss = 0.17796435952186584\n2026-01-02 16:16:24,589 | INFO | [2026-01-02 16:16:24] Save the checkpoint on global step 1000\nSteps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [42:31<00:00,  2.07s/it, lr=0, step_loss=0.31]âœ… [2026-01-02 16:16:24] Save the checkpoint on global step 1000\n2026-01-02 16:16:24,590 | INFO | [2026-01-02 16:16:24] Global Step 1000 => train_loss = 0.26337558031082153\nSteps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [42:31<00:00,  2.07s/it, lr=0, step_loss=0.263]\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n\u001b[34m\u001b[1mwandb\u001b[0m: train_loss â–„â–ƒâ–ˆâ–…â–„â–ƒâ–„â–‚â–‡â–‚â–…â–ƒâ–‚â–„â–ƒâ–â–…â–„â–ƒâ–‡â–ƒâ–…â–‚â–„â–ƒâ–ƒâ–„â–„â–ƒâ–‚â–‚â–‚â–…â–„â–ƒâ–…â–„â–†â–„â–‚\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.22067\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mcosmic-night-24\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dungngocpham171-university-of-science/FontDiffuser_training_phase_1/runs/jqgox26m\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dungngocpham171-university-of-science/FontDiffuser_training_phase_1\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20260102_153351-jqgox26m/logs\u001b[0m\nSteps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [42:32<00:00,  2.55s/it, lr=0, step_loss=0.263]\n[rank0]:[W102 16:16:29.430460708 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n","output_type":"stream"}],"execution_count":28},{"id":"cb2a3326-6bfa-4fba-bbcc-e2e7be996c7f","cell_type":"code","source":"!ls -lr outputs/FontDiffuser","metadata":{"id":"cb2a3326-6bfa-4fba-bbcc-e2e7be996c7f","trusted":true},"outputs":[],"execution_count":null},{"id":"97f8136e","cell_type":"code","source":"# @title Training phase 2 with SCR\nif is_colab:\n  !uv pip install --upgrade \"huggingface-hub>=0.34.0,<1.0\"\nelse:\n  !uv pip install --upgrade \"huggingface-hub==0.25.2\"\n\n!wandb login\nMAX_TRAIN_STEPS = 500 # @param {type:\"integer\"}\n!accelerate launch FontDiffusion/my_train.py \\\n    --seed=123 \\\n    --experience_name=\"FontDiffuser_training_phase_2\" \\\n    --data_root=\"my_dataset\" \\\n    --output_dir=\"outputs/FontDiffuser\" \\\n    --report_to=\"wandb\" \\\n    --phase_2 \\\n    --phase_1_ckpt_dir=\"outputs/FontDiffuser/global_step_500\" \\\n    --scr_ckpt_path=\"ckpt/scr_210000.pth\" \\\n    \\\n    --sc_coefficient=0.05 \\\n    --num_neg=10 \\\n    --resolution=96 \\\n    --style_image_size=96 \\\n    --content_image_size=96 \\\n    --content_encoder_downsample_size=3 \\\n    --channel_attn=True \\\n    --content_start_channel=64 \\\n    --style_start_channel=64 \\\n    \\\n    --train_batch_size=16 \\\n    --gradient_accumulation_steps=1 \\\n    --perceptual_coefficient=0.05 \\\n    --offset_coefficient=0.5 \\\n    --max_train_steps={MAX_TRAIN_STEPS} \\\n    --ckpt_interval={MAX_TRAIN_STEPS // 2} \\\n    --log_interval=50 \\\n    \\\n    --learning_rate=1e-5 \\\n    --lr_scheduler=\"constant\" \\\n    --lr_warmup_steps=100 \\\n    --drop_prob=0.1 \\\n    --mixed_precision=\"no\"\n","metadata":{"id":"97f8136e","papermill":{"duration":0.022471,"end_time":"2025-12-30T18:55:24.845778","exception":false,"start_time":"2025-12-30T18:55:24.823307","status":"completed"},"tags":[],"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fd8d0266-9c9f-409a-d92d-f403a2057ad3"},"outputs":[],"execution_count":null},{"id":"0c935ec2-c328-4d82-925f-f51cb83bac9c","cell_type":"code","source":"!ls -l outputs/FontDiffuser/*/*","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T16:18:29.441118Z","iopub.execute_input":"2026-01-02T16:18:29.442060Z","iopub.status.idle":"2026-01-02T16:18:29.578047Z","shell.execute_reply.started":"2026-01-02T16:18:29.442025Z","shell.execute_reply":"2026-01-02T16:18:29.577230Z"}},"outputs":[{"name":"stdout","text":"-rw-r--r-- 1 root root   4756580 Jan  2 16:16 outputs/FontDiffuser/global_step_1000/content_encoder.safetensors\n-rw-r--r-- 1 root root  82394556 Jan  2 16:16 outputs/FontDiffuser/global_step_1000/style_encoder.safetensors\n-rw-r--r-- 1 root root 402093724 Jan  2 16:16 outputs/FontDiffuser/global_step_1000/total_model.safetensors\n-rw-r--r-- 1 root root 314927748 Jan  2 16:16 outputs/FontDiffuser/global_step_1000/unet.safetensors\n-rw-r--r-- 1 root root   4756580 Jan  2 15:03 outputs/FontDiffuser/global_step_250/content_encoder.safetensors\n-rw-r--r-- 1 root root  82394556 Jan  2 15:03 outputs/FontDiffuser/global_step_250/style_encoder.safetensors\n-rw-r--r-- 1 root root 402084924 Jan  2 15:03 outputs/FontDiffuser/global_step_250/total_model.safetensors\n-rw-r--r-- 1 root root 314927748 Jan  2 15:03 outputs/FontDiffuser/global_step_250/unet.safetensors\n-rw-r--r-- 1 root root   4756580 Jan  2 15:59 outputs/FontDiffuser/global_step_500/content_encoder.safetensors\n-rw-r--r-- 1 root root  82394556 Jan  2 15:59 outputs/FontDiffuser/global_step_500/style_encoder.safetensors\n-rw-r--r-- 1 root root 402093724 Jan  2 15:59 outputs/FontDiffuser/global_step_500/total_model.safetensors\n-rw-r--r-- 1 root root 314927748 Jan  2 15:59 outputs/FontDiffuser/global_step_500/unet.safetensors\n","output_type":"stream"}],"execution_count":29},{"id":"88c45e2f","cell_type":"code","source":"STEP = 1000\n!python FontDiffusion/upload_models.py \\\n    --weights_dir \"outputs/FontDiffuser/global_step_{STEP}\" \\\n    --repo_id \"dzungpham/font-diffusion-weights\" \\\n    --token \"{HF_TOKEN}\"","metadata":{"id":"88c45e2f","papermill":{"duration":0.217876,"end_time":"2025-12-30T18:55:25.079820","exception":false,"start_time":"2025-12-30T18:55:24.861944","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T16:19:20.861791Z","iopub.execute_input":"2026-01-02T16:19:20.862140Z","iopub.status.idle":"2026-01-02T16:19:32.100703Z","shell.execute_reply.started":"2026-01-02T16:19:20.862109Z","shell.execute_reply":"2026-01-02T16:19:32.099694Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nPYTORCH TO SAFETENSORS CONVERTER & HF UPLOADER\n======================================================================\n\n======================================================================\nVALIDATING INPUTS\n======================================================================\nâœ“ Weights directory: outputs/FontDiffuser/global_step_1000\nâœ“ HF token: ********************\n\nâœ“ Files to process: 10\n  âš  content_encoder.pth (not found)\n  âœ“ content_encoder.safetensors (4.54 MB)\n  âš  style_encoder.pth (not found)\n  âœ“ style_encoder.safetensors (78.58 MB)\n  âš  unet.pth (not found)\n  âœ“ unet.safetensors (300.34 MB)\n  âš  total_model.pth (not found)\n  âœ“ total_model.safetensors (383.47 MB)\n  âš  scr.pth (not found)\n  âš  scr.safetensors (not found)\n\n======================================================================\nCONVERTING .pth TO .safetensors\n======================================================================\n\nâš  content_encoder.pth: Not found, skipping\n\nâš  style_encoder.pth: Not found, skipping\n\nâš  unet.pth: Not found, skipping\n\nâš  total_model.pth: Not found, skipping\n\nâš  scr.pth: Not found, skipping\n\n----------------------------------------------------------------------\nConversion complete: 0 succeeded, 0 failed\n\n======================================================================\nUPLOADING TO HUGGING FACE HUB\n======================================================================\nThe token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n\nðŸ“¤ Creating/verifying repository...\nâœ“ Repository ready\n\nðŸ“¤ Uploading folder: outputs/FontDiffuser/global_step_1000\n  0%|                                                     | 0/4 [00:00<?, ?it/s]\ncontent_encoder.safetensors:   0%|                  | 0.00/4.76M [00:00<?, ?B/s]\u001b[A\ncontent_encoder.safetensors: 16.0MB [00:00, 28.2MB/s]                           \u001b[A\n 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                 | 1/4 [00:00<00:02,  1.23it/s]\nstyle_encoder.safetensors:   0%|                    | 0.00/82.4M [00:00<?, ?B/s]\u001b[A\nstyle_encoder.safetensors:  19%|â–ˆâ–ˆâ–        | 16.0M/82.4M [00:00<00:02, 26.5MB/s]\u001b[A\nstyle_encoder.safetensors: 96.0MB [00:00, 121MB/s]                              \u001b[A\n 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 2/4 [00:01<00:01,  1.06it/s]\ntotal_model.safetensors:   0%|                       | 0.00/402M [00:00<?, ?B/s]\u001b[A\ntotal_model.safetensors:   4%|â–Œ             | 16.0M/402M [00:00<00:13, 28.0MB/s]\u001b[A\ntotal_model.safetensors: 416MB [00:01, 350MB/s]                                 \u001b[A\n 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 3/4 [00:03<00:01,  1.16s/it]\nunet.safetensors:   0%|                              | 0.00/315M [00:00<?, ?B/s]\u001b[A\nunet.safetensors:   5%|â–ˆ                    | 16.0M/315M [00:00<00:13, 21.8MB/s]\u001b[A\nunet.safetensors:  10%|â–ˆâ–ˆâ–                  | 32.0M/315M [00:00<00:06, 42.4MB/s]\u001b[A\nunet.safetensors: 320MB [00:01, 217MB/s]                                        \u001b[A\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.27s/it]\n\nâœ“ Upload successful!\n  Repository URL: https://huggingface.co/models/dzungpham/font-diffusion-weights\n\n======================================================================\nâœ“ ALL DONE!\n======================================================================\n\nðŸ“¦ Your weights are now available at:\n   https://huggingface.co/models/dzungpham/font-diffusion-weights\n\nðŸ“– Load them with:\n   from safetensors.torch import load_file\n   state = load_file('model.safetensors')\n","output_type":"stream"}],"execution_count":30},{"id":"5868b20b","cell_type":"code","source":"import os\nimport zipfile\nfrom pathlib import Path\nfrom typing import List\ndef find_result_folders(base_path: Path, pattern_name: str) -> List[Path]:\n    return [p for p in base_path.glob(pattern_name) if p.is_dir()]\n\ndef zip_folder(folder_path: Path, output_base_path: Path) -> bool:\n    folder_name = folder_path.name\n    zip_path = output_base_path / f\"{folder_name}.zip\"\n    try:\n        print(f\"   -> Zipping folder: {folder_name}...\")\n        with zipfile.ZipFile(zip_path, mode=\"w\", compression=zipfile.ZIP_DEFLATED) as zipf:\n            for file_path in folder_path.rglob(\"*\"):\n                if file_path.is_file():\n                    arcname = file_path.relative_to(folder_path.parent)\n                    zipf.write(file_path, arcname)\n        print(f\"   âœ… Created ZIP: {zip_path.name}\")\n        return True\n    except Exception as exc:\n        print(f\"   âŒ Failed to zip {folder_name}: {exc}\")\n        return False\n\ndef zip_stats_results_folders(output_base_path: str, pattern_name: str) -> None:\n    base = Path(output_base_path)\n    base.mkdir(parents=True, exist_ok=True)\n    result_folders = find_result_folders(base, pattern_name)\n    if not result_folders:\n        print(f\"âš ï¸ No folders matching '*dataset' found in '{output_base_path}'.\")\n        return\n    print(f\"ðŸ” Found {len(result_folders)} result folder(s) to zip.\")\n    successful = sum(1 for folder in result_folders if zip_folder(folder, base))\n    print(f\"\\nâœ… DONE! Successfully zipped {successful} out of {len(result_folders)} folder(s).\")\n\nif __name__ == \"__main__\":\n    try:\n        output_root = os.getenv(\"OUTPUT_PATH\") or globals().get(\"OUTPUT_PATH\")\n        if not output_root:\n            raise ValueError(\"OUTPUT_PATH not defined\")\n        zip_stats_results_folders(\n            output_base_path=OUTPUT_PATH,\n            pattern_name=\"my_dataset\")\n    except Exception as e:\n        print(f\"âŒ An error occurred: {e}\")","metadata":{"id":"5868b20b","papermill":{"duration":0.031197,"end_time":"2025-12-30T18:55:25.126961","exception":false,"start_time":"2025-12-30T18:55:25.095764","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}