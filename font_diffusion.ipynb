{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":127.636509,"end_time":"2025-12-30T18:55:25.961447","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-12-30T18:53:18.324938","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"13dcc8c050c94bf08809b513af66e71d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_961fd67e53094ae38e25bb349e7026a6","IPY_MODEL_b18dd409df074df3ad5377b78549ce99","IPY_MODEL_8197301e998f411e8f1c729343489063"],"layout":"IPY_MODEL_0b09965d72f144c2996827b43ff2af54"}},"961fd67e53094ae38e25bb349e7026a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de3ef430c1a44670906d16eefebd0ccc","placeholder":"​","style":"IPY_MODEL_19851fb2c35a410591bcc7662a34ba64","value":"content_encoder.pth: 100%"}},"b18dd409df074df3ad5377b78549ce99":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_474215913b004c27bbd8103a9bd02a34","max":4765643,"min":0,"orientation":"horizontal","style":"IPY_MODEL_40551dfe31404308bcd54d33fbd4cccf","value":4765643}},"8197301e998f411e8f1c729343489063":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_580290334e7b4fd48958960885414f92","placeholder":"​","style":"IPY_MODEL_3e7f58f4df6a4c4c8ee4298d439df592","value":" 4.77M/4.77M [00:01&lt;00:00, 6.15MB/s]"}},"0b09965d72f144c2996827b43ff2af54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de3ef430c1a44670906d16eefebd0ccc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19851fb2c35a410591bcc7662a34ba64":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"474215913b004c27bbd8103a9bd02a34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40551dfe31404308bcd54d33fbd4cccf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"580290334e7b4fd48958960885414f92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e7f58f4df6a4c4c8ee4298d439df592":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b4da517c870e45d086af056a2f14644b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b2e744b57e784711adb065a7dcc20b8d","IPY_MODEL_8f19aec8e0e043b396f17a8a3e4d87bd","IPY_MODEL_c54866342be6402f829fe6e469a79176"],"layout":"IPY_MODEL_1c78b84b8ebc43ba8eac35a73a45b16d"}},"b2e744b57e784711adb065a7dcc20b8d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80ff0ed5cffd4555a5b12ab771c668c1","placeholder":"​","style":"IPY_MODEL_f647b6d6657e4bbfadff2e72deed8a6a","value":"style_encoder.pth: 100%"}},"8f19aec8e0e043b396f17a8a3e4d87bd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_79e611ff2d7d4163ae1f3d28bac3bb45","max":82410027,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6ee9719c538747f2a072c319a23d60bc","value":82410027}},"c54866342be6402f829fe6e469a79176":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd70e0836ae14b88985382731ea4e4b5","placeholder":"​","style":"IPY_MODEL_fec07f02713f45de98c8c7acb5e0ec85","value":" 82.4M/82.4M [00:01&lt;00:00, 137MB/s]"}},"1c78b84b8ebc43ba8eac35a73a45b16d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80ff0ed5cffd4555a5b12ab771c668c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f647b6d6657e4bbfadff2e72deed8a6a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"79e611ff2d7d4163ae1f3d28bac3bb45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ee9719c538747f2a072c319a23d60bc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cd70e0836ae14b88985382731ea4e4b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fec07f02713f45de98c8c7acb5e0ec85":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9b30333cd204203aa4893c193b950ad":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_912491bb437044a8a7af89ed3f001828","IPY_MODEL_f86e58e72ef84d359862d09aca84a8ba","IPY_MODEL_b4c8c2887c2946b59b4d5d9785a330d7"],"layout":"IPY_MODEL_479ef528237d48318f71a770fc448e52"}},"912491bb437044a8a7af89ed3f001828":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4c056dd71d34a8babea55a5b9670d95","placeholder":"​","style":"IPY_MODEL_e5692a73a28d4fc5a24d6a346fbfb323","value":"unet.pth: 100%"}},"f86e58e72ef84d359862d09aca84a8ba":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a162b4f8c6e417698522c9492d981ea","max":315147685,"min":0,"orientation":"horizontal","style":"IPY_MODEL_756152c336d14a38b14b4a676f59dc3f","value":315147685}},"b4c8c2887c2946b59b4d5d9785a330d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebff0148645547eb8a8d2dc871d6b064","placeholder":"​","style":"IPY_MODEL_a1252cf387494b54a850e9a87c9c1e96","value":" 315M/315M [00:03&lt;00:00, 220MB/s]"}},"479ef528237d48318f71a770fc448e52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4c056dd71d34a8babea55a5b9670d95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5692a73a28d4fc5a24d6a346fbfb323":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a162b4f8c6e417698522c9492d981ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"756152c336d14a38b14b4a676f59dc3f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ebff0148645547eb8a8d2dc871d6b064":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1252cf387494b54a850e9a87c9c1e96":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e87aad0600364534ac555d5b84287468":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_056b7d84091a4e0baeecb43a6e60fb53","IPY_MODEL_c5a77b1eabc845019484ba3e34bbc91c","IPY_MODEL_61029bf3b9944abfa866fdf6227573b6"],"layout":"IPY_MODEL_729af54f5f16497593f0b4a3d426dd6a"}},"056b7d84091a4e0baeecb43a6e60fb53":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea313d8f00884ec68f9753669d3cd61a","placeholder":"​","style":"IPY_MODEL_a1d5643bee8646d69e77e1a0b116833a","value":"Ds_10k_ChuNom_TuTao.txt: "}},"c5a77b1eabc845019484ba3e34bbc91c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_443b2e65f93849eca9cab42f36cb3e39","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_03431a179ddb4e409c541f44f5d2e896","value":1}},"61029bf3b9944abfa866fdf6227573b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb86821f6cc94bdaae6e51dc463ba077","placeholder":"​","style":"IPY_MODEL_965eee19a9ac491dba0d874ff3e42078","value":" 59.6k/? [00:00&lt;00:00, 4.57MB/s]"}},"729af54f5f16497593f0b4a3d426dd6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea313d8f00884ec68f9753669d3cd61a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1d5643bee8646d69e77e1a0b116833a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"443b2e65f93849eca9cab42f36cb3e39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"03431a179ddb4e409c541f44f5d2e896":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fb86821f6cc94bdaae6e51dc463ba077":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"965eee19a9ac491dba0d874ff3e42078":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82549384f46044f48a310cfb6fd68cae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_06cf6ecf71004ee9bb919d7e82007e1d","IPY_MODEL_6b008ff294e74e5686e677afdae7abcc","IPY_MODEL_fbeb3be394df4b07bee67f50cb7923ef"],"layout":"IPY_MODEL_0fe235807a9843f2ad671c6dc095f031"}},"06cf6ecf71004ee9bb919d7e82007e1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3478954c1b684265adfc587b481794e8","placeholder":"​","style":"IPY_MODEL_32ed6b57bf2a4699935d4dd7691080f2","value":"Ds_300_ChuNom_TuTao.csv: "}},"6b008ff294e74e5686e677afdae7abcc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7430f0928f844bdaba7b572cd13c969","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a75085decd55451ea653273aeee544ee","value":1}},"fbeb3be394df4b07bee67f50cb7923ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_98b40b0e16fb4dacb6b1bd5f526c5c68","placeholder":"​","style":"IPY_MODEL_0bd634cdae0d4371bb91e57895a25a6a","value":" 11.4k/? [00:00&lt;00:00, 1.03MB/s]"}},"0fe235807a9843f2ad671c6dc095f031":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3478954c1b684265adfc587b481794e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32ed6b57bf2a4699935d4dd7691080f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7430f0928f844bdaba7b572cd13c969":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"a75085decd55451ea653273aeee544ee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"98b40b0e16fb4dacb6b1bd5f526c5c68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bd634cdae0d4371bb91e57895a25a6a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"22d3b0d8e1384e1fbcec471d606bd385":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_33be7ff0037d446ea4592d2b43eebc80","IPY_MODEL_ac1b8a48eac547609b31cdff6dd1898e","IPY_MODEL_c0e1a8eccd2141c4973225dc867c76e0"],"layout":"IPY_MODEL_17efc0dec3f24ce5836696645768e9cc"}},"33be7ff0037d446ea4592d2b43eebc80":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f248b56f31ee478b8e7de22d3bc5051f","placeholder":"​","style":"IPY_MODEL_08b2b098800f4420a2b59544f54a4d5b","value":"Top184_PureNomChar.xlsx: 100%"}},"ac1b8a48eac547609b31cdff6dd1898e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_694b02dd3eb043a78267714fd01ae53e","max":15786,"min":0,"orientation":"horizontal","style":"IPY_MODEL_257493b9863c41b68f40a184f67af002","value":15786}},"c0e1a8eccd2141c4973225dc867c76e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_615d312d90ee46939ace0e004887851a","placeholder":"​","style":"IPY_MODEL_a2f0b00d233841368854f74b7921ffd7","value":" 15.8k/15.8k [00:00&lt;00:00, 1.60MB/s]"}},"17efc0dec3f24ce5836696645768e9cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f248b56f31ee478b8e7de22d3bc5051f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08b2b098800f4420a2b59544f54a4d5b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"694b02dd3eb043a78267714fd01ae53e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"257493b9863c41b68f40a184f67af002":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"615d312d90ee46939ace0e004887851a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2f0b00d233841368854f74b7921ffd7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"a95a46ef","cell_type":"code","source":"# @title Environment Setup\nimport os\nimport sys\nif 'MPLBACKEND' in os.environ:\n    del os.environ['MPLBACKEND']\n    print(\"MPLBACKEND environment variable cleared.\")\n\n# 2. Clone the repository\n!rm -rf FontDiffusion\n!git clone https://github.com/dzungphieuluuky/FontDiffusion.git","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a95a46ef","outputId":"f0886d52-e0c0-45af-db89-331a6d4a2927","papermill":{"duration":12.857369,"end_time":"2025-12-30T18:53:35.066181","exception":false,"start_time":"2025-12-30T18:53:22.208812","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T07:51:32.917856Z","iopub.execute_input":"2026-01-03T07:51:32.918191Z","iopub.status.idle":"2026-01-03T07:51:46.740662Z","shell.execute_reply.started":"2026-01-03T07:51:32.918165Z","shell.execute_reply":"2026-01-03T07:51:46.739851Z"}},"outputs":[{"name":"stdout","text":"MPLBACKEND environment variable cleared.\nCloning into 'FontDiffusion'...\nremote: Enumerating objects: 20757, done.\u001b[K\nremote: Counting objects: 100% (110/110), done.\u001b[K\nremote: Compressing objects: 100% (78/78), done.\u001b[K\nremote: Total 20757 (delta 64), reused 68 (delta 32), pack-reused 20647 (from 2)\u001b[K\nReceiving objects: 100% (20757/20757), 278.14 MiB | 30.91 MiB/s, done.\nResolving deltas: 100% (1060/1060), done.\nUpdating files: 100% (138/138), done.\n","output_type":"stream"}],"execution_count":1},{"id":"9cdd8666","cell_type":"code","source":"import os\nimport sys\nfrom IPython import get_ipython\nfrom typing import Optional\n\ndef configure_environment_paths():\n    try:\n        if \"google.colab\" in str(get_ipython()):\n            print(\"✅ Environment: Google Colab\")\n            base_data_path = \"/content/\"\n            base_output_path = \"/content/\"\n            environment_name = \"colab\"\n        elif os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\"):\n            print(\"✅ Environment: Kaggle\")\n            base_data_path = \"/kaggle/input/\"\n            base_output_path = \"/kaggle/working/\"\n            environment_name = \"kaggle\"\n        else:\n            print(\"⚠️ Environment: Local/Unknown\")\n            base_data_path = \"./data/\"\n            base_output_path = \"./output/\"\n            environment_name = \"local\"\n    except NameError:\n        print(\"⚠️ Non-interactive session. Using local paths.\")\n        base_data_path = \"./data/\"\n        base_output_path = \"./output/\"\n        environment_name = \"local\"\n    os.makedirs(base_output_path, exist_ok=True)\n    print(f\"📂 Data Path: {base_data_path}\")\n    print(f\"📦 Output Path: {base_output_path}\")\n    return base_data_path, base_output_path, environment_name\n\ndef load_secret(key_name: str) -> Optional[str]:\n    env = ENV_NAME\n    secret_value = None\n    print(f\"Attempting to load secret '{key_name}' from '{env}' environment...\")\n    try:\n        if env == \"colab\":\n            from google.colab import userdata\n            secret_value = userdata.get(key_name)\n        elif env == \"kaggle\":\n            from kaggle_secrets import UserSecretsClient\n            user_secrets = UserSecretsClient()\n            secret_value = user_secrets.get_secret(key_name)\n        else:\n            secret_value = os.getenv(key_name)\n        if not secret_value:\n            print(f\"⚠️ Secret '{key_name}' not found in the {env} environment.\")\n            return None\n        print(f\"✅ Successfully loaded secret '{key_name}'.\")\n        return secret_value\n    except Exception as e:\n        print(f\"❌ An error occurred while loading secret '{key_name}': {e}\")\n        return None\n\ndef print_system_info():\n    print(\"\\n🔧 System Information\")\n    print(f\"Python version: {sys.version.split()[0]}\")\n    try:\n        import torch\n        print(f\"PyTorch version: {torch.__version__}\")\n        if torch.cuda.is_available():\n            print(f\"CUDA version: {torch.version.cuda}\")\n            print(f\"GPU count: {torch.cuda.device_count()}\")\n            for i in range(torch.cuda.device_count()):\n                print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n        else:\n            print(\"CUDA not available\")\n    except ImportError:\n        print(\"PyTorch not installed\")\n    finally:\n      !nvidia-smi\n\nINPUT_PATH, OUTPUT_PATH, ENV_NAME = configure_environment_paths()\nis_kaggle = (\"kaggle\" in ENV_NAME)\nis_colab = not is_kaggle\nprint_system_info()\n\nos.environ[\"WANDB_API_KEY\"] = wandb_key = load_secret(\"WANDB_API_KEY\")\nos.environ[\"HF_TOKEN\"] = HF_TOKEN = load_secret('HF_TOKEN')\nos.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n\n# Now, these libraries will log in automatically\nimport wandb\nimport huggingface_hub\n\nwandb.login()\nhuggingface_hub.login(token=os.environ[\"HF_TOKEN\"])","metadata":{"id":"9cdd8666","papermill":{"duration":0.019157,"end_time":"2025-12-30T18:53:35.092303","exception":false,"start_time":"2025-12-30T18:53:35.073146","status":"completed"},"tags":[],"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"62c7e749-1e21-4ff2-9615-8cc3e6080b19","execution":{"iopub.status.busy":"2026-01-03T07:51:46.742291Z","iopub.execute_input":"2026-01-03T07:51:46.742589Z","iopub.status.idle":"2026-01-03T07:52:03.977254Z","shell.execute_reply.started":"2026-01-03T07:51:46.742562Z","shell.execute_reply":"2026-01-03T07:52:03.976394Z"}},"outputs":[{"name":"stdout","text":"✅ Environment: Kaggle\n📂 Data Path: /kaggle/input/\n📦 Output Path: /kaggle/working/\n\n🔧 System Information\nPython version: 3.11.13\nPyTorch version: 2.6.0+cu124\nCUDA version: 12.4\nGPU count: 2\n  GPU 0: Tesla T4\n  GPU 1: Tesla T4\nSat Jan  3 07:51:52 2026       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   39C    P8              9W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   42C    P8              9W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\nAttempting to load secret 'WANDB_API_KEY' from 'kaggle' environment...\n✅ Successfully loaded secret 'WANDB_API_KEY'.\nAttempting to load secret 'HF_TOKEN' from 'kaggle' environment...\n✅ Successfully loaded secret 'HF_TOKEN'.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdungngocpham171\u001b[0m (\u001b[33mdungngocpham171-university-of-science\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\nNote: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n","output_type":"stream"}],"execution_count":2},{"id":"a73b4150","cell_type":"code","source":"!uv pip install --upgrade pip\n# 3. Install PyTorch 1.13\n%cd {OUTPUT_PATH}\n# Force reinstall torch 1.13 to match the model's training environment\n# !uv pip uninstall torch torchvision\n# !uv pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 --extra-index-url https://download.pytorch.org/whl/cu117\n!uv pip install torch==2.9 torchvision\n# 4. Install other dependencies\n\nprint(\"\\n⬇️ Installing Dependencies (Manually fixed)...\")\n# Install xformers compatible with Torch 1.13\n!uv pip install xformers==0.0.16 -q\n\n# Install original dependencies\n!uv pip install transformers==4.33.1 accelerate==0.23.0 diffusers==0.22.0\n!uv pip install gradio==4.8.0 pyyaml pygame opencv-python info-nce-pytorch kornia\n# -----------------------------------------------------------------\n!uv pip install lpips scikit-image pytorch-fid\n# !sudo apt-get update && sudo apt-get install dos2unix\n!uv pip install gdown tqdm\n!uv pip install wandb hf_transfer\n!uv pip install --upgrade pyarrow datasets\nprint(\"\\n✅ Environment setup complete. You can now proceed to Block 2 (Inference).\")","metadata":{"id":"a73b4150","papermill":{"duration":61.239828,"end_time":"2025-12-30T18:54:36.338205","exception":false,"start_time":"2025-12-30T18:53:35.098377","status":"completed"},"tags":[],"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"75ab7573-8060-42de-fa59-c63471c2d12e","execution":{"iopub.status.busy":"2026-01-03T07:52:03.978352Z","iopub.execute_input":"2026-01-03T07:52:03.978822Z","iopub.status.idle":"2026-01-03T07:53:36.187423Z","shell.execute_reply.started":"2026-01-03T07:52:03.978798Z","shell.execute_reply":"2026-01-03T07:53:36.186543Z"}},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 262ms\u001b[0m\u001b[0m                                          \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 138ms\u001b[0m\u001b[0m                                              \n\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 254ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 21ms\u001b[0m\u001b[0m                                 \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mpip\u001b[0m\u001b[2m==24.1.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpip\u001b[0m\u001b[2m==25.3\u001b[0m\n/kaggle/working\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m40 packages\u001b[0m \u001b[2min 567ms\u001b[0m\u001b[0m                                        \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m19 packages\u001b[0m \u001b[2min 40.35s\u001b[0m\u001b[0m                                           \n\u001b[2mUninstalled \u001b[1m17 packages\u001b[0m \u001b[2min 1.94s\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m19 packages\u001b[0m \u001b[2min 2.18s\u001b[0m\u001b[0m                              \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.5.3.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.8.4.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.3.0.75\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.10.2.21\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.2.3.61\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.3.3.83\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cufile-cu12\u001b[0m\u001b[2m==1.13.1.3\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.6.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.9.90\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.6.3.83\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.3.90\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.1.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.8.93\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.6.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.7.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.21.5\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.27.5\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nvshmem-cu12\u001b[0m\u001b[2m==3.3.20\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.13.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.14.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.6.0+cu124 (from https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl)\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.9.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.21.0+cu124 (from https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl)\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.24.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.2.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.5.0\u001b[0m\n\n⬇️ Installing Dependencies (Manually fixed)...\n  \u001b[31m×\u001b[0m Failed to build `xformers==0.0.16`\n\u001b[31m  ├─▶ \u001b[0mThe build backend returned an error\n\u001b[31m  ╰─▶ \u001b[0mCall to `setuptools.build_meta:__legacy__.build_wheel` failed (exit\n\u001b[31m      \u001b[0mstatus: 1)\n\n\u001b[31m      \u001b[0m\u001b[31m[stderr]\u001b[39m\n\u001b[31m      \u001b[0mError in sitecustomize; set PYTHONVERBOSE for traceback:\n\u001b[31m      \u001b[0mModuleNotFoundError: No module named 'wrapt'\n\u001b[31m      \u001b[0mTraceback (most recent call last):\n\u001b[31m      \u001b[0m  File \"<string>\", line 14, in <module>\n\u001b[31m      \u001b[0m  File\n\u001b[31m      \u001b[0m\"/root/.cache/uv/builds-v0/.tmpRKhOzZ/lib/python3.11/site-packages/setuptools/build_meta.py\",\n\u001b[31m      \u001b[0mline 331, in get_requires_for_build_wheel\n\u001b[31m      \u001b[0m    return self._get_build_requires(config_settings, requirements=[])\n\u001b[31m      \u001b[0m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[31m      \u001b[0m  File\n\u001b[31m      \u001b[0m\"/root/.cache/uv/builds-v0/.tmpRKhOzZ/lib/python3.11/site-packages/setuptools/build_meta.py\",\n\u001b[31m      \u001b[0mline 301, in _get_build_requires\n\u001b[31m      \u001b[0m    self.run_setup()\n\u001b[31m      \u001b[0m  File\n\u001b[31m      \u001b[0m\"/root/.cache/uv/builds-v0/.tmpRKhOzZ/lib/python3.11/site-packages/setuptools/build_meta.py\",\n\u001b[31m      \u001b[0mline 512, in run_setup\n\u001b[31m      \u001b[0m    super().run_setup(setup_script=setup_script)\n\u001b[31m      \u001b[0m  File\n\u001b[31m      \u001b[0m\"/root/.cache/uv/builds-v0/.tmpRKhOzZ/lib/python3.11/site-packages/setuptools/build_meta.py\",\n\u001b[31m      \u001b[0mline 317, in run_setup\n\u001b[31m      \u001b[0m    exec(code, locals())\n\u001b[31m      \u001b[0m  File \"<string>\", line 23, in <module>\n\u001b[31m      \u001b[0mModuleNotFoundError: No module named 'torch'\n\n\u001b[31m      \u001b[0m\u001b[36m\u001b[1mhint\u001b[0m\u001b[39m\u001b[1m:\u001b[0m This error likely indicates that `\u001b[36mxformers@0.0.16\u001b[39m` depends\n\u001b[31m      \u001b[0mon `\u001b[36mtorch\u001b[39m`, but doesn't declare it as a build dependency. If\n\u001b[31m      \u001b[0m`\u001b[36mxformers\u001b[39m` is a first-party package, consider adding `\u001b[36mtorch\u001b[39m` to its\n\u001b[31m      \u001b[0m`\u001b[32mbuild-system.requires\u001b[39m`. Otherwise, `\u001b[32muv pip install torch\u001b[39m` into the\n\u001b[31m      \u001b[0menvironment and re-run with `\u001b[32m--no-build-isolation\u001b[39m`.\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m58 packages\u001b[0m \u001b[2min 240ms\u001b[0m\u001b[0m                                        \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m4 packages\u001b[0m \u001b[2min 506ms\u001b[0m\u001b[0m                                             \n\u001b[2mUninstalled \u001b[1m4 packages\u001b[0m \u001b[2min 902ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m4 packages\u001b[0m \u001b[2min 42ms\u001b[0m\u001b[0m                                \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.9.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==0.23.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mdiffusers\u001b[0m\u001b[2m==0.34.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdiffusers\u001b[0m\u001b[2m==0.22.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.21.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.13.3\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.53.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.33.1\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m102 packages\u001b[0m \u001b[2min 522ms\u001b[0m\u001b[0m                                       \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m8 packages\u001b[0m \u001b[2min 1.15s\u001b[0m\u001b[0m                                             \n\u001b[2mUninstalled \u001b[1m7 packages\u001b[0m \u001b[2min 651ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m8 packages\u001b[0m \u001b[2min 69ms\u001b[0m\u001b[0m                                \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mgradio\u001b[0m\u001b[2m==5.38.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mgradio\u001b[0m\u001b[2m==4.8.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mgradio-client\u001b[0m\u001b[2m==1.11.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mgradio-client\u001b[0m\u001b[2m==0.7.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1minfo-nce-pytorch\u001b[0m\u001b[2m==0.1.4\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==2.1.5\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mopencv-python\u001b[0m\u001b[2m==4.12.0.88\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mopencv-python\u001b[0m\u001b[2m==4.11.0.86\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==11.3.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==10.4.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtomlkit\u001b[0m\u001b[2m==0.13.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtomlkit\u001b[0m\u001b[2m==0.12.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mwebsockets\u001b[0m\u001b[2m==15.0.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mwebsockets\u001b[0m\u001b[2m==11.0.3\u001b[0m\n\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mThe package `typer==0.16.0` does not have an extra named `all`\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m49 packages\u001b[0m \u001b[2min 193ms\u001b[0m\u001b[0m                                        \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 25ms\u001b[0m\u001b[0m                                              \n\u001b[2K\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m                                 \u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mlpips\u001b[0m\u001b[2m==0.1.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpytorch-fid\u001b[0m\u001b[2m==0.3.0\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2mAudited \u001b[1m2 packages\u001b[0m \u001b[2min 108ms\u001b[0m\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2mAudited \u001b[1m2 packages\u001b[0m \u001b[2min 111ms\u001b[0m\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m39 packages\u001b[0m \u001b[2min 268ms\u001b[0m\u001b[0m                                        \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m12 packages\u001b[0m \u001b[2min 435ms\u001b[0m\u001b[0m                                            \n\u001b[2mUninstalled \u001b[1m12 packages\u001b[0m \u001b[2min 578ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m12 packages\u001b[0m \u001b[2min 16.57s\u001b[0m\u001b[0m                             \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.11.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.12.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.10.5\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.11.12\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.3.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.3.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==4.4.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==4.4.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.20.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.20.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.36.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==1.2.3\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.4.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.2.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.3.3\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mpyarrow\u001b[0m\u001b[2m==19.0.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpyarrow\u001b[0m\u001b[2m==22.0.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtyper-slim\u001b[0m\u001b[2m==0.20.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtyper-slim\u001b[0m\u001b[2m==0.21.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtzdata\u001b[0m\u001b[2m==2025.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtzdata\u001b[0m\u001b[2m==2025.3\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.5.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.6.2\u001b[0m\n\n✅ Environment setup complete. You can now proceed to Block 2 (Inference).\n","output_type":"stream"}],"execution_count":3},{"id":"bd517dfe","cell_type":"code","source":"# KAGGLE CELL #1: Download checkpoint\nif is_colab:\n  !uv pip install --upgrade \"huggingface-hub>=0.34.0,<1.0\"\nelse:\n  !uv pip install --upgrade \"huggingface-hub==0.25.2\" \"protobuf<5.0.0\" \"numpy<2.0.0\"\nimport os\nimport sys\nfrom tqdm.auto import tqdm\nfrom pathlib import Path\nos.chdir(OUTPUT_PATH)\nimport os\nfrom pathlib import Path\ndef download_from_hf(\n    repo_id: str,\n    local_dir: str = \"ckpt\",\n    allow_patterns=None,\n    force_download: bool = False,\n    repo_type: str = \"model\"\n):\n    if allow_patterns is None:\n        allow_patterns = [\"*.safetensors\", \"scr*\"]\n    print(f\"📥 Downloading checkpoint from Hugging Face Hub to '{local_dir}'...\\n\")\n    from huggingface_hub import snapshot_download\n    snapshot_download(\n        repo_id=repo_id,\n        local_dir=local_dir,\n        repo_type=repo_type,\n        allow_patterns=allow_patterns,\n        force_download=force_download\n    )\n    print(\"\\n✅ Download complete!\")\n    print(f\"\\n📂 Files in {local_dir}/:\")\n    for file in os.listdir(local_dir):\n        if file.endswith(\".safetensors\"):\n            size = os.path.getsize(os.path.join(local_dir, file)) / (1024**2)\n            print(f\"  ✓ {file} ({size:.2f} MB)\")","metadata":{"id":"bd517dfe","papermill":{"duration":12.524295,"end_time":"2025-12-30T18:54:48.878013","exception":false,"start_time":"2025-12-30T18:54:36.353718","status":"completed"},"tags":[],"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"87d50ec4-56e6-4d4a-d37f-fc1b653f9708","execution":{"iopub.status.busy":"2026-01-03T07:53:36.189849Z","iopub.execute_input":"2026-01-03T07:53:36.190094Z","iopub.status.idle":"2026-01-03T07:53:37.061481Z","shell.execute_reply.started":"2026-01-03T07:53:36.190069Z","shell.execute_reply":"2026-01-03T07:53:37.060763Z"}},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m14 packages\u001b[0m \u001b[2min 142ms\u001b[0m\u001b[0m                                        \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m4 packages\u001b[0m \u001b[2min 408ms\u001b[0m\u001b[0m                                             \n\u001b[2mUninstalled \u001b[1m4 packages\u001b[0m \u001b[2min 42ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m4 packages\u001b[0m \u001b[2min 25ms\u001b[0m\u001b[0m                                \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.10.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.12.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==1.2.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.25.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.4.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==6.33.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==4.25.8\u001b[0m\n","output_type":"stream"}],"execution_count":4},{"id":"tOpa7Bh8leVB","cell_type":"code","source":"download_from_hf(\n    repo_id=\"dzungpham/font-diffusion-weights\",\n    local_dir=\"ckpt\",\n    allow_patterns=[\"content*\", \"style*\", \"unet*\", \"scr*\"]\n)","metadata":{"id":"tOpa7Bh8leVB","trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":287,"referenced_widgets":["13dcc8c050c94bf08809b513af66e71d","961fd67e53094ae38e25bb349e7026a6","b18dd409df074df3ad5377b78549ce99","8197301e998f411e8f1c729343489063","0b09965d72f144c2996827b43ff2af54","de3ef430c1a44670906d16eefebd0ccc","19851fb2c35a410591bcc7662a34ba64","474215913b004c27bbd8103a9bd02a34","40551dfe31404308bcd54d33fbd4cccf","580290334e7b4fd48958960885414f92","3e7f58f4df6a4c4c8ee4298d439df592","b4da517c870e45d086af056a2f14644b","b2e744b57e784711adb065a7dcc20b8d","8f19aec8e0e043b396f17a8a3e4d87bd","c54866342be6402f829fe6e469a79176","1c78b84b8ebc43ba8eac35a73a45b16d","80ff0ed5cffd4555a5b12ab771c668c1","f647b6d6657e4bbfadff2e72deed8a6a","79e611ff2d7d4163ae1f3d28bac3bb45","6ee9719c538747f2a072c319a23d60bc","cd70e0836ae14b88985382731ea4e4b5","fec07f02713f45de98c8c7acb5e0ec85","e9b30333cd204203aa4893c193b950ad","912491bb437044a8a7af89ed3f001828","f86e58e72ef84d359862d09aca84a8ba","b4c8c2887c2946b59b4d5d9785a330d7","479ef528237d48318f71a770fc448e52","c4c056dd71d34a8babea55a5b9670d95","e5692a73a28d4fc5a24d6a346fbfb323","8a162b4f8c6e417698522c9492d981ea","756152c336d14a38b14b4a676f59dc3f","ebff0148645547eb8a8d2dc871d6b064","a1252cf387494b54a850e9a87c9c1e96"]},"outputId":"9b94944d-dbaa-4b0c-a1a8-fb66f5255747","execution":{"iopub.status.busy":"2026-01-03T07:53:37.062539Z","iopub.execute_input":"2026-01-03T07:53:37.062770Z","iopub.status.idle":"2026-01-03T07:53:50.141879Z","shell.execute_reply.started":"2026-01-03T07:53:37.062744Z","shell.execute_reply":"2026-01-03T07:53:50.140937Z"}},"outputs":[{"name":"stdout","text":"📥 Downloading checkpoint from Hugging Face Hub to 'ckpt'...\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"content_encoder.pth:   0%|          | 0.00/4.77M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3bf3dd1426244f69c3cc938d54c0652"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"content_encoder.safetensors:   0%|          | 0.00/4.76M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51d5bbf463c34364a6eb3f87235b7741"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"scr_210000.pth:   0%|          | 0.00/284M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"659d840957a94e7eb38e7362a8d96c11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"style_encoder.pth:   0%|          | 0.00/82.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e09010b4c144ef79f1fc4c4a363a8ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"style_encoder.safetensors:   0%|          | 0.00/82.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"075d9cf0e2a7455fbe80634473b65dbc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"unet.pth:   0%|          | 0.00/315M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"152dd61f85a64a04ae2b915dec7fc354"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"unet.safetensors:   0%|          | 0.00/315M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c487d09f2135486689d158b309493ae6"}},"metadata":{}},{"name":"stdout","text":"\n✅ Download complete!\n\n📂 Files in ckpt/:\n  ✓ unet.safetensors (300.34 MB)\n  ✓ content_encoder.safetensors (4.54 MB)\n  ✓ style_encoder.safetensors (78.58 MB)\n","output_type":"stream"}],"execution_count":5},{"id":"Jc4jsIvvlg7T","cell_type":"code","source":"download_from_hf(\n    repo_id=\"dzungpham/font-diffusion-generated-data\",\n    local_dir=\"NomTuTao\",\n    repo_type=\"dataset\",\n    allow_patterns=[\"*Nom*\"]\n)","metadata":{"id":"Jc4jsIvvlg7T","trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":217,"referenced_widgets":["e87aad0600364534ac555d5b84287468","056b7d84091a4e0baeecb43a6e60fb53","c5a77b1eabc845019484ba3e34bbc91c","61029bf3b9944abfa866fdf6227573b6","729af54f5f16497593f0b4a3d426dd6a","ea313d8f00884ec68f9753669d3cd61a","a1d5643bee8646d69e77e1a0b116833a","443b2e65f93849eca9cab42f36cb3e39","03431a179ddb4e409c541f44f5d2e896","fb86821f6cc94bdaae6e51dc463ba077","965eee19a9ac491dba0d874ff3e42078","82549384f46044f48a310cfb6fd68cae","06cf6ecf71004ee9bb919d7e82007e1d","6b008ff294e74e5686e677afdae7abcc","fbeb3be394df4b07bee67f50cb7923ef","0fe235807a9843f2ad671c6dc095f031","3478954c1b684265adfc587b481794e8","32ed6b57bf2a4699935d4dd7691080f2","e7430f0928f844bdaba7b572cd13c969","a75085decd55451ea653273aeee544ee","98b40b0e16fb4dacb6b1bd5f526c5c68","0bd634cdae0d4371bb91e57895a25a6a","22d3b0d8e1384e1fbcec471d606bd385","33be7ff0037d446ea4592d2b43eebc80","ac1b8a48eac547609b31cdff6dd1898e","c0e1a8eccd2141c4973225dc867c76e0","17efc0dec3f24ce5836696645768e9cc","f248b56f31ee478b8e7de22d3bc5051f","08b2b098800f4420a2b59544f54a4d5b","694b02dd3eb043a78267714fd01ae53e","257493b9863c41b68f40a184f67af002","615d312d90ee46939ace0e004887851a","a2f0b00d233841368854f74b7921ffd7"]},"outputId":"5dfb0dba-97eb-460e-9019-8ab6648be7dc","execution":{"iopub.status.busy":"2026-01-03T07:53:50.142875Z","iopub.execute_input":"2026-01-03T07:53:50.143769Z","iopub.status.idle":"2026-01-03T07:53:50.874076Z","shell.execute_reply.started":"2026-01-03T07:53:50.143746Z","shell.execute_reply":"2026-01-03T07:53:50.873219Z"}},"outputs":[{"name":"stdout","text":"📥 Downloading checkpoint from Hugging Face Hub to 'NomTuTao'...\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Ds_10k_ChuNom_TuTao.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f15332cdf5c4b539abe365bad590928"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Ds_300_ChuNom_TuTao.csv: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"add0e3fb6c7645d4b2513d3604ae3286"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Top184_PureNomChar.xlsx:   0%|          | 0.00/15.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5dd369d7ddd41f4b35adbd87deb823d"}},"metadata":{}},{"name":"stdout","text":"\n✅ Download complete!\n\n📂 Files in NomTuTao/:\n","output_type":"stream"}],"execution_count":6},{"id":"767e8ea2","cell_type":"code","source":"# @title Unzipping all archived files\nimport os\nimport glob\nfrom zipfile import ZipFile\n\nzip_file_paths = glob.glob(os.path.join(INPUT_PATH, '*.zip'))\n\nif not zip_file_paths:\n    print(f'No .zip files found in {INPUT_PATH}.')\nelse:\n    for zip_file_path in zip_file_paths:\n        if os.path.exists(zip_file_path):\n            print(f'Unzipping {zip_file_path}...')\n            !unzip -o {zip_file_path} -d ./\n            print(f'Unzipping of {zip_file_path} complete.')\n        else:\n            print(f'Error: The file {zip_file_path} was not found (post-glob check).')","metadata":{"id":"767e8ea2","papermill":{"duration":0.023805,"end_time":"2025-12-30T18:54:48.917163","exception":false,"start_time":"2025-12-30T18:54:48.893358","status":"completed"},"tags":[],"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"baf300a9-b290-4461-b300-1916ebfba814","execution":{"iopub.status.busy":"2026-01-03T07:53:50.874947Z","iopub.execute_input":"2026-01-03T07:53:50.875194Z","iopub.status.idle":"2026-01-03T07:53:51.129594Z","shell.execute_reply.started":"2026-01-03T07:53:50.875176Z","shell.execute_reply":"2026-01-03T07:53:51.128875Z"}},"outputs":[{"name":"stdout","text":"No .zip files found in /kaggle/input/.\n","output_type":"stream"}],"execution_count":7},{"id":"4f4cf20b","cell_type":"code","source":"print(\"Model files:\")\n!ls -larth {OUTPUT_PATH}/ckpt","metadata":{"id":"4f4cf20b","papermill":{"duration":0.140282,"end_time":"2025-12-30T18:54:50.749810","exception":false,"start_time":"2025-12-30T18:54:50.609528","status":"completed"},"tags":[],"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c594f2b9-0375-4de5-bccd-946e8f638e88","execution":{"iopub.status.busy":"2026-01-03T07:53:51.130335Z","iopub.execute_input":"2026-01-03T07:53:51.130606Z","iopub.status.idle":"2026-01-03T07:53:51.279781Z","shell.execute_reply.started":"2026-01-03T07:53:51.130586Z","shell.execute_reply":"2026-01-03T07:53:51.278737Z"}},"outputs":[{"name":"stdout","text":"Model files:\ntotal 1.1G\ndrwxr-xr-x 3 root root 4.0K Jan  3 07:53 .cache\n-rw-r--r-- 1 root root 4.6M Jan  3 07:53 content_encoder.pth\n-rw-r--r-- 1 root root 4.6M Jan  3 07:53 content_encoder.safetensors\n-rw-r--r-- 1 root root 272M Jan  3 07:53 scr_210000.pth\n-rw-r--r-- 1 root root  79M Jan  3 07:53 style_encoder.pth\n-rw-r--r-- 1 root root  79M Jan  3 07:53 style_encoder.safetensors\n-rw-r--r-- 1 root root 301M Jan  3 07:53 unet.pth\n-rw-r--r-- 1 root root 301M Jan  3 07:53 unet.safetensors\ndrwxr-xr-x 3 root root 4.0K Jan  3 07:53 .\ndrwxr-xr-x 6 root root 4.0K Jan  3 07:53 ..\n","output_type":"stream"}],"execution_count":8},{"id":"92cff682","cell_type":"code","source":"# @title Exporting train original data from HF\n%cd {OUTPUT_PATH}\nHF_USERNAME = \"dzungpham\"\n# Train Split\n!python FontDiffusion/export_hf_dataset_to_disk.py \\\n  --output-dir \"my_dataset/train_original\" \\\n  --repo-id {HF_USERNAME}/font-diffusion-generated-data \\\n  --split \"train_original\" \\\n  --token HF_TOKEN","metadata":{"id":"92cff682","papermill":{"duration":0.104394,"end_time":"2025-12-30T18:54:50.869230","exception":false,"start_time":"2025-12-30T18:54:50.764836","status":"completed"},"tags":[],"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"49767de4-6474-4044-dcee-b0e9d8e4eef7","execution":{"iopub.status.busy":"2026-01-03T07:53:51.281202Z","iopub.execute_input":"2026-01-03T07:53:51.281901Z","iopub.status.idle":"2026-01-03T07:54:39.452471Z","shell.execute_reply.started":"2026-01-03T07:53:51.281868Z","shell.execute_reply":"2026-01-03T07:54:39.451659Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n2026-01-03 07:53:58,058 - __main__ - INFO - Starting dataset export...\n2026-01-03 07:53:58,058 - __main__ - INFO - Loading dataset from Hub: dzungpham/font-diffusion-generated-data (split: train_original)\nREADME.md: 3.05kB [00:00, 10.2MB/s]\ntrain_original-00000-of-00001.parquet: 100%|█▉| 192M/192M [00:00<00:00, 223MB/s]\ntrain-00000-of-00001.parquet: 100%|██████████▉| 124M/124M [00:00<00:00, 191MB/s]\nval-00000-of-00001.parquet: 100%|██████████| 5.96M/5.96M [00:00<00:00, 68.5MB/s]\nGenerating train_original split: 100%|█| 14620/14620 [00:00<00:00, 29386.98 exam\nGenerating train split: 100%|█████| 9360/9360 [00:00<00:00, 30904.44 examples/s]\nGenerating val split: 100%|█████████| 585/585 [00:00<00:00, 47396.47 examples/s]\n2026-01-03 07:54:04,446 - __main__ - INFO - Loaded 14620 samples from Hub\n2026-01-03 07:54:04,447 - __main__ - INFO - Created directory structure at my_dataset/train_original\n2026-01-03 07:54:04,447 - __main__ - INFO - Exporting images...\nExporting images: 100%|██████████████| 14620/14620 [00:34<00:00, 428.16sample/s]\n2026-01-03 07:54:38,594 - __main__ - INFO - Exported 998 content images, 14620 target images\n2026-01-03 07:54:38,732 - __main__ - INFO - Saved checkpoint with 14620 generations: 998 chars, 15 styles\n2026-01-03 07:54:38,733 - __main__ - INFO - Export completed successfully\n2026-01-03 07:54:38,739 - __main__ - INFO - Successfully exported to my_dataset/train_original\n  ContentImage/\n  TargetImage/\n  results_checkpoint.json\n","output_type":"stream"}],"execution_count":9},{"id":"lh696hc0l1jr","cell_type":"code","source":"# @title Exporting train data from HF\n!python FontDiffusion/export_hf_dataset_to_disk.py \\\n  --output-dir \"my_dataset/train\" \\\n  --repo-id {HF_USERNAME}/font-diffusion-generated-data \\\n  --split \"train\" \\\n  --token HF_TOKEN","metadata":{"id":"lh696hc0l1jr","trusted":true,"execution":{"iopub.status.busy":"2026-01-03T07:54:39.454729Z","iopub.execute_input":"2026-01-03T07:54:39.454966Z","iopub.status.idle":"2026-01-03T07:55:27.621167Z","shell.execute_reply.started":"2026-01-03T07:54:39.454942Z","shell.execute_reply":"2026-01-03T07:55:27.620388Z"}},"outputs":[{"name":"stdout","text":"2026-01-03 07:54:42,320 - __main__ - INFO - Starting dataset export...\n2026-01-03 07:54:42,321 - __main__ - INFO - Loading dataset from Hub: dzungpham/font-diffusion-generated-data (split: train)\n2026-01-03 07:55:04,848 - __main__ - INFO - Loaded 9360 samples from Hub\n2026-01-03 07:55:04,848 - __main__ - INFO - Created directory structure at my_dataset/train\n2026-01-03 07:55:04,849 - __main__ - INFO - Exporting images...\nExporting images: 100%|████████████████| 9360/9360 [00:22<00:00, 425.13sample/s]\n2026-01-03 07:55:26,866 - __main__ - INFO - Exported 799 content images, 9360 target images\n2026-01-03 07:55:26,952 - __main__ - INFO - Saved checkpoint with 9360 generations: 799 chars, 12 styles\n2026-01-03 07:55:26,952 - __main__ - INFO - Export completed successfully\n2026-01-03 07:55:26,956 - __main__ - INFO - Successfully exported to my_dataset/train\n  ContentImage/\n  TargetImage/\n  results_checkpoint.json\n","output_type":"stream"}],"execution_count":10},{"id":"rzW-I7QMl2ik","cell_type":"code","source":"# @title Exporting validation data from HF\n!python FontDiffusion/export_hf_dataset_to_disk.py \\\n  --output-dir \"my_dataset/val\" \\\n  --repo-id {HF_USERNAME}/font-diffusion-generated-data \\\n  --split \"val\" \\\n  --token HF_TOKEN","metadata":{"id":"rzW-I7QMl2ik","trusted":true,"execution":{"iopub.status.busy":"2026-01-03T07:55:27.622148Z","iopub.execute_input":"2026-01-03T07:55:27.622419Z","iopub.status.idle":"2026-01-03T07:55:35.481305Z","shell.execute_reply.started":"2026-01-03T07:55:27.622394Z","shell.execute_reply":"2026-01-03T07:55:35.480548Z"}},"outputs":[{"name":"stdout","text":"2026-01-03 07:55:30,466 - __main__ - INFO - Starting dataset export...\n2026-01-03 07:55:30,466 - __main__ - INFO - Loading dataset from Hub: dzungpham/font-diffusion-generated-data (split: val)\n2026-01-03 07:55:33,303 - __main__ - INFO - Loaded 585 samples from Hub\n2026-01-03 07:55:33,304 - __main__ - INFO - Created directory structure at my_dataset/val\n2026-01-03 07:55:33,304 - __main__ - INFO - Exporting images...\nExporting images: 100%|██████████████████| 585/585 [00:01<00:00, 385.42sample/s]\n2026-01-03 07:55:34,822 - __main__ - INFO - Exported 199 content images, 585 target images\n2026-01-03 07:55:34,828 - __main__ - INFO - Saved checkpoint with 585 generations: 199 chars, 3 styles\n2026-01-03 07:55:34,828 - __main__ - INFO - Export completed successfully\n2026-01-03 07:55:34,829 - __main__ - INFO - Successfully exported to my_dataset/val\n  ContentImage/\n  TargetImage/\n  results_checkpoint.json\n","output_type":"stream"}],"execution_count":11},{"id":"6db9c1d6-dd60-479c-92c4-2f653e4d48fd","cell_type":"code","source":"# @title Show fonts and styles images\nprint(\"Fonts currently in fonts/ folder\")\n!ls -lt FontDiffusion/fonts\nprint(\"Styles in style_images/ folder\")\n!ls -l FontDiffusion/styles_images","metadata":{"trusted":true,"id":"6db9c1d6-dd60-479c-92c4-2f653e4d48fd","colab":{"base_uri":"https://localhost:8080/"},"outputId":"db60cf06-b497-4ae2-8233-1f0de1a512fd","execution":{"iopub.status.busy":"2026-01-03T07:55:35.482420Z","iopub.execute_input":"2026-01-03T07:55:35.482746Z","iopub.status.idle":"2026-01-03T07:55:35.743755Z","shell.execute_reply.started":"2026-01-03T07:55:35.482707Z","shell.execute_reply":"2026-01-03T07:55:35.743007Z"}},"outputs":[{"name":"stdout","text":"Fonts currently in fonts/ folder\ntotal 332584\n-rw-r--r-- 1 root root 26929728 Jan  3 07:51  NomNaTongLight2.ttf\n-rw-r--r-- 1 root root 14574480 Jan  3 07:51  NomNaTongLight.ttf\n-rw-r--r-- 1 root root 31729820 Jan  3 07:51  NomNaTong-Regular2.otf\n-rw-r--r-- 1 root root 14574552 Jan  3 07:51  NomNaTong-Regular.ttf\n-rw-r--r-- 1 root root  9424552 Jan  3 07:51  NomNaTong-Regular.otf\n-rw-r--r-- 1 root root 12967288 Jan  3 07:51  HanaMinC.otf\n-rw-r--r-- 1 root root 30739236 Jan  3 07:51  HanaMinB.ttf\n-rw-r--r-- 1 root root 32201032 Jan  3 07:51  HanaMinB.otf\n-rw-r--r-- 1 root root 22761228 Jan  3 07:51  HanaMinA.ttf\n-rw-r--r-- 1 root root 31621108 Jan  3 07:51  HanaMinA.otf\n-rw-r--r-- 1 root root 18202176 Jan  3 07:51 'Han-nom Minh 1.42.otf'\n-rw-r--r-- 1 root root 19505228 Jan  3 07:51  Han-Nom-Khai-Regular-300623.ttf\n-rw-r--r-- 1 root root 20368044 Jan  3 07:51 'Han-Nom Kai 1.00.otf'\n-rw-r--r-- 1 root root 33815824 Jan  3 07:51 'HAN NOM B.ttf'\n-rw-r--r-- 1 root root 21320444 Jan  3 07:51 'HAN NOM A.ttf'\nStyles in style_images/ folder\ntotal 520\n-rw-r--r-- 1 root root  55480 Jan  3 07:51 1.png\n-rw-r--r-- 1 root root  73193 Jan  3 07:51 2.png\n-rw-r--r-- 1 root root  62305 Jan  3 07:51 3.png\n-rw-r--r-- 1 root root  47202 Jan  3 07:51 4.png\n-rw-r--r-- 1 root root  40943 Jan  3 07:51 5.png\n-rw-r--r-- 1 root root  11400 Jan  3 07:51 6.png\n-rw-r--r-- 1 root root  26508 Jan  3 07:51 hanh.png\n-rw-r--r-- 1 root root   1569 Jan  3 07:51 hanhthu1.jpg\n-rw-r--r-- 1 root root   1036 Jan  3 07:51 hanhthu2.jpg\n-rw-r--r-- 1 root root 100710 Jan  3 07:51 khai.png\n-rw-r--r-- 1 root root  36429 Jan  3 07:51 le.png\n-rw-r--r-- 1 root root   1086 Jan  3 07:51 lethu1.jpg\n-rw-r--r-- 1 root root   1182 Jan  3 07:51 lethu2.jpg\n-rw-r--r-- 1 root root  17600 Jan  3 07:51 thao.png\n-rw-r--r-- 1 root root  27078 Jan  3 07:51 trien.png\n","output_type":"stream"}],"execution_count":12},{"id":"29deed1d","cell_type":"code","source":"# @title Run batch generation\nif is_colab:\n  !uv pip install --upgrade \"huggingface-hub>=0.34.0,<1.0\"\nelse:\n  !uv pip install --upgrade \"huggingface-hub==0.25.2\" \"protobuf<5.0.0\" \"numpy<2.0.0\"\n%cd {OUTPUT_PATH}\n# No need to pass num_processes because accelerate auto detect num gpus on machine\n!accelerate launch FontDiffusion/sample_batch_multi_gpus.py \\\n    --characters \"NomTuTao/Ds_10k_ChuNom_TuTao.txt\" \\\n    --style_images \"FontDiffusion/styles_images\" \\\n    --ckpt_dir \"ckpt/\" \\\n    --ttf_path \"FontDiffusion/fonts/NomNaTong-Regular.otf\" \\\n    --output_dir \"my_dataset/train_original\" \\\n    --num_inference_steps 20 \\\n    --guidance_scale 7.5 \\\n    --start_line 900 \\\n    --end_line 1000 \\\n    --batch_size 35 \\\n    --save_interval 1 \\\n    --channels_last \\\n    --seed 42 \\\n    --compile \\\n    --enable_xformers","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"29deed1d","outputId":"1d74908d-cc48-4187-d45d-85029535655a","papermill":{"duration":10.53661,"end_time":"2025-12-30T18:55:01.421093","exception":false,"start_time":"2025-12-30T18:54:50.884483","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T07:20:36.994064Z","iopub.execute_input":"2026-01-03T07:20:36.994574Z","iopub.status.idle":"2026-01-03T07:39:30.100313Z","shell.execute_reply.started":"2026-01-03T07:20:36.994534Z","shell.execute_reply":"2026-01-03T07:39:30.099384Z"}},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m14 packages\u001b[0m \u001b[2min 56ms\u001b[0m\u001b[0m                                         \u001b[0m\n\u001b[2mAudited \u001b[1m14 packages\u001b[0m \u001b[2min 0.11ms\u001b[0m\u001b[0m\n/kaggle/working\nThe cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n0it [00:00, ?it/s]\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\nThe following values were not passed to `accelerate launch` and had defaults used instead:\n\t`--num_processes` was set to a value of `2`\n\t\tMore than one GPU was found, enabling multi-GPU training.\n\t\tIf this was unintended please pass in `--num_processes=1`.\n\t`--num_machines` was set to a value of `1`\n\t`--mixed_precision` was set to a value of `'no'`\n\t`--dynamo_backend` was set to a value of `'no'`\nTo avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n2026-01-03 07:20:53.807501: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2026-01-03 07:20:53.807501: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767424853.988625     515 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767424853.988610     514 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767424854.044892     515 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1767424854.044895     514 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\npygame 2.6.1 (SDL 2.28.4, Python 3.11.13)\nHello from the pygame community. https://www.pygame.org/contribute.html\npygame 2.6.1 (SDL 2.28.4, Python 3.11.13)\nHello from the pygame community. https://www.pygame.org/contribute.html\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n2026-01-03 07:21:07,785 | INFO | ============================================================\n2026-01-03 07:21:07,786 | INFO | ============================================================\n2026-01-03 07:21:07,786 | INFO | FONTDIFFUSER SYNTHESIS DATA GENERATION MAGIC\n2026-01-03 07:21:07,786 | INFO | FONTDIFFUSER SYNTHESIS DATA GENERATION MAGIC\n2026-01-03 07:21:07,786 | INFO | ============================================================\n2026-01-03 07:21:07,786 | INFO | ============================================================\n2026-01-03 07:21:08,028 | INFO | 📖 Loading characters from file: NomTuTao/Ds_10k_ChuNom_TuTao.txt\n2026-01-03 07:21:08,029 | INFO |    Lines 900 to 1000 (total file: 10174 lines)\n2026-01-03 07:21:08,029 | INFO | 📖 Loading characters from file: NomTuTao/Ds_10k_ChuNom_TuTao.txt\n2026-01-03 07:21:08,029 | INFO |    Processing 101 lines...\n2026-01-03 07:21:08,029 | INFO |    Lines 900 to 1000 (total file: 10174 lines)\n2026-01-03 07:21:08,029 | INFO |    Processing 101 lines...\n📖 Reading character file: 100%|\u001b[38;2;65;166;126m████████████████████████████\u001b[0m| 101/101 [00:00<00:00, 310kiteration/s]\u001b[0m\n2026-01-03 07:21:08,030 | INFO | ✅ Successfully loaded 101 single characters.\n📖 Reading character file: 100%|\u001b[38;2;65;166;126m████████████████████████████\u001b[0m| 101/101 [00:00<00:00, 317kiteration/s]\u001b[0m\n2026-01-03 07:21:08,030 | INFO | ✅ Successfully loaded 101 single characters.\n2026-01-03 07:21:08,030 | INFO | 📂 Loading 15 style images from directory...\n2026-01-03 07:21:08,031 | INFO | 📂 Loading 15 style images from directory...\n✓ Verifying style images: 100%|\u001b[38;2;65;166;126m██████████████████████████\u001b[0m| 15.0/15.0 [00:00<00:00, 42.3kiteration/s]\u001b[0m\n✓ Verifying style images: 100%|\u001b[38;2;65;166;126m██████████████████████████\u001b[0m| 15.0/15.0 [00:00<00:00, 46.4kiteration/s]\u001b[0m\n2026-01-03 07:21:08,031 | INFO | Initializing font manager...\nerror: XDG_RUNTIME_DIR not set in the environment.\nerror: XDG_RUNTIME_DIR not set in the environment.\nALSA lib confmisc.c:855:(parse_card) cannot find card '0'\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\nALSA lib confmisc.c:422:(snd_func_concat) error evaluating stringsALSA lib confmisc.c:855:(parse_card) \ncannot find card '0'ALSA lib conf.c:5178:(_snd_config_evaluate) \nfunction snd_func_concat returned error: No such file or directory\nALSA lib conf.c:5178:(_snd_config_evaluate) ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\nfunction snd_func_card_inum returned error: No such file or directoryALSA lib conf.c:5178:(_snd_config_evaluate) \nfunction snd_func_refer returned error: No such file or directoryALSA lib confmisc.c:422:(snd_func_concat) \nerror evaluating strings\nALSA lib conf.c:5701:(snd_config_expand) ALSA lib conf.c:5178:(_snd_config_evaluate) Evaluate error: No such file or directoryfunction snd_func_concat returned error: No such file or directory\n\nALSA lib confmisc.c:1334:(snd_func_refer) ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) error evaluating name\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\nALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\nALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\nUnknown PCM default\n2026-01-03 07:21:08,233 | INFO | ✓ Loaded font: NomNaTong-Regular2026-01-03 07:21:08,233 | INFO | ✓ Loaded font: NomNaTong-Regular\n\n2026-01-03 07:21:08,233 | INFO | ✓ Loaded 1 fonts.\n2026-01-03 07:21:08,233 | INFO | 📊 Configuration:\n2026-01-03 07:21:08,233 | INFO |   Dataset split: train_original\n2026-01-03 07:21:08,233 | INFO |   Characters: 101 (lines 900-1000)\n2026-01-03 07:21:08,233 | INFO |   Styles: 15\n2026-01-03 07:21:08,233 | INFO |   Output Directory: my_dataset/train_original\n2026-01-03 07:21:08,233 | INFO |   Checkpoint Directory: ckpt/\n2026-01-03 07:21:08,233 | INFO |   Device: cuda\n2026-01-03 07:21:08,233 | INFO |   Batch Size: 35\n2026-01-03 07:21:08,233 | INFO |   Using 2 GPUs\n2026-01-03 07:21:08,233 | INFO |   Results checkpoint path: my_dataset/train_original/results_checkpoint.json\n2026-01-03 07:21:08,317 | INFO | ✓ Loaded checkpoint: 14220 unique generations\n2026-01-03 07:21:08,317 | INFO |   Total raw entries: 14220\n2026-01-03 07:21:08,322 | INFO | \nLoading FontDiffuser pipeline...\nLoading FontDiffuser pipeline...\nLoad the down block  DownBlock2D\n2026-01-03 07:21:08,325 | INFO | ✓ Loaded checkpoint: 14220 unique generations\n2026-01-03 07:21:08,325 | INFO |   Total raw entries: 14220\nLoad the down block  MCADownBlock2D\nLoading FontDiffuser pipeline...\nLoad the down block  DownBlock2D\nThe style_attention cross attention dim in Down Block 1 layer is 1024\nLoad the down block  MCADownBlock2D\nThe style_attention cross attention dim in Down Block 1 layer is 1024\nThe style_attention cross attention dim in Down Block 2 layer is 1024\nThe style_attention cross attention dim in Down Block 2 layer is 1024\nLoad the down block  MCADownBlock2D\nLoad the down block  MCADownBlock2D\nThe style_attention cross attention dim in Down Block 1 layer is 1024\nThe style_attention cross attention dim in Down Block 1 layer is 1024\nThe style_attention cross attention dim in Down Block 2 layer is 1024\nThe style_attention cross attention dim in Down Block 2 layer is 1024\nLoad the down block  DownBlock2D\nLoad the down block  DownBlock2D\nLoad the up block  UpBlock2D\nLoad the up block  UpBlock2D\nLoad the up block  StyleRSIUpBlock2D\nLoad the up block  StyleRSIUpBlock2D\nLoad the up block  StyleRSIUpBlock2D\nLoad the up block  StyleRSIUpBlock2D\nLoad the up block  UpBlock2D\nLoad the up block  UpBlock2D\nParam count for Ds initialized parameters: 20591296\nGet CG-GAN Style Encoder!\nParam count for Ds initialized parameters: 20591296\nGet CG-GAN Style Encoder!\nParam count for Ds initialized parameters: 1187008\nGet CG-GAN Content Encoder!\n✓ Loaded model state_dict successfully\nConverting to channels-last memory format...\nParam count for Ds initialized parameters: 1187008\nGet CG-GAN Content Encoder!\n✓ Loaded model state_dict successfully\nConverting to channels-last memory format...\n✓ Model moved to device\n✓ Loaded training DDPM scheduler successfully\n✓ Loaded DPM-Solver pipeline successfully\n2026-01-03 07:21:09,814 | INFO | 🔧 Compiling model components with torch.compile...\n/kaggle/working/FontDiffusion/sample_batch_multi_gpus.py:524: FutureWarning: Accessing config attribute `unet` directly via 'FontDiffuserModelDPM' object attribute is deprecated. Please access 'unet' over 'FontDiffuserModelDPM's config object instead, e.g. 'unet.config.unet'.\n  if hasattr(pipe.model, \"unet\"):\n✓ Model moved to device\n✓ Loaded training DDPM scheduler successfully\n✓ Loaded DPM-Solver pipeline successfully\n/kaggle/working/FontDiffusion/sample_batch_multi_gpus.py:524: FutureWarning: Accessing config attribute `unet` directly via 'FontDiffuserModelDPM' object attribute is deprecated. Please access 'unet' over 'FontDiffuserModelDPM's config object instead, e.g. 'unet.config.unet'.\n  if hasattr(pipe.model, \"unet\"):\n/kaggle/working/FontDiffusion/sample_batch_multi_gpus.py:526: FutureWarning: Accessing config attribute `style_encoder` directly via 'FontDiffuserModelDPM' object attribute is deprecated. Please access 'style_encoder' over 'FontDiffuserModelDPM's config object instead, e.g. 'unet.config.style_encoder'.\n  if hasattr(pipe.model, \"style_encoder\"):\n/kaggle/working/FontDiffusion/sample_batch_multi_gpus.py:526: FutureWarning: Accessing config attribute `style_encoder` directly via 'FontDiffuserModelDPM' object attribute is deprecated. Please access 'style_encoder' over 'FontDiffuserModelDPM's config object instead, e.g. 'unet.config.style_encoder'.\n  if hasattr(pipe.model, \"style_encoder\"):\n/kaggle/working/FontDiffusion/sample_batch_multi_gpus.py:530: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModelDPM' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModelDPM's config object instead, e.g. 'unet.config.content_encoder'.\n  if hasattr(pipe.model, \"content_encoder\"):\n/kaggle/working/FontDiffusion/sample_batch_multi_gpus.py:530: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModelDPM' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModelDPM's config object instead, e.g. 'unet.config.content_encoder'.\n  if hasattr(pipe.model, \"content_encoder\"):\nSetting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n2026-01-03 07:21:12,432 | INFO | ✓ Compilation complete.\nSetting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\nDownloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n100%|█████████████████████████████████████████| 233M/233M [00:01<00:00, 211MB/s]\n100%|█████████████████████████████████████████| 233M/233M [00:01<00:00, 188MB/s]\nLoading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/alex.pth\nLoading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/alex.pth\n/usr/local/lib/python3.11/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n  warnings.warn(  # warn only once\n[rank0]:[W103 07:21:14.415475714 ProcessGroupNCCL.cpp:5068] Guessing device ID based on global rank. This can cause a hang if rank to GPU mapping is heterogeneous. You can specify device_id in init_process_group()\n2026-01-03 07:21:15,043 | INFO | Generating content images for 101 characters\nGPU 0: 100%|\u001b[38;2;65;166;126m██████████████████████████████████████████████\u001b[0m| 51.0/51.0 [00:03<00:00, 13.9iteration/s]\u001b[0m\n2026-01-03 07:21:18,778 | INFO | Generated 100 content images\n2026-01-03 07:21:18,782 | INFO | Generating images: 101 chars × 15 styles\n2026-01-03 07:21:18,782 | INFO | Using 2 GPUs\n2026-01-03 07:21:18,782 | INFO | Primary font: NomNaTong-Regular\n  📸 Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126m██████████████████\u001b[0m| 50.0/50.0 [00:00<00:00, 1.00kiteration/s]\u001b[0m\n    🚀 Batch Inference:   0%|\u001b[38;2;16;85;201m                                    \u001b[0m| 0.00/2.00 [00:00<?, ?iteration/s]\u001b[0m\n  📸 Preparing NomNaTong-Regular:   0%|\u001b[36m                          \u001b[0m| 0.00/50.0 [00:00<?, ?iteration/s]\u001b[0m\u001b[A\n  📸 Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126m████████████████████\u001b[0m| 50.0/50.0 [00:00<00:00, 885iteration/s]\u001b[0m\u001b[A\n\n    🚀 Batch Inference:   0%|\u001b[38;2;16;85;201m                                    \u001b[0m| 0.00/2.00 [00:00<?, ?iteration/s]\u001b[0m\u001b[A/usr/local/lib/python3.11/dist-packages/torch/backends/cuda/__init__.py:131: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n  return torch._C._get_cublas_allow_tf32()\n/usr/local/lib/python3.11/dist-packages/torch/backends/cuda/__init__.py:131: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n  return torch._C._get_cublas_allow_tf32()\n[rank0]:W0103 07:21:30.823000 514 torch/_inductor/utils.py:1558] [0/0] Not enough SMs to use max_autotune_gemm mode\n[rank1]:W0103 07:21:30.824000 515 torch/_inductor/utils.py:1558] [0/0] Not enough SMs to use max_autotune_gemm mode\n\n    🚀 Batch Inference:  50%|\u001b[38;2;16;85;201m███████████████               \u001b[0m| 1.00/2.00 [03:26<03:26, 207s/iteration]\u001b[0m\u001b[A[rank0]:W0103 07:25:11.121000 514 torch/fx/experimental/symbolic_shapes.py:6833] [2/1] _maybe_guard_rel() was called on non-relation expression Eq(s53, s54) | Eq(s54, 1)\n[rank1]:W0103 07:25:11.165000 515 torch/fx/experimental/symbolic_shapes.py:6833] [2/1] _maybe_guard_rel() was called on non-relation expression Eq(s53, s54) | Eq(s54, 1)\n\n    🚀 Batch Inference:   0%|\u001b[38;2;16;85;201m                                 \u001b[0m| 3.00/? [06:53<00:00, 131s/iteration]\u001b[0m\u001b[A\n    🚀 Batch Inference: 100%|\u001b[38;2;65;166;126m██████████████████████████████\u001b[0m| 2.00/2.00 [06:53<00:00, 207s/iteration]\u001b[0m\u001b[A\n/usr/local/lib/python3.11/dist-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.\n  warnings.warn(  # warn only once\n    🚀 Batch Inference: 100%|\u001b[38;2;65;166;126m██████████████████████████████\u001b[0m| 2.00/2.00 [06:56<00:00, 208s/iteration]\u001b[0m\n2026-01-03 07:28:18,416 | INFO |   ✅ Saved results_checkpoint.json (14270 generations)              \n2026-01-03 07:28:18,416 | INFO | Checkpoint saved at 1/8 styles                                     :59<?, ?iteration/s]\u001b[0m\n  📸 Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126m████████████████████\u001b[0m| 50.0/50.0 [00:00<00:00, 987iteration/s]\u001b[0m\n    🚀 Batch Inference:   0%|\u001b[38;2;16;85;201m                                    \u001b[0m| 0.00/2.00 [00:00<?, ?iteration/s]\u001b[0m\n  📸 Preparing NomNaTong-Regular:   0%|\u001b[36m                          \u001b[0m| 0.00/50.0 [00:00<?, ?iteration/s]\u001b[0m\u001b[A\n  📸 Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126m██████████████████\u001b[0m| 50.0/50.0 [00:00<00:00, 1.01kiteration/s]\u001b[0m\u001b[A\n\n    🚀 Batch Inference:   0%|\u001b[38;2;16;85;201m                                    \u001b[0m| 0.00/2.00 [00:00<?, ?iteration/s]\u001b[0m\u001b[A\n    🚀 Batch Inference:  50%|\u001b[38;2;16;85;201m██████████████▌              \u001b[0m| 1.00/2.00 [00:58<00:58, 58.2s/iteration]\u001b[0m\u001b[A\n    🚀 Batch Inference:   0%|\u001b[38;2;16;85;201m                                \u001b[0m| 3.00/? [01:19<00:00, 23.2s/iteration]\u001b[0m\u001b[A\n    🚀 Batch Inference: 100%|\u001b[38;2;65;166;126m█████████████████████████████\u001b[0m| 2.00/2.00 [01:19<00:00, 39.6s/iteration]\u001b[0m\u001b[A\n    🚀 Batch Inference: 100%|\u001b[38;2;65;166;126m█████████████████████████████\u001b[0m| 2.00/2.00 [01:23<00:00, 42.0s/iteration]\u001b[0m\n2026-01-03 07:29:46,097 | INFO |   ✅ Saved results_checkpoint.json (14320 generations)              \n2026-01-03 07:29:46,098 | INFO | Checkpoint saved at 2/8 styles                                     :57, 420s/iteration]\u001b[0m\n  📸 Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126m████████████████████\u001b[0m| 50.0/50.0 [00:00<00:00, 953iteration/s]\u001b[0m\n    🚀 Batch Inference:   0%|\u001b[38;2;16;85;201m                                    \u001b[0m| 0.00/2.00 [00:00<?, ?iteration/s]\u001b[0m\n  📸 Preparing NomNaTong-Regular:   0%|\u001b[36m                          \u001b[0m| 0.00/50.0 [00:00<?, ?iteration/s]\u001b[0m\u001b[A\n  📸 Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126m████████████████████\u001b[0m| 50.0/50.0 [00:00<00:00, 959iteration/s]\u001b[0m\u001b[A\n\n    🚀 Batch Inference:   0%|\u001b[38;2;16;85;201m                                    \u001b[0m| 0.00/2.00 [00:00<?, ?iteration/s]\u001b[0m\u001b[A\n    🚀 Batch Inference:  50%|\u001b[38;2;16;85;201m██████████████▌              \u001b[0m| 1.00/2.00 [00:59<00:59, 59.0s/iteration]\u001b[0m\u001b[A\n    🚀 Batch Inference:   0%|\u001b[38;2;16;85;201m                                \u001b[0m| 3.00/? [01:19<00:00, 23.2s/iteration]\u001b[0m\u001b[A\n    🚀 Batch Inference: 100%|\u001b[38;2;65;166;126m█████████████████████████████\u001b[0m| 2.00/2.00 [01:19<00:00, 39.7s/iteration]\u001b[0m\u001b[A\n    🚀 Batch Inference: 100%|\u001b[38;2;65;166;126m█████████████████████████████\u001b[0m| 2.00/2.00 [01:24<00:00, 42.2s/iteration]\u001b[0m\n2026-01-03 07:31:14,220 | INFO |   ✅ Saved results_checkpoint.json (14370 generations)              \n2026-01-03 07:31:14,220 | INFO | Checkpoint saved at 3/8 styles                                     :26, 224s/iteration]\u001b[0m\n  📸 Preparing NomNaTong-Regular:   0%|\u001b[36m                          \u001b[0m| 0.00/50.0 [00:00<?, ?iteration/s]\u001b[0mration]\u001b[0m\n  📸 Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126m████████████████████\u001b[0m| 50.0/50.0 [00:00<00:00, 975iteration/s]\u001b[0m\n    🚀 Batch Inference:   0%|\u001b[38;2;16;85;201m                                    \u001b[0m| 0.00/2.00 [00:00<?, ?iteration/s]\u001b[0m\n  📸 Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126m████████████████████\u001b[0m| 50.0/50.0 [00:00<00:00, 972iteration/s]\u001b[0m\u001b[A\n\n    🚀 Batch Inference:   0%|\u001b[38;2;16;85;201m                                    \u001b[0m| 0.00/2.00 [00:00<?, ?iteration/s]\u001b[0m\u001b[A\n    🚀 Batch Inference:  50%|\u001b[38;2;16;85;201m██████████████▌              \u001b[0m| 1.00/2.00 [00:59<00:59, 59.3s/iteration]\u001b[0m\u001b[A\n    🚀 Batch Inference:   0%|\u001b[38;2;16;85;201m                                \u001b[0m| 3.00/? [01:19<00:00, 23.3s/iteration]\u001b[0m\u001b[A\n    🚀 Batch Inference: 100%|\u001b[38;2;65;166;126m█████████████████████████████\u001b[0m| 2.00/2.00 [01:19<00:00, 39.8s/iteration]\u001b[0m\u001b[A\n    🚀 Batch Inference: 100%|\u001b[38;2;65;166;126m█████████████████████████████\u001b[0m| 2.00/2.00 [01:24<00:00, 42.4s/iteration]\u001b[0m\n2026-01-03 07:32:42,631 | INFO |   ✅ Saved results_checkpoint.json (14420 generations)              \n2026-01-03 07:32:42,631 | INFO | Checkpoint saved at 4/8 styles                                     :30, 162s/iteration]\u001b[0m\n  📸 Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126m████████████████████\u001b[0m| 50.0/50.0 [00:00<00:00, 968iteration/s]\u001b[0m\n    🚀 Batch Inference:   0%|\u001b[38;2;16;85;201m                                    \u001b[0m| 0.00/2.00 [00:00<?, ?iteration/s]\u001b[0m\n  📸 Preparing NomNaTong-Regular:   0%|\u001b[36m                          \u001b[0m| 0.00/50.0 [00:00<?, ?iteration/s]\u001b[0m\u001b[A\n  📸 Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126m████████████████████\u001b[0m| 50.0/50.0 [00:00<00:00, 931iteration/s]\u001b[0m\u001b[A\n\n    🚀 Batch Inference:   0%|\u001b[38;2;16;85;201m                                    \u001b[0m| 0.00/2.00 [00:00<?, ?iteration/s]\u001b[0m\u001b[A\n    🚀 Batch Inference:  50%|\u001b[38;2;16;85;201m██████████████▌              \u001b[0m| 1.00/2.00 [00:59<00:59, 59.5s/iteration]\u001b[0m\u001b[A\n    🚀 Batch Inference:   0%|\u001b[38;2;16;85;201m                                \u001b[0m| 3.00/? [01:19<00:00, 23.3s/iteration]\u001b[0m\u001b[A\n    🚀 Batch Inference: 100%|\u001b[38;2;65;166;126m█████████████████████████████\u001b[0m| 2.00/2.00 [01:19<00:00, 39.8s/iteration]\u001b[0m\u001b[A\n    🚀 Batch Inference: 100%|\u001b[38;2;65;166;126m█████████████████████████████\u001b[0m| 2.00/2.00 [01:24<00:00, 42.4s/iteration]\u001b[0m\n2026-01-03 07:34:11,176 | INFO |   ✅ Saved results_checkpoint.json (14470 generations)              \n2026-01-03 07:34:11,176 | INFO | Checkpoint saved at 5/8 styles                                     :52, 133s/iteration]\u001b[0m\n  📸 Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126m████████████████████\u001b[0m| 50.0/50.0 [00:00<00:00, 962iteration/s]\u001b[0m\n    🚀 Batch Inference:   0%|\u001b[38;2;16;85;201m                                    \u001b[0m| 0.00/2.00 [00:00<?, ?iteration/s]\u001b[0m\n  📸 Preparing NomNaTong-Regular:   0%|\u001b[36m                          \u001b[0m| 0.00/50.0 [00:00<?, ?iteration/s]\u001b[0m\u001b[A\n  📸 Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126m████████████████████\u001b[0m| 50.0/50.0 [00:00<00:00, 985iteration/s]\u001b[0m\u001b[A\n\n    🚀 Batch Inference:   0%|\u001b[38;2;16;85;201m                                    \u001b[0m| 0.00/2.00 [00:00<?, ?iteration/s]\u001b[0m\u001b[A\n    🚀 Batch Inference:  50%|\u001b[38;2;16;85;201m██████████████▌              \u001b[0m| 1.00/2.00 [00:59<00:59, 59.3s/iteration]\u001b[0m\u001b[A\n    🚀 Batch Inference:   0%|\u001b[38;2;16;85;201m                                \u001b[0m| 3.00/? [01:19<00:00, 23.3s/iteration]\u001b[0m\u001b[A\n    🚀 Batch Inference: 100%|\u001b[38;2;65;166;126m█████████████████████████████\u001b[0m| 2.00/2.00 [01:19<00:00, 39.7s/iteration]\u001b[0m\u001b[A\n    🚀 Batch Inference: 100%|\u001b[38;2;65;166;126m█████████████████████████████\u001b[0m| 2.00/2.00 [01:24<00:00, 42.3s/iteration]\u001b[0m\n2026-01-03 07:35:39,488 | INFO |   ✅ Saved results_checkpoint.json (14520 generations)              \n2026-01-03 07:35:39,489 | INFO | Checkpoint saved at 6/8 styles                                     :50, 117s/iteration]\u001b[0m\n  📸 Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126m████████████████████\u001b[0m| 50.0/50.0 [00:00<00:00, 944iteration/s]\u001b[0m\n    🚀 Batch Inference:   0%|\u001b[38;2;16;85;201m                                    \u001b[0m| 0.00/2.00 [00:00<?, ?iteration/s]\u001b[0m\n  📸 Preparing NomNaTong-Regular:   0%|\u001b[36m                          \u001b[0m| 0.00/50.0 [00:00<?, ?iteration/s]\u001b[0m\u001b[A\n  📸 Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126m████████████████████\u001b[0m| 50.0/50.0 [00:00<00:00, 972iteration/s]\u001b[0m\u001b[A\n\n    🚀 Batch Inference:   0%|\u001b[38;2;16;85;201m                                    \u001b[0m| 0.00/2.00 [00:00<?, ?iteration/s]\u001b[0m\u001b[A\n    🚀 Batch Inference:  50%|\u001b[38;2;16;85;201m██████████████▌              \u001b[0m| 1.00/2.00 [00:59<00:59, 59.3s/iteration]\u001b[0m\u001b[A\n    🚀 Batch Inference:   0%|\u001b[38;2;16;85;201m                                \u001b[0m| 3.00/? [01:19<00:00, 23.3s/iteration]\u001b[0m\u001b[A\n    🚀 Batch Inference: 100%|\u001b[38;2;65;166;126m█████████████████████████████\u001b[0m| 2.00/2.00 [01:19<00:00, 39.8s/iteration]\u001b[0m\u001b[A\n    🚀 Batch Inference: 100%|\u001b[38;2;65;166;126m█████████████████████████████\u001b[0m| 2.00/2.00 [01:24<00:00, 42.3s/iteration]\u001b[0m\n2026-01-03 07:37:07,813 | INFO |   ✅ Saved results_checkpoint.json (14570 generations)              \n2026-01-03 07:37:07,814 | INFO | Checkpoint saved at 7/8 styles                                     :34, 107s/iteration]\u001b[0m\nGPU 0:  88%|\u001b[38;2;5;51;156m█████████████████████████████████████████▏     \u001b[0m| 7.00/8.00 [15:49<01:41, 101s/iteration]\u001b[0m\n  📸 Preparing NomNaTong-Regular:   0%|\u001b[36m                          \u001b[0m| 0.00/50.0 [00:00<?, ?iteration/s]\u001b[0m\u001b[A\n  📸 Preparing NomNaTong-Regular: 100%|\u001b[38;2;65;166;126m████████████████████\u001b[0m| 50.0/50.0 [00:00<00:00, 976iteration/s]\u001b[0m\u001b[A\n\n    🚀 Batch Inference:   0%|\u001b[38;2;16;85;201m                                    \u001b[0m| 0.00/2.00 [00:00<?, ?iteration/s]\u001b[0m\u001b[A\n    🚀 Batch Inference:  50%|\u001b[38;2;16;85;201m██████████████▌              \u001b[0m| 1.00/2.00 [00:57<00:57, 57.7s/iteration]\u001b[0m\u001b[A\n    🚀 Batch Inference:   0%|\u001b[38;2;16;85;201m                                \u001b[0m| 3.00/? [01:23<00:00, 24.5s/iteration]\u001b[0m\u001b[A\n    🚀 Batch Inference: 100%|\u001b[38;2;65;166;126m█████████████████████████████\u001b[0m| 2.00/2.00 [01:23<00:00, 41.7s/iteration]\u001b[0m\u001b[A\n2026-01-03 07:38:34,844 | INFO |   ✅ Saved results_checkpoint.json (14620 generations)              \n2026-01-03 07:38:34,844 | INFO | Checkpoint saved at 8/8 styles                                     :41, 101s/iteration]\u001b[0m\nGPU 0: 100%|\u001b[38;2;65;166;126m███████████████████████████████████████████████\u001b[0m| 8.00/8.00 [17:16<00:00, 130s/iteration]\u001b[0m\n2026-01-03 07:38:34,846 | INFO | ============================================================\n2026-01-03 07:38:34,846 | INFO | GENERATION COMPLETE\n2026-01-03 07:38:34,846 | INFO | ============================================================\n2026-01-03 07:38:34,846 | INFO | Generated: 400 images\n2026-01-03 07:38:34,846 | INFO | Skipped: 0 images\n2026-01-03 07:38:34,847 | INFO | Failed: 0 images\n2026-01-03 07:38:34,847 | INFO | Total characters: 998\n2026-01-03 07:38:34,847 | INFO | Total styles: 15\n2026-01-03 07:38:34,847 | INFO | ============================================================\n2026-01-03 07:38:34,974 | INFO |   ✅ Saved results_checkpoint.json (14620 generations)\n2026-01-03 07:38:34,975 | INFO | \n💾 Saving final checkpoint...\n2026-01-03 07:38:35,108 | INFO |   ✅ Saved results_checkpoint.json (14620 generations)\n2026-01-03 07:38:35,108 | INFO | ============================================================\n2026-01-03 07:38:35,108 | INFO |                 LOGGING TO WEIGHTS & BIASES                 \n2026-01-03 07:38:35,108 | INFO | ============================================================\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdungngocpham171\u001b[0m (\u001b[33mdungngocpham171-university-of-science\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.0\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20260103_073835-2vga68hx\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtrain_original_20260103_073835\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dungngocpham171-university-of-science/fontdiffuser-eval\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/dungngocpham171-university-of-science/fontdiffuser-eval/runs/2vga68hx\u001b[0m\n2026-01-03 07:38:36,884 | INFO | \n📸 Logging sample images...\n2026-01-03 07:38:37,109 | INFO | ✓ Logged 20 sample images\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Finishing up...\n\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Finishing up...\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n\u001b[34m\u001b[1mwandb\u001b[0m:               num_characters ▁\n\u001b[34m\u001b[1mwandb\u001b[0m:                    num_fonts ▁\n\u001b[34m\u001b[1mwandb\u001b[0m:                   num_styles ▁\n\u001b[34m\u001b[1mwandb\u001b[0m:       timing/mean_batch_time ▁\n\u001b[34m\u001b[1mwandb\u001b[0m:   timing/mean_time_per_image ▁\n\u001b[34m\u001b[1mwandb\u001b[0m: timing/median_time_per_image ▁\n\u001b[34m\u001b[1mwandb\u001b[0m:            timing/total_time ▁\n\u001b[34m\u001b[1mwandb\u001b[0m:            total_generations ▁\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n\u001b[34m\u001b[1mwandb\u001b[0m:               num_characters 998\n\u001b[34m\u001b[1mwandb\u001b[0m:                    num_fonts 1\n\u001b[34m\u001b[1mwandb\u001b[0m:                   num_styles 15\n\u001b[34m\u001b[1mwandb\u001b[0m:       timing/mean_batch_time 121.76776\n\u001b[34m\u001b[1mwandb\u001b[0m:   timing/mean_time_per_image 2.43536\n\u001b[34m\u001b[1mwandb\u001b[0m: timing/median_time_per_image 1.59206\n\u001b[34m\u001b[1mwandb\u001b[0m:            timing/total_time 974.14204\n\u001b[34m\u001b[1mwandb\u001b[0m:            total_generations 14620\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mtrain_original_20260103_073835\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dungngocpham171-university-of-science/fontdiffuser-eval/runs/2vga68hx\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dungngocpham171-university-of-science/fontdiffuser-eval\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 21 media file(s), 2 artifact file(s) and 0 other file(s)\n\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20260103_073835-2vga68hx/logs\u001b[0m\n2026-01-03 07:38:38,490 | INFO | \n✓ Successfully logged to Weights & Biases\n2026-01-03 07:38:38,490 | INFO |   Project: fontdiffuser-eval\n2026-01-03 07:38:38,490 | INFO |   Run: train_original_20260103_073835\n2026-01-03 07:38:38,490 | INFO | ============================================================\n2026-01-03 07:38:38,490 | INFO | ============================================================\n2026-01-03 07:38:38,490 | INFO | ✅ GENERATION COMPLETE!\n2026-01-03 07:38:38,490 | INFO | ============================================================\n2026-01-03 07:38:38,490 | INFO | Output structure:\n2026-01-03 07:38:38,490 | INFO |   my_dataset/train_original/\n2026-01-03 07:38:38,490 | INFO |     ├── ContentImage/\n2026-01-03 07:38:38,491 | INFO |     │   ├── U+XXXX_char_hash.png\n2026-01-03 07:38:38,491 | INFO |     │   └── ...\n2026-01-03 07:38:38,491 | INFO |     ├── TargetImage/\n2026-01-03 07:38:38,491 | INFO |     │   ├── style0/\n2026-01-03 07:38:38,491 | INFO |     │   │   ├── U+XXXX_char_style0_hash.png\n2026-01-03 07:38:38,491 | INFO |     │   │   └── ...\n2026-01-03 07:38:38,491 | INFO |     │   └── ...\n2026-01-03 07:38:38,491 | INFO |     └── results_checkpoint.json ✅ (single source of truth)\n^C\nW0103 07:39:29.394000 505 torch/distributed/elastic/agent/server/api.py:725] Received 2 death signal, shutting down workers\nW0103 07:39:29.395000 505 torch/distributed/elastic/multiprocessing/api.py:908] Sending process 514 closing signal SIGINT\nW0103 07:39:29.395000 505 torch/distributed/elastic/multiprocessing/api.py:908] Sending process 515 closing signal SIGINT\n","output_type":"stream"}],"execution_count":13},{"id":"997103e5-221c-40a1-a0d1-83a93e1030f7","cell_type":"code","source":"# @title Count images in ContentImage and TargetImage\n!find my_dataset/train_original/ContentImage -type f | wc -l\n!find my_dataset/train_original/TargetImage -type f | wc -l","metadata":{"trusted":true,"id":"997103e5-221c-40a1-a0d1-83a93e1030f7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0c142b06-1a13-4145-c6c0-e1ae4ceadb42","execution":{"iopub.status.busy":"2026-01-03T08:01:58.856725Z","iopub.execute_input":"2026-01-03T08:01:58.857546Z","iopub.status.idle":"2026-01-03T08:01:59.143121Z","shell.execute_reply.started":"2026-01-03T08:01:58.857513Z","shell.execute_reply":"2026-01-03T08:01:59.142204Z"}},"outputs":[{"name":"stdout","text":"998\n14620\n","output_type":"stream"}],"execution_count":13},{"id":"f9250a14","cell_type":"code","source":"# @title Train Validation split\n!python FontDiffusion/create_validation_split.py \\\n  --data_root my_dataset \\\n  --val_ratio 0.2 \\\n  --seed 42","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2026-01-03T08:02:01.903136Z","iopub.execute_input":"2026-01-03T08:02:01.903435Z","iopub.status.idle":"2026-01-03T08:02:07.703288Z","shell.execute_reply.started":"2026-01-03T08:02:01.903405Z","shell.execute_reply":"2026-01-03T08:02:07.702546Z"},"id":"f9250a14","outputId":"4e9d8a99-58a1-4a60-9a81-7420baadf293","papermill":{"duration":0.236541,"end_time":"2025-12-30T18:55:01.673705","exception":false,"start_time":"2025-12-30T18:55:01.437164","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"2026-01-03 08:02:03,892 | INFO | ✓ Using source directory: my_dataset/train_original\n2026-01-03 08:02:03,893 | INFO | \n============================================================\n2026-01-03 08:02:03,893 | INFO | FONTDIFFUSION VALIDATION SPLIT CREATOR\n2026-01-03 08:02:03,893 | INFO | ============================================================\n2026-01-03 08:02:03,893 | INFO | \n============================================================\n2026-01-03 08:02:03,893 | INFO | ANALYZING TRAINING DATA\n2026-01-03 08:02:03,893 | INFO | ============================================================\n2026-01-03 08:02:03,893 | INFO | \n🔍 Scanning content images...\nContent images: 100%|\u001b[38;2;65;166;126m█████████████████████████████████████████████\u001b[0m| 998/998 [00:00<00:00, 523kimg/s]\u001b[0m\n2026-01-03 08:02:03,899 | INFO |   ✓ Found 998 content images\n2026-01-03 08:02:03,899 | INFO | \n🔍 Scanning target images...\nStyles: 100%|\u001b[38;2;65;166;126m██████████████████████████████████████████████████\u001b[0m| 15.0/15.0 [00:00<00:00, 218style/s]\u001b[0m\n2026-01-03 08:02:03,968 | INFO |   ✓ Found 14620 valid target images\n2026-01-03 08:02:03,968 | INFO | \n🔍 Validating content ↔ target pairs...\nValidating pairs: 100%|\u001b[38;2;65;166;126m█████████████████████████████████████\u001b[0m| 14.3k/14.3k [00:00<00:00, 2.26Mpair/s]\u001b[0m\n2026-01-03 08:02:03,978 | INFO | ============================================================\n2026-01-03 08:02:03,978 | INFO | 📊 DATA ANALYSIS SUMMARY\n2026-01-03 08:02:03,978 | INFO | ============================================================\n2026-01-03 08:02:03,978 | INFO | Content images found:        998\n2026-01-03 08:02:03,978 | INFO | Target images scanned:       14,620\n2026-01-03 08:02:03,979 | INFO |   ├─ Parse errors:          0\n2026-01-03 08:02:03,979 | INFO |   └─ Style mismatches:      0\n2026-01-03 08:02:03,979 | INFO | Target images after filter:  14,620\n2026-01-03 08:02:03,979 | INFO | Missing content images:      0\n2026-01-03 08:02:03,979 | INFO | Final valid pairs:           14,620\n2026-01-03 08:02:03,979 | INFO | ============================================================\n2026-01-03 08:02:03,979 | INFO | \n============================================================\n2026-01-03 08:02:03,980 | INFO | CREATING TRAIN/VAL SPLITS (random char & style)\n2026-01-03 08:02:03,980 | INFO | ============================================================\n2026-01-03 08:02:03,981 | INFO | \n📊 Split Statistics:\n2026-01-03 08:02:03,981 | INFO |   Total chars: 998 → train: 799, val: 199\n2026-01-03 08:02:03,981 | INFO |   Total styles: 15 → train: 12, val: 3\n2026-01-03 08:02:03,981 | INFO |   train:\n2026-01-03 08:02:03,981 | INFO |     Chars: 799\n2026-01-03 08:02:03,982 | INFO |     Styles: 12\n2026-01-03 08:02:03,982 | INFO |   val:\n2026-01-03 08:02:03,982 | INFO |     Chars: 199\n2026-01-03 08:02:03,982 | INFO |     Styles: 3\n2026-01-03 08:02:03,982 | INFO | \n📁 CREATING TRAIN SPLIT...\n2026-01-03 08:02:03,982 | INFO |   📥 Copying content images for train...\n2026-01-03 08:02:04,192 | INFO |   📥 Copying target images for train...        00<00:00, 3.84kchar/s]\u001b[0m\n2026-01-03 08:02:06,758 | INFO |   ✓ train: 799 content, 9,360 target (skipped: 0)<00:00, 5.87kpair/s]\u001b[0m\n2026-01-03 08:02:06,758 | INFO |   📋 Filtering checkpoint for train...\n2026-01-03 08:02:06,934 | INFO |     ✓ Saved: 9,360/14,620 generations          3k/14.3k [00:00<00:00]\u001b[0m\n2026-01-03 08:02:06,937 | INFO | 📁 CREATING VAL SPLIT...\n2026-01-03 08:02:06,938 | INFO |   📥 Copying content images for val...\n2026-01-03 08:02:06,983 | INFO |   📥 Copying target images for val...          00<00:00, 4.46kchar/s]\u001b[0m\n2026-01-03 08:02:07,161 | INFO |   ✓ val: 199 content, 585 target (skipped: 0)  00<00:00, 95.3kpair/s]\u001b[0m\n2026-01-03 08:02:07,161 | INFO |   📋 Filtering checkpoint for val...\n2026-01-03 08:02:07,250 | INFO |     ✓ Saved: 585/14,620 generations            3k/14.3k [00:00<00:00]\u001b[0m\n2026-01-03 08:02:07,253 | INFO | ✓ Saved split metadata to my_dataset/split_info.json\n2026-01-03 08:02:07,255 | INFO | \n============================================================\n2026-01-03 08:02:07,255 | INFO | ✓ SPLIT CREATION COMPLETE\n2026-01-03 08:02:07,255 | INFO | ============================================================\n2026-01-03 08:02:07,255 | INFO | \n✅ Created:\n2026-01-03 08:02:07,255 | INFO |   📁 train/\n2026-01-03 08:02:07,255 | INFO |     ├── ContentImage/ (training chars)\n2026-01-03 08:02:07,255 | INFO |     ├── TargetImage/ (training styles)\n2026-01-03 08:02:07,255 | INFO |     └── results_checkpoint.json (filtered)\n2026-01-03 08:02:07,255 | INFO |   📁 val/\n2026-01-03 08:02:07,256 | INFO |     ├── ContentImage/ (validation chars)\n2026-01-03 08:02:07,256 | INFO |     ├── TargetImage/ (validation styles)\n2026-01-03 08:02:07,256 | INFO |     └── results_checkpoint.json (filtered)\n2026-01-03 08:02:07,256 | INFO | \n💡 Guarantees:\n2026-01-03 08:02:07,256 | INFO |   ✓ Every target has matching content\n2026-01-03 08:02:07,256 | INFO |   ✓ Checkpoint contains only relevant generations\n2026-01-03 08:02:07,256 | INFO |   ✓ Train and val are completely disjoint\n","output_type":"stream"}],"execution_count":14},{"id":"79508d80-fac1-4318-9174-a32613a557e3","cell_type":"code","source":"!uv pip install --upgrade pyarrow datasets","metadata":{"id":"79508d80-fac1-4318-9174-a32613a557e3","trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4fba960d-f59b-4cad-baaf-257a7b246bc2"},"outputs":[],"execution_count":null},{"id":"vRL8QovYCvLY","cell_type":"code","source":"# @title Creat and upload dataset to HF\nHF_USERNAME = \"dzungpham\"\n!python FontDiffusion/create_hf_dataset.py \\\n  --data-dir \"my_dataset/train_original\" \\\n  --repo-id dzungpham/font-diffusion-generated-data \\\n  --split \"train_original\" \\\n  --token {HF_TOKEN}\n\n# Train Split\n!python FontDiffusion/create_hf_dataset.py \\\n  --data-dir \"my_dataset/train\" \\\n  --repo-id dzungpham/font-diffusion-generated-data \\\n  --split \"train\" \\\n  --token {HF_TOKEN}\n\n# Train Split\n!python FontDiffusion/create_hf_dataset.py \\\n  --data-dir \"my_dataset/val\" \\\n  --repo-id dzungpham/font-diffusion-generated-data \\\n  --split \"val\" \\\n  --token {HF_TOKEN}\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2026-01-03T08:02:11.090071Z","iopub.execute_input":"2026-01-03T08:02:11.090826Z","iopub.status.idle":"2026-01-03T08:04:06.450938Z","shell.execute_reply.started":"2026-01-03T08:02:11.090790Z","shell.execute_reply":"2026-01-03T08:04:06.450168Z"},"id":"vRL8QovYCvLY","outputId":"5a648043-c8f3-4539-ba16-4ce56c0f4f4f","trusted":true},"outputs":[{"name":"stdout","text":"2026-01-03 08:02:13,926 | INFO | Directory structure validated successfully\n2026-01-03 08:02:13,927 | INFO | Building dataset...\n2026-01-03 08:02:14,013 | INFO | Loaded checkpoint: 14620 generations, 998 characters, 15 styles\nLoading image pairs: 100%|\u001b[38;2;65;166;126m██████████████████████████████████\u001b[0m| 14.3k/14.3k [00:12<00:00, 1.20kpair/s]\u001b[0m\n2026-01-03 08:02:26,219 | INFO | Successfully loaded 14620 samples\n2026-01-03 08:03:02,456 | INFO | Pushing dataset to dzungpham/font-diffusion-generated-data...\nUploading the dataset shards:   0%|                  | 0/1 [00:00<?, ? shards/s]\nMap:   0%|                                     | 0/14620 [00:00<?, ? examples/s]\u001b[A\nMap:  46%|██████████▌            | 6747/14620 [00:00<00:00, 15780.89 examples/s]\u001b[A\nMap: 100%|██████████████████████| 14620/14620 [00:00<00:00, 15850.93 examples/s]\u001b[A\n\nCreating parquet from Arrow format:   0%|                 | 0/3 [00:00<?, ?ba/s]\u001b[A\nCreating parquet from Arrow format:  33%|███      | 1/3 [00:00<00:00,  4.18ba/s]\u001b[A\nCreating parquet from Arrow format: 100%|█████████| 3/3 [00:00<00:00,  6.07ba/s]\u001b[A\nUploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.28s/ shards]\n2026-01-03 08:03:21,228 | INFO | Successfully pushed to https://huggingface.co/datasets/dzungpham/font-diffusion-generated-data\n2026-01-03 08:03:21,241 | INFO | Dataset creation completed successfully\n2026-01-03 08:03:25,031 | INFO | Directory structure validated successfully\n2026-01-03 08:03:25,032 | INFO | Building dataset...\n2026-01-03 08:03:25,085 | INFO | Loaded checkpoint: 9360 generations, 799 characters, 12 styles\nLoading image pairs: 100%|\u001b[38;2;65;166;126m██████████████████████████████████\u001b[0m| 9.14k/9.14k [00:07<00:00, 1.21kpair/s]\u001b[0m\n2026-01-03 08:03:32,849 | INFO | Successfully loaded 9360 samples\n2026-01-03 08:03:56,422 | INFO | Pushing dataset to dzungpham/font-diffusion-generated-data...\nUploading the dataset shards:   0%|                  | 0/1 [00:00<?, ? shards/s]\nMap:   0%|                                      | 0/9360 [00:00<?, ? examples/s]\u001b[A\nMap:  71%|█████████████████       | 6673/9360 [00:00<00:00, 14691.05 examples/s]\u001b[A\nMap: 100%|████████████████████████| 9360/9360 [00:00<00:00, 13673.62 examples/s]\u001b[A\n\nCreating parquet from Arrow format:   0%|                 | 0/2 [00:00<?, ?ba/s]\u001b[A\nCreating parquet from Arrow format: 100%|█████████| 2/2 [00:00<00:00,  6.55ba/s]\u001b[A\nUploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.48s/ shards]\nREADME.md: 3.05kB [00:00, 13.7MB/s]\n2026-01-03 08:03:59,099 | INFO | Successfully pushed to https://huggingface.co/datasets/dzungpham/font-diffusion-generated-data\n2026-01-03 08:03:59,107 | INFO | Dataset creation completed successfully\n2026-01-03 08:04:02,629 | INFO | Directory structure validated successfully\n2026-01-03 08:04:02,629 | INFO | Building dataset...\n2026-01-03 08:04:02,633 | INFO | Loaded checkpoint: 585 generations, 199 characters, 3 styles\nLoading image pairs: 100%|\u001b[38;2;65;166;126m██████████████████████████████████████\u001b[0m| 585/585 [00:00<00:00, 1.12kpair/s]\u001b[0m\n2026-01-03 08:04:03,156 | INFO | Successfully loaded 585 samples\n2026-01-03 08:04:04,599 | INFO | Pushing dataset to dzungpham/font-diffusion-generated-data...\nUploading the dataset shards:   0%|                  | 0/1 [00:00<?, ? shards/s]\nMap: 100%|██████████████████████████| 585/585 [00:00<00:00, 18797.30 examples/s]\u001b[A\n\nCreating parquet from Arrow format: 100%|█████████| 1/1 [00:00<00:00, 72.32ba/s]\u001b[A\nUploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  4.90 shards/s]\nREADME.md: 3.05kB [00:00, 11.0MB/s]\n2026-01-03 08:04:05,787 | INFO | Successfully pushed to https://huggingface.co/datasets/dzungpham/font-diffusion-generated-data\n2026-01-03 08:04:05,787 | INFO | Dataset creation completed successfully\n","output_type":"stream"}],"execution_count":15},{"id":"a87caab2","cell_type":"code","source":"import torch, gc\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"id":"a87caab2","papermill":{"duration":1.992585,"end_time":"2025-12-30T18:55:24.769269","exception":false,"start_time":"2025-12-30T18:55:22.776684","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T07:47:55.647116Z","iopub.execute_input":"2026-01-03T07:47:55.647379Z","iopub.status.idle":"2026-01-03T07:47:55.870624Z","shell.execute_reply.started":"2026-01-03T07:47:55.647359Z","shell.execute_reply":"2026-01-03T07:47:55.869966Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"280"},"metadata":{}}],"execution_count":22},{"id":"267634e8","cell_type":"code","source":"# @title Training phase 1\nif is_colab:\n  !uv pip install --upgrade \"huggingface-hub>=0.34.0,<1.0\"\nelse:\n  !uv pip install --upgrade \"huggingface-hub==0.25.2\"\nimport wandb\n\nMAX_TRAIN_STEPS = 1000\n!accelerate launch FontDiffusion/my_train.py \\\n    --seed=123 \\\n    --experience_name=\"FontDiffuser_training_phase_1\" \\\n    --data_root=\"my_dataset\" \\\n    --output_dir=\"outputs/FontDiffuser\" \\\n    --phase_1_ckpt_dir=\"ckpt\" \\\n    --report_to=\"wandb\" \\\n      \\\n    --resolution=96 \\\n    --style_image_size=96 \\\n    --content_image_size=96 \\\n    --content_encoder_downsample_size=3 \\\n    --channel_attn=True \\\n    --content_start_channel=64 \\\n    --style_start_channel=64 \\\n      \\\n    --train_batch_size=16 \\\n    --gradient_accumulation_steps=1 \\\n    --perceptual_coefficient=0.05 \\\n    --offset_coefficient=0.5 \\\n    --max_train_steps={MAX_TRAIN_STEPS} \\\n    --ckpt_interval={MAX_TRAIN_STEPS // 2} \\\n    --log_interval=50 \\\n      \\\n    --learning_rate=1e-4 \\\n    --lr_scheduler=\"linear\" \\\n    --lr_warmup_steps=200 \\\n    --drop_prob=0.1 \\\n    --mixed_precision=\"fp16\"","metadata":{"execution":{"iopub.status.busy":"2026-01-03T07:48:41.629870Z","iopub.execute_input":"2026-01-03T07:48:41.630187Z","iopub.status.idle":"2026-01-03T07:49:03.202031Z","shell.execute_reply.started":"2026-01-03T07:48:41.630157Z","shell.execute_reply":"2026-01-03T07:49:03.201183Z"},"id":"267634e8","papermill":{"duration":0.021927,"end_time":"2025-12-30T18:55:24.807644","exception":false,"start_time":"2025-12-30T18:55:24.785717","status":"completed"},"tags":[],"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"582c9a45-8dc2-4e10-b91e-62f62684d95d"},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m12 packages\u001b[0m \u001b[2min 52ms\u001b[0m\u001b[0m                                         \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 0.50ms\u001b[0m\u001b[0m                                            \n\u001b[2mUninstalled \u001b[1m2 packages\u001b[0m \u001b[2min 6ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 7ms\u001b[0m\u001b[0m5.2                              \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.10.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.12.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==1.2.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.25.2\u001b[0m\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\nThe following values were not passed to `accelerate launch` and had defaults used instead:\n\t`--num_processes` was set to a value of `2`\n\t\tMore than one GPU was found, enabling multi-GPU training.\n\t\tIf this was unintended please pass in `--num_processes=1`.\n\t`--num_machines` was set to a value of `1`\n\t`--mixed_precision` was set to a value of `'no'`\n\t`--dynamo_backend` was set to a value of `'no'`\nTo avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n2026-01-03 07:48:51.876755: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767426531.900346   16809 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767426531.908193   16809 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n2026-01-03 07:48:53.006382: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767426533.043235   16808 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767426533.055433   16808 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.4.0 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"/kaggle/working/FontDiffusion/my_train.py\", line 25, in <module>\n    from src import (\n  File \"/kaggle/working/FontDiffusion/src/__init__.py\", line 12, in <module>\n    from .build_optimized import (\n  File \"/kaggle/working/FontDiffusion/src/build_optimized.py\", line 8, in <module>\n    from diffusers.models.attention_processor import AttnProcessor2_0\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py\", line 24, in <module>\n    from .lora import LoRACompatibleLinear, LoRALinearLayer\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/lora.py\", line 21, in <module>\n    from ..loaders import PatchedLoraProjection, text_encoder_attn_modules, text_encoder_mlp_modules\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/loaders.py\", line 55, in <module>\n    from transformers import CLIPTextModel, CLIPTextModelWithProjection, PreTrainedModel\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1175, in __getattr__\n    value = getattr(module, name)\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1174, in __getattr__\n    module = self._get_module(self._class_to_module[name])\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1184, in _get_module\n    return importlib.import_module(\".\" + module_name, self.__name__)\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py\", line 27, in <module>\n    from ...modeling_utils import PreTrainedModel\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 39, in <module>\n    from .generation import GenerationConfig, GenerationMixin\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1174, in __getattr__\n    module = self._get_module(self._class_to_module[name])\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1184, in _get_module\n    return importlib.import_module(\".\" + module_name, self.__name__)\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\", line 27, in <module>\n    from ..integrations.deepspeed import is_deepspeed_zero3_enabled\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/__init__.py\", line 33, in <module>\n    from .integration_utils import (\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/integration_utils.py\", line 71, in <module>\n    from ..trainer_callback import ProgressCallback, TrainerCallback  # noqa: E402\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_callback.py\", line 26, in <module>\n    from .trainer_utils import IntervalStrategy, has_length\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_utils.py\", line 49, in <module>\n    import tensorflow as tf\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 467, in <module>\n    importlib.import_module(\"keras.src.optimizers\")\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/usr/local/lib/python3.11/dist-packages/keras/__init__.py\", line 2, in <module>\n    from keras.api import DTypePolicy\n  File \"/usr/local/lib/python3.11/dist-packages/keras/api/__init__.py\", line 8, in <module>\n    from keras.api import activations\n  File \"/usr/local/lib/python3.11/dist-packages/keras/api/activations/__init__.py\", line 7, in <module>\n    from keras.src.activations import deserialize\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/__init__.py\", line 13, in <module>\n    from keras.src import visualization\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/visualization/__init__.py\", line 2, in <module>\n    from keras.src.visualization import plot_image_gallery\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/visualization/plot_image_gallery.py\", line 13, in <module>\n    import matplotlib.pyplot as plt\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/__init__.py\", line 129, in <module>\n    from . import _api, _version, cbook, _docstring, rcsetup\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/rcsetup.py\", line 27, in <module>\n    from matplotlib.colors import Colormap, is_color_like\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py\", line 56, in <module>\n    from matplotlib import _api, _cm, cbook, scale\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/scale.py\", line 22, in <module>\n    from matplotlib.ticker import (\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/ticker.py\", line 138, in <module>\n    from matplotlib import transforms as mtransforms\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/transforms.py\", line 49, in <module>\n    from matplotlib._path import (\nAttributeError: _ARRAY_API not found\n\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.4.0 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"/kaggle/working/FontDiffusion/my_train.py\", line 25, in <module>\n    from src import (\n  File \"/kaggle/working/FontDiffusion/src/__init__.py\", line 12, in <module>\n    from .build_optimized import (\n  File \"/kaggle/working/FontDiffusion/src/build_optimized.py\", line 8, in <module>\n    from diffusers.models.attention_processor import AttnProcessor2_0\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py\", line 24, in <module>\n    from .lora import LoRACompatibleLinear, LoRALinearLayer\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/lora.py\", line 21, in <module>\n    from ..loaders import PatchedLoraProjection, text_encoder_attn_modules, text_encoder_mlp_modules\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/loaders.py\", line 55, in <module>\n    from transformers import CLIPTextModel, CLIPTextModelWithProjection, PreTrainedModel\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1175, in __getattr__\n    value = getattr(module, name)\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1174, in __getattr__\n    module = self._get_module(self._class_to_module[name])\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1184, in _get_module\n    return importlib.import_module(\".\" + module_name, self.__name__)\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py\", line 27, in <module>\n    from ...modeling_utils import PreTrainedModel\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 39, in <module>\n    from .generation import GenerationConfig, GenerationMixin\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1174, in __getattr__\n    module = self._get_module(self._class_to_module[name])\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1184, in _get_module\n    return importlib.import_module(\".\" + module_name, self.__name__)\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\", line 27, in <module>\n    from ..integrations.deepspeed import is_deepspeed_zero3_enabled\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/__init__.py\", line 33, in <module>\n    from .integration_utils import (\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/integration_utils.py\", line 71, in <module>\n    from ..trainer_callback import ProgressCallback, TrainerCallback  # noqa: E402\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_callback.py\", line 26, in <module>\n    from .trainer_utils import IntervalStrategy, has_length\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_utils.py\", line 49, in <module>\n    import tensorflow as tf\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 467, in <module>\n    importlib.import_module(\"keras.src.optimizers\")\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/usr/local/lib/python3.11/dist-packages/keras/__init__.py\", line 2, in <module>\n    from keras.api import DTypePolicy\n  File \"/usr/local/lib/python3.11/dist-packages/keras/api/__init__.py\", line 34, in <module>\n    from keras.api import visualization\n  File \"/usr/local/lib/python3.11/dist-packages/keras/api/visualization/__init__.py\", line 11, in <module>\n    from keras.src.visualization.plot_bounding_box_gallery import (\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/visualization/plot_bounding_box_gallery.py\", line 12, in <module>\n    from matplotlib import patches  # For legend patches\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/__init__.py\", line 129, in <module>\n    from . import _api, _version, cbook, _docstring, rcsetup\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/rcsetup.py\", line 27, in <module>\n    from matplotlib.colors import Colormap, is_color_like\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py\", line 56, in <module>\n    from matplotlib import _api, _cm, cbook, scale\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/scale.py\", line 22, in <module>\n    from matplotlib.ticker import (\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/ticker.py\", line 138, in <module>\n    from matplotlib import transforms as mtransforms\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/transforms.py\", line 49, in <module>\n    from matplotlib._path import (\nAttributeError: _ARRAY_API not found\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1184, in _get_module\n    return importlib.import_module(\".\" + module_name, self.__name__)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\", line 27, in <module>\n    from ..integrations.deepspeed import is_deepspeed_zero3_enabled\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/__init__.py\", line 33, in <module>\n    from .integration_utils import (\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/integration_utils.py\", line 71, in <module>\n    from ..trainer_callback import ProgressCallback, TrainerCallback  # noqa: E402\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_callback.py\", line 26, in <module>\n    from .trainer_utils import IntervalStrategy, has_length\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_utils.py\", line 49, in <module>\n    import tensorflow as tf\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 467, in <module>\n    importlib.import_module(\"keras.src.optimizers\")\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/keras/__init__.py\", line 2, in <module>\n    from keras.api import DTypePolicy\n  File \"/usr/local/lib/python3.11/dist-packages/keras/api/__init__.py\", line 35, in <module>\n    from keras.api import wrappers\n  File \"/usr/local/lib/python3.11/dist-packages/keras/api/wrappers/__init__.py\", line 7, in <module>\n    from keras.src.wrappers.sklearn_wrapper import SKLearnClassifier\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/wrappers/__init__.py\", line 1, in <module>\n    from keras.src.wrappers.sklearn_wrapper import SKLearnClassifier\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/wrappers/sklearn_wrapper.py\", line 8, in <module>\n    from keras.src.wrappers.fixes import _routing_enabled\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/wrappers/fixes.py\", line 2, in <module>\n    import sklearn\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/__init__.py\", line 82, in <module>\n    from .base import clone\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 17, in <module>\n    from .utils import _IS_32BIT\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/__init__.py\", line 19, in <module>\n    from .murmurhash import murmurhash3_32\n  File \"sklearn/utils/murmurhash.pyx\", line 1, in init sklearn.utils.murmurhash\nValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1184, in _get_module\n    return importlib.import_module(\".\" + module_name, self.__name__)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py\", line 27, in <module>\n    from ...modeling_utils import PreTrainedModel\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 39, in <module>\n    from .generation import GenerationConfig, GenerationMixin\n  File \"<frozen importlib._bootstrap>\", line 1229, in _handle_fromlist\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1174, in __getattr__\n    module = self._get_module(self._class_to_module[name])\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1186, in _get_module\n    raise RuntimeError(\nRuntimeError: Failed to import transformers.generation.utils because of the following error (look up to see its traceback):\nnumpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/kaggle/working/FontDiffusion/my_train.py\", line 25, in <module>\n    from src import (\n  File \"/kaggle/working/FontDiffusion/src/__init__.py\", line 12, in <module>\n    from .build_optimized import (\n  File \"/kaggle/working/FontDiffusion/src/build_optimized.py\", line 8, in <module>\n    from diffusers.models.attention_processor import AttnProcessor2_0\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py\", line 24, in <module>\n    from .lora import LoRACompatibleLinear, LoRALinearLayer\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/lora.py\", line 21, in <module>\n    from ..loaders import PatchedLoraProjection, text_encoder_attn_modules, text_encoder_mlp_modules\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/loaders.py\", line 55, in <module>\n    from transformers import CLIPTextModel, CLIPTextModelWithProjection, PreTrainedModel\n  File \"<frozen importlib._bootstrap>\", line 1229, in _handle_fromlist\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1175, in __getattr__\n    value = getattr(module, name)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1174, in __getattr__\n    module = self._get_module(self._class_to_module[name])\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1186, in _get_module\n    raise RuntimeError(\nRuntimeError: Failed to import transformers.models.clip.modeling_clip because of the following error (look up to see its traceback):\nFailed to import transformers.generation.utils because of the following error (look up to see its traceback):\nnumpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.4.0 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"/kaggle/working/FontDiffusion/my_train.py\", line 25, in <module>\n    from src import (\n  File \"/kaggle/working/FontDiffusion/src/__init__.py\", line 12, in <module>\n    from .build_optimized import (\n  File \"/kaggle/working/FontDiffusion/src/build_optimized.py\", line 8, in <module>\n    from diffusers.models.attention_processor import AttnProcessor2_0\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py\", line 24, in <module>\n    from .lora import LoRACompatibleLinear, LoRALinearLayer\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/lora.py\", line 21, in <module>\n    from ..loaders import PatchedLoraProjection, text_encoder_attn_modules, text_encoder_mlp_modules\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/loaders.py\", line 55, in <module>\n    from transformers import CLIPTextModel, CLIPTextModelWithProjection, PreTrainedModel\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1175, in __getattr__\n    value = getattr(module, name)\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1174, in __getattr__\n    module = self._get_module(self._class_to_module[name])\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1184, in _get_module\n    return importlib.import_module(\".\" + module_name, self.__name__)\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py\", line 27, in <module>\n    from ...modeling_utils import PreTrainedModel\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 39, in <module>\n    from .generation import GenerationConfig, GenerationMixin\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1174, in __getattr__\n    module = self._get_module(self._class_to_module[name])\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1184, in _get_module\n    return importlib.import_module(\".\" + module_name, self.__name__)\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\", line 27, in <module>\n    from ..integrations.deepspeed import is_deepspeed_zero3_enabled\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/__init__.py\", line 33, in <module>\n    from .integration_utils import (\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/integration_utils.py\", line 71, in <module>\n    from ..trainer_callback import ProgressCallback, TrainerCallback  # noqa: E402\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_callback.py\", line 26, in <module>\n    from .trainer_utils import IntervalStrategy, has_length\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_utils.py\", line 49, in <module>\n    import tensorflow as tf\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 467, in <module>\n    importlib.import_module(\"keras.src.optimizers\")\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/usr/local/lib/python3.11/dist-packages/keras/__init__.py\", line 2, in <module>\n    from keras.api import DTypePolicy\n  File \"/usr/local/lib/python3.11/dist-packages/keras/api/__init__.py\", line 8, in <module>\n    from keras.api import activations\n  File \"/usr/local/lib/python3.11/dist-packages/keras/api/activations/__init__.py\", line 7, in <module>\n    from keras.src.activations import deserialize\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/__init__.py\", line 13, in <module>\n    from keras.src import visualization\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/visualization/__init__.py\", line 2, in <module>\n    from keras.src.visualization import plot_image_gallery\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/visualization/plot_image_gallery.py\", line 13, in <module>\n    import matplotlib.pyplot as plt\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/__init__.py\", line 129, in <module>\n    from . import _api, _version, cbook, _docstring, rcsetup\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/rcsetup.py\", line 27, in <module>\n    from matplotlib.colors import Colormap, is_color_like\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py\", line 56, in <module>\n    from matplotlib import _api, _cm, cbook, scale\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/scale.py\", line 22, in <module>\n    from matplotlib.ticker import (\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/ticker.py\", line 138, in <module>\n    from matplotlib import transforms as mtransforms\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/transforms.py\", line 49, in <module>\n    from matplotlib._path import (\nAttributeError: _ARRAY_API not found\n\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.4.0 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"/kaggle/working/FontDiffusion/my_train.py\", line 25, in <module>\n    from src import (\n  File \"/kaggle/working/FontDiffusion/src/__init__.py\", line 12, in <module>\n    from .build_optimized import (\n  File \"/kaggle/working/FontDiffusion/src/build_optimized.py\", line 8, in <module>\n    from diffusers.models.attention_processor import AttnProcessor2_0\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py\", line 24, in <module>\n    from .lora import LoRACompatibleLinear, LoRALinearLayer\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/lora.py\", line 21, in <module>\n    from ..loaders import PatchedLoraProjection, text_encoder_attn_modules, text_encoder_mlp_modules\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/loaders.py\", line 55, in <module>\n    from transformers import CLIPTextModel, CLIPTextModelWithProjection, PreTrainedModel\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1175, in __getattr__\n    value = getattr(module, name)\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1174, in __getattr__\n    module = self._get_module(self._class_to_module[name])\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1184, in _get_module\n    return importlib.import_module(\".\" + module_name, self.__name__)\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py\", line 27, in <module>\n    from ...modeling_utils import PreTrainedModel\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 39, in <module>\n    from .generation import GenerationConfig, GenerationMixin\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1174, in __getattr__\n    module = self._get_module(self._class_to_module[name])\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1184, in _get_module\n    return importlib.import_module(\".\" + module_name, self.__name__)\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\", line 27, in <module>\n    from ..integrations.deepspeed import is_deepspeed_zero3_enabled\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/__init__.py\", line 33, in <module>\n    from .integration_utils import (\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/integration_utils.py\", line 71, in <module>\n    from ..trainer_callback import ProgressCallback, TrainerCallback  # noqa: E402\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_callback.py\", line 26, in <module>\n    from .trainer_utils import IntervalStrategy, has_length\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_utils.py\", line 49, in <module>\n    import tensorflow as tf\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 467, in <module>\n    importlib.import_module(\"keras.src.optimizers\")\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/usr/local/lib/python3.11/dist-packages/keras/__init__.py\", line 2, in <module>\n    from keras.api import DTypePolicy\n  File \"/usr/local/lib/python3.11/dist-packages/keras/api/__init__.py\", line 34, in <module>\n    from keras.api import visualization\n  File \"/usr/local/lib/python3.11/dist-packages/keras/api/visualization/__init__.py\", line 11, in <module>\n    from keras.src.visualization.plot_bounding_box_gallery import (\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/visualization/plot_bounding_box_gallery.py\", line 12, in <module>\n    from matplotlib import patches  # For legend patches\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/__init__.py\", line 129, in <module>\n    from . import _api, _version, cbook, _docstring, rcsetup\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/rcsetup.py\", line 27, in <module>\n    from matplotlib.colors import Colormap, is_color_like\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py\", line 56, in <module>\n    from matplotlib import _api, _cm, cbook, scale\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/scale.py\", line 22, in <module>\n    from matplotlib.ticker import (\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/ticker.py\", line 138, in <module>\n    from matplotlib import transforms as mtransforms\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/transforms.py\", line 49, in <module>\n    from matplotlib._path import (\nAttributeError: _ARRAY_API not found\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1184, in _get_module\n    return importlib.import_module(\".\" + module_name, self.__name__)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\", line 27, in <module>\n    from ..integrations.deepspeed import is_deepspeed_zero3_enabled\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/__init__.py\", line 33, in <module>\n    from .integration_utils import (\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/integration_utils.py\", line 71, in <module>\n    from ..trainer_callback import ProgressCallback, TrainerCallback  # noqa: E402\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_callback.py\", line 26, in <module>\n    from .trainer_utils import IntervalStrategy, has_length\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_utils.py\", line 49, in <module>\n    import tensorflow as tf\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 467, in <module>\n    importlib.import_module(\"keras.src.optimizers\")\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/keras/__init__.py\", line 2, in <module>\n    from keras.api import DTypePolicy\n  File \"/usr/local/lib/python3.11/dist-packages/keras/api/__init__.py\", line 35, in <module>\n    from keras.api import wrappers\n  File \"/usr/local/lib/python3.11/dist-packages/keras/api/wrappers/__init__.py\", line 7, in <module>\n    from keras.src.wrappers.sklearn_wrapper import SKLearnClassifier\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/wrappers/__init__.py\", line 1, in <module>\n    from keras.src.wrappers.sklearn_wrapper import SKLearnClassifier\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/wrappers/sklearn_wrapper.py\", line 8, in <module>\n    from keras.src.wrappers.fixes import _routing_enabled\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/wrappers/fixes.py\", line 2, in <module>\n    import sklearn\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/__init__.py\", line 82, in <module>\n    from .base import clone\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 17, in <module>\n    from .utils import _IS_32BIT\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/__init__.py\", line 19, in <module>\n    from .murmurhash import murmurhash3_32\n  File \"sklearn/utils/murmurhash.pyx\", line 1, in init sklearn.utils.murmurhash\nValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1184, in _get_module\n    return importlib.import_module(\".\" + module_name, self.__name__)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py\", line 27, in <module>\n    from ...modeling_utils import PreTrainedModel\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 39, in <module>\n    from .generation import GenerationConfig, GenerationMixin\n  File \"<frozen importlib._bootstrap>\", line 1229, in _handle_fromlist\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1174, in __getattr__\n    module = self._get_module(self._class_to_module[name])\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1186, in _get_module\n    raise RuntimeError(\nRuntimeError: Failed to import transformers.generation.utils because of the following error (look up to see its traceback):\nnumpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/kaggle/working/FontDiffusion/my_train.py\", line 25, in <module>\n    from src import (\n  File \"/kaggle/working/FontDiffusion/src/__init__.py\", line 12, in <module>\n    from .build_optimized import (\n  File \"/kaggle/working/FontDiffusion/src/build_optimized.py\", line 8, in <module>\n    from diffusers.models.attention_processor import AttnProcessor2_0\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py\", line 24, in <module>\n    from .lora import LoRACompatibleLinear, LoRALinearLayer\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/lora.py\", line 21, in <module>\n    from ..loaders import PatchedLoraProjection, text_encoder_attn_modules, text_encoder_mlp_modules\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/loaders.py\", line 55, in <module>\n    from transformers import CLIPTextModel, CLIPTextModelWithProjection, PreTrainedModel\n  File \"<frozen importlib._bootstrap>\", line 1229, in _handle_fromlist\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1175, in __getattr__\n    value = getattr(module, name)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1174, in __getattr__\n    module = self._get_module(self._class_to_module[name])\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1186, in _get_module\n    raise RuntimeError(\nRuntimeError: Failed to import transformers.models.clip.modeling_clip because of the following error (look up to see its traceback):\nFailed to import transformers.generation.utils because of the following error (look up to see its traceback):\nnumpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\nE0103 07:49:02.150000 16800 torch/distributed/elastic/multiprocessing/api.py:882] failed (exitcode: 1) local_rank: 0 (pid: 16808) of binary: /usr/bin/python3\nTraceback (most recent call last):\n  File \"/usr/local/bin/accelerate\", line 10, in <module>\n    sys.exit(main())\n             ^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 47, in main\n    args.func(args)\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 977, in launch_command\n    multi_gpu_launcher(args)\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 646, in multi_gpu_launcher\n    distrib_run.run(args)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/run.py\", line 927, in run\n    elastic_launch(\n  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 156, in __call__\n    return launch_agent(self._config, self._entrypoint, list(args))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 293, in launch_agent\n    raise ChildFailedError(\ntorch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n============================================================\nFontDiffusion/my_train.py FAILED\n------------------------------------------------------------\nFailures:\n[1]:\n  time      : 2026-01-03_07:49:02\n  host      : 2afd4c94bbc8\n  rank      : 1 (local_rank: 1)\n  exitcode  : 1 (pid: 16809)\n  error_file: <N/A>\n  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n------------------------------------------------------------\nRoot Cause (first observed failure):\n[0]:\n  time      : 2026-01-03_07:49:02\n  host      : 2afd4c94bbc8\n  rank      : 0 (local_rank: 0)\n  exitcode  : 1 (pid: 16808)\n  error_file: <N/A>\n  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n============================================================\n","output_type":"stream"}],"execution_count":24},{"id":"cb2a3326-6bfa-4fba-bbcc-e2e7be996c7f","cell_type":"code","source":"!ls -lr outputs/FontDiffuser","metadata":{"id":"cb2a3326-6bfa-4fba-bbcc-e2e7be996c7f","trusted":true,"execution":{"iopub.status.busy":"2026-01-03T07:48:39.053115Z","iopub.execute_input":"2026-01-03T07:48:39.053602Z","iopub.status.idle":"2026-01-03T07:48:39.184520Z","shell.execute_reply.started":"2026-01-03T07:48:39.053578Z","shell.execute_reply":"2026-01-03T07:48:39.183747Z"}},"outputs":[{"name":"stdout","text":"ls: cannot access 'outputs/FontDiffuser': No such file or directory\n","output_type":"stream"}],"execution_count":23},{"id":"97f8136e","cell_type":"code","source":"# @title Training phase 2 with SCR\nif is_colab:\n  !uv pip install --upgrade \"huggingface-hub>=0.34.0,<1.0\"\nelse:\n  !uv pip install --upgrade \"huggingface-hub==0.25.2\"\n\n!wandb login\nMAX_TRAIN_STEPS = 500\n!accelerate launch FontDiffusion/my_train.py \\\n    --seed=123 \\\n    --experience_name=\"FontDiffuser_training_phase_2\" \\\n    --data_root=\"my_dataset\" \\\n    --output_dir=\"outputs/FontDiffuser\" \\\n    --report_to=\"wandb\" \\\n    --phase_2 \\\n    --phase_1_ckpt_dir=\"outputs/FontDiffuser/global_step_500\" \\\n    --scr_ckpt_path=\"ckpt/scr_210000.pth\" \\\n    \\\n    --sc_coefficient=0.05 \\\n    --num_neg=10 \\\n    --resolution=96 \\\n    --style_image_size=96 \\\n    --content_image_size=96 \\\n    --content_encoder_downsample_size=3 \\\n    --channel_attn=True \\\n    --content_start_channel=64 \\\n    --style_start_channel=64 \\\n    \\\n    --train_batch_size=16 \\\n    --gradient_accumulation_steps=1 \\\n    --perceptual_coefficient=0.05 \\\n    --offset_coefficient=0.5 \\\n    --max_train_steps={MAX_TRAIN_STEPS} \\\n    --ckpt_interval={MAX_TRAIN_STEPS // 2} \\\n    --log_interval=50 \\\n    \\\n    --learning_rate=1e-5 \\\n    --lr_scheduler=\"constant\" \\\n    --lr_warmup_steps=100 \\\n    --drop_prob=0.1 \\\n    --mixed_precision=\"no\"\n","metadata":{"id":"97f8136e","papermill":{"duration":0.022471,"end_time":"2025-12-30T18:55:24.845778","exception":false,"start_time":"2025-12-30T18:55:24.823307","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"0c935ec2-c328-4d82-925f-f51cb83bac9c","cell_type":"code","source":"!ls -l outputs/FontDiffuser/*/*","metadata":{"trusted":true,"id":"0c935ec2-c328-4d82-925f-f51cb83bac9c","outputId":"069960f1-c613-4390-bd0b-932306139b75"},"outputs":[],"execution_count":null},{"id":"88c45e2f","cell_type":"code","source":"STEP = 1000\n!python FontDiffusion/upload_models.py \\\n    --weights_dir \"outputs/FontDiffuser/global_step_{STEP}\" \\\n    --repo_id \"dzungpham/font-diffusion-weights\" \\\n    --token \"{HF_TOKEN}\"","metadata":{"id":"88c45e2f","papermill":{"duration":0.217876,"end_time":"2025-12-30T18:55:25.079820","exception":false,"start_time":"2025-12-30T18:55:24.861944","status":"completed"},"tags":[],"trusted":true,"outputId":"8e134396-7f00-4111-f45b-99760b66f48f"},"outputs":[],"execution_count":null},{"id":"5868b20b","cell_type":"code","source":"import os\nimport zipfile\nfrom pathlib import Path\nfrom typing import List\ndef find_result_folders(base_path: Path, pattern_name: str) -> List[Path]:\n    return [p for p in base_path.glob(pattern_name) if p.is_dir()]\n\ndef zip_folder(folder_path: Path, output_base_path: Path) -> bool:\n    folder_name = folder_path.name\n    zip_path = output_base_path / f\"{folder_name}.zip\"\n    try:\n        print(f\"   -> Zipping folder: {folder_name}...\")\n        with zipfile.ZipFile(zip_path, mode=\"w\", compression=zipfile.ZIP_DEFLATED) as zipf:\n            for file_path in folder_path.rglob(\"*\"):\n                if file_path.is_file():\n                    arcname = file_path.relative_to(folder_path.parent)\n                    zipf.write(file_path, arcname)\n        print(f\"   ✅ Created ZIP: {zip_path.name}\")\n        return True\n    except Exception as exc:\n        print(f\"   ❌ Failed to zip {folder_name}: {exc}\")\n        return False\n\ndef zip_stats_results_folders(output_base_path: str, pattern_name: str) -> None:\n    base = Path(output_base_path)\n    base.mkdir(parents=True, exist_ok=True)\n    result_folders = find_result_folders(base, pattern_name)\n    if not result_folders:\n        print(f\"⚠️ No folders matching '*dataset' found in '{output_base_path}'.\")\n        return\n    print(f\"🔍 Found {len(result_folders)} result folder(s) to zip.\")\n    successful = sum(1 for folder in result_folders if zip_folder(folder, base))\n    print(f\"\\n✅ DONE! Successfully zipped {successful} out of {len(result_folders)} folder(s).\")\n\nif __name__ == \"__main__\":\n    try:\n        output_root = os.getenv(\"OUTPUT_PATH\") or globals().get(\"OUTPUT_PATH\")\n        if not output_root:\n            raise ValueError(\"OUTPUT_PATH not defined\")\n        zip_stats_results_folders(\n            output_base_path=OUTPUT_PATH,\n            pattern_name=\"my_dataset\")\n    except Exception as e:\n        print(f\"❌ An error occurred: {e}\")","metadata":{"id":"5868b20b","papermill":{"duration":0.031197,"end_time":"2025-12-30T18:55:25.126961","exception":false,"start_time":"2025-12-30T18:55:25.095764","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}